{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d8d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Obtaining dependency information for category_encoders from https://files.pythonhosted.org/packages/1f/e2/495811f12b2e90753fff0e42a07adb0370a725de17cc23a579ac9d3ca67c/category_encoders-2.6.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading category_encoders-2.6.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting numpy>=1.14.0 (from category_encoders)\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-win_amd64.whl (14.0 MB)\n",
      "     ---------------------------------------- 14.0/14.0 MB 9.8 MB/s eta 0:00:00\n",
      "Collecting scikit-learn>=0.20.0 (from category_encoders)\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-win_amd64.whl (7.1 MB)\n",
      "     ---------------------------------------- 7.1/7.1 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.0.0 (from category_encoders)\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-win_amd64.whl (34.1 MB)\n",
      "     --------------------------------------- 34.1/34.1 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting statsmodels>=0.9.0 (from category_encoders)\n",
      "  Downloading statsmodels-0.13.5-cp37-cp37m-win_amd64.whl (9.1 MB)\n",
      "     ---------------------------------------- 9.1/9.1 MB 10.6 MB/s eta 0:00:00\n",
      "Collecting pandas>=1.0.5 (from category_encoders)\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-win_amd64.whl (10.0 MB)\n",
      "     ---------------------------------------- 10.0/10.0 MB 5.7 MB/s eta 0:00:00\n",
      "Collecting patsy>=0.5.1 (from category_encoders)\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "     ------------------------------------- 233.8/233.8 kB 14.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from category_encoders) (5.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Collecting pytz>=2017.3 (from pandas>=1.0.5->category_encoders)\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "     ------------------------------------- 502.3/502.3 kB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Collecting joblib>=0.11 (from scikit-learn>=0.20.0->category_encoders)\n",
      "  Obtaining dependency information for joblib>=0.11 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.20.0->category_encoders)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from importlib-resources->category_encoders) (3.15.0)\n",
      "Downloading category_encoders-2.6.2-py2.py3-none-any.whl (81 kB)\n",
      "   ---------------------------------------- 81.8/81.8 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 302.2/302.2 kB 9.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, threadpoolctl, numpy, joblib, scipy, patsy, pandas, statsmodels, scikit-learn, category_encoders\n",
      "Successfully installed category_encoders-2.6.2 joblib-1.3.2 numpy-1.21.6 pandas-1.3.5 patsy-0.5.3 pytz-2023.3 scikit-learn-1.0.2 scipy-1.7.3 statsmodels-0.13.5 threadpoolctl-3.1.0\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.2-py3-none-win_amd64.whl (125.4 MB)\n",
      "     -------------------------------------- 125.4/125.4 MB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from xgboost) (1.21.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.2\n",
      "Collecting lightgbm\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/87/0f/7630ee4fea60ebab5b0e3c35df570cb295c91ece537231a38105c0f243e8/lightgbm-4.0.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading lightgbm-4.0.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from lightgbm) (1.21.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "Downloading lightgbm-4.0.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 1.3/1.3 MB 7.6 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.0.0\n",
      "Collecting optuna\n",
      "  Obtaining dependency information for optuna from https://files.pythonhosted.org/packages/69/60/87a06ef66b34cbe2f2eb0ab66f003664404a7f40c21403a69fad7e28a82b/optuna-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading optuna-3.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Obtaining dependency information for alembic>=1.5.0 from https://files.pythonhosted.org/packages/ab/7d/b572fc6a51bc430b1fa0ef59591db32b14105093324d472eed8ea296d2df/alembic-1.11.3-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.11.3-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting cmaes>=0.10.0 (from optuna)\n",
      "  Obtaining dependency information for cmaes>=0.10.0 from https://files.pythonhosted.org/packages/f7/46/7d9544d453346f6c0c405916c95fdb653491ea2e9976cabb810ba2fe8cd4/cmaes-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from optuna) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from optuna) (23.1)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Obtaining dependency information for sqlalchemy>=1.3.0 from https://files.pythonhosted.org/packages/64/b6/73fdf8747cb07714383ed39e23a43de437f9ec6e2cad023866573bfe31ae/SQLAlchemy-2.0.20-cp37-cp37m-win_amd64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.20-cp37-cp37m-win_amd64.whl.metadata (9.7 kB)\n",
      "Collecting tqdm (from optuna)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting PyYAML (from optuna)\n",
      "  Obtaining dependency information for PyYAML from https://files.pythonhosted.org/packages/1e/ae/964ccb88a938f20ece5754878f182cfbd846924930d02d29d06af8d4c69e/PyYAML-6.0.1-cp37-cp37m-win_amd64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp37-cp37m-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.7/78.7 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (6.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (5.12.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
      "  Downloading greenlet-2.0.2-cp37-cp37m-win_amd64.whl (192 kB)\n",
      "     -------------------------------------- 192.4/192.4 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
      "   ---------------------------------------- 404.2/404.2 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading alembic-1.11.3-py3-none-any.whl (225 kB)\n",
      "   ---------------------------------------- 225.4/225.4 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Downloading SQLAlchemy-2.0.20-cp37-cp37m-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp37-cp37m-win_amd64.whl (153 kB)\n",
      "   ---------------------------------------- 153.2/153.2 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.3/78.3 kB 624.0 kB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, PyYAML, greenlet, colorlog, cmaes, sqlalchemy, Mako, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 PyYAML-6.0.1 alembic-1.11.3 cmaes-0.10.0 colorlog-6.7.0 greenlet-2.0.2 optuna-3.3.0 sqlalchemy-2.0.20 tqdm-4.66.1\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.3-cp37-cp37m-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 9.2 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "     ------------------------------------- 965.4/965.4 kB 10.2 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/27/b5/c548a1f1cef3fb9af3f59d6fc4259aa17c48403680c33435ca675aae2b30/kiwisolver-1.4.5-cp37-cp37m-win_amd64.whl.metadata\n",
      "  Downloading kiwisolver-1.4.5-cp37-cp37m-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from matplotlib) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Collecting pillow>=6.2.0 (from matplotlib)\n",
      "  Downloading Pillow-9.5.0-cp37-cp37m-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.2.1 (from matplotlib)\n",
      "  Obtaining dependency information for pyparsing>=2.2.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading kiwisolver-1.4.5-cp37-cp37m-win_amd64.whl (55 kB)\n",
      "   ---------------------------------------- 55.8/55.8 kB ? eta 0:00:00\n",
      "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 103.1/103.1 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.5 matplotlib-3.5.3 pillow-9.5.0 pyparsing-3.1.1\n",
      "Collecting catboost\n",
      "  Obtaining dependency information for catboost from https://files.pythonhosted.org/packages/47/80/a4169166708ea103545ca314b21fd92d241394bc100257bf1a611b1a6366/catboost-1.2.1-cp37-cp37m-win_amd64.whl.metadata\n",
      "  Downloading catboost-1.2.1-cp37-cp37m-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "     -------------------------------------- 47.0/47.0 kB 782.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from catboost) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from catboost) (1.21.6)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from catboost) (1.3.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from catboost) (1.7.3)\n",
      "Collecting plotly (from catboost)\n",
      "  Obtaining dependency information for plotly from https://files.pythonhosted.org/packages/26/5d/1e13b597ed8e54803e9ac6ded18c04cd35d8cbc49016778ec50c4ca9e9d5/plotly-5.16.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading plotly-5.16.1-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: six in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from matplotlib->catboost) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Collecting tenacity>=6.2.0 (from plotly->catboost)\n",
      "  Obtaining dependency information for tenacity>=6.2.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.7.1)\n",
      "Downloading catboost-1.2.1-cp37-cp37m-win_amd64.whl (101.0 MB)\n",
      "   ---------------------------------------- 101.0/101.0 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading plotly-5.16.1-py2.py3-none-any.whl (15.6 MB)\n",
      "   ---------------------------------------- 15.6/15.6 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, graphviz, plotly, catboost\n",
      "Successfully installed catboost-1.2.1 graphviz-0.20.1 plotly-5.16.1 tenacity-8.2.3\n"
     ]
    }
   ],
   "source": [
    "! pip install category_encoders\n",
    "! pip install xgboost\n",
    "! pip install lightgbm\n",
    "! pip install optuna\n",
    "! pip install matplotlib\n",
    "! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09cccbe-1e8d-4829-822c-c47402926b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import optuna\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e71d3a-bba7-4f21-bd12-2fddf7beaee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "moscow_df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab7a797-5e91-4641-958c-af3c54088720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updated</th>\n",
       "      <th>price</th>\n",
       "      <th>is_new</th>\n",
       "      <th>rooms</th>\n",
       "      <th>area</th>\n",
       "      <th>area_live</th>\n",
       "      <th>area_kitchen</th>\n",
       "      <th>floor_</th>\n",
       "      <th>floors</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>closest_station</th>\n",
       "      <th>dist_to_station</th>\n",
       "      <th>time</th>\n",
       "      <th>address_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-28 23:30:29</td>\n",
       "      <td>16200000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.60</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>55.663111</td>\n",
       "      <td>37.535233</td>\n",
       "      <td>ул. академика челомея 2</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Воронцовская</td>\n",
       "      <td>0.817926</td>\n",
       "      <td>243061860</td>\n",
       "      <td>ул.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-28 23:30:29</td>\n",
       "      <td>15100000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>70.00</td>\n",
       "      <td>41.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>55.744936</td>\n",
       "      <td>37.720906</td>\n",
       "      <td>авиамоторная ул. 30</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Авиамоторная</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>249401111</td>\n",
       "      <td>ул.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-28 23:30:31</td>\n",
       "      <td>59500000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>128.40</td>\n",
       "      <td>92.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>55.798480</td>\n",
       "      <td>37.520671</td>\n",
       "      <td>чапаевский пер. 3</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Сокол</td>\n",
       "      <td>0.991473</td>\n",
       "      <td>245344012</td>\n",
       "      <td>пер.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-28 23:30:32</td>\n",
       "      <td>7850000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>55.809216</td>\n",
       "      <td>37.759246</td>\n",
       "      <td>амурская ул. вл3бс1</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Локомотив</td>\n",
       "      <td>1.641747</td>\n",
       "      <td>245369240</td>\n",
       "      <td>ул.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-28 23:30:34</td>\n",
       "      <td>12600000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>54.40</td>\n",
       "      <td>32.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>55.597668</td>\n",
       "      <td>37.519018</td>\n",
       "      <td>вильнюсская ул. 15</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Ясенево</td>\n",
       "      <td>1.857019</td>\n",
       "      <td>249071508</td>\n",
       "      <td>ул.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547020</th>\n",
       "      <td>2022-03-03 15:31:51</td>\n",
       "      <td>7881820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.08</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>55.855774</td>\n",
       "      <td>37.621708</td>\n",
       "      <td>грин парк жк</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789749</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547021</th>\n",
       "      <td>2022-03-03 15:31:52</td>\n",
       "      <td>8140728</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.61</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>55.855774</td>\n",
       "      <td>37.621708</td>\n",
       "      <td>грин парк жк</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789746</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547022</th>\n",
       "      <td>2022-03-03 15:31:52</td>\n",
       "      <td>8989574</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.62</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>55.855774</td>\n",
       "      <td>37.621708</td>\n",
       "      <td>грин парк жк</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789741</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547023</th>\n",
       "      <td>2022-03-03 15:31:55</td>\n",
       "      <td>12757016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.84</td>\n",
       "      <td>12.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>55.855774</td>\n",
       "      <td>37.621708</td>\n",
       "      <td>грин парк жк</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789731</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547024</th>\n",
       "      <td>2022-03-03 15:31:55</td>\n",
       "      <td>12577110</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.94</td>\n",
       "      <td>10.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>55.855774</td>\n",
       "      <td>37.621708</td>\n",
       "      <td>грин парк жк</td>\n",
       "      <td>moscow</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789736</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547025 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    updated     price  is_new  rooms    area  area_live  \\\n",
       "0       2021-02-28 23:30:29  16200000       0      2   58.60       31.0   \n",
       "1       2021-02-28 23:30:29  15100000       0      3   70.00       41.7   \n",
       "2       2021-02-28 23:30:31  59500000       0      3  128.40       92.5   \n",
       "3       2021-02-28 23:30:32   7850000       1      1   41.30       20.0   \n",
       "4       2021-02-28 23:30:34  12600000       0      2   54.40       32.2   \n",
       "...                     ...       ...     ...    ...     ...        ...   \n",
       "547020  2022-03-03 15:31:51   7881820       1      0   23.08        9.6   \n",
       "547021  2022-03-03 15:31:52   8140728       1      0   23.61       11.1   \n",
       "547022  2022-03-03 15:31:52   8989574       1      0   26.62       11.8   \n",
       "547023  2022-03-03 15:31:55  12757016       1      1   41.84       12.4   \n",
       "547024  2022-03-03 15:31:55  12577110       1      1   37.94       10.8   \n",
       "\n",
       "        area_kitchen  floor_  floors        lat        lng  \\\n",
       "0               10.4      11      17  55.663111  37.535233   \n",
       "1               11.0       6       8  55.744936  37.720906   \n",
       "2               20.0      12      57  55.798480  37.520671   \n",
       "3               10.0       2       5  55.809216  37.759246   \n",
       "4                9.5       8      17  55.597668  37.519018   \n",
       "...              ...     ...     ...        ...        ...   \n",
       "547020           5.6       2      14  55.855774  37.621708   \n",
       "547021           5.0       3      14  55.855774  37.621708   \n",
       "547022           6.6       7      14  55.855774  37.621708   \n",
       "547023          20.3       2      14  55.855774  37.621708   \n",
       "547024          18.1       3      14  55.855774  37.621708   \n",
       "\n",
       "                        address    city closest_station  dist_to_station  \\\n",
       "0       ул. академика челомея 2  moscow    Воронцовская         0.817926   \n",
       "1           авиамоторная ул. 30  moscow    Авиамоторная         0.867403   \n",
       "2             чапаевский пер. 3  moscow           Сокол         0.991473   \n",
       "3           амурская ул. вл3бс1  moscow       Локомотив         1.641747   \n",
       "4            вильнюсская ул. 15  moscow         Ясенево         1.857019   \n",
       "...                         ...     ...             ...              ...   \n",
       "547020            грин парк жк   moscow        Отрадное         2.076289   \n",
       "547021            грин парк жк   moscow        Отрадное         2.076289   \n",
       "547022            грин парк жк   moscow        Отрадное         2.076289   \n",
       "547023            грин парк жк   moscow        Отрадное         2.076289   \n",
       "547024            грин парк жк   moscow        Отрадное         2.076289   \n",
       "\n",
       "             time address_type  \n",
       "0       243061860          ул.  \n",
       "1       249401111          ул.  \n",
       "2       245344012         пер.  \n",
       "3       245369240          ул.  \n",
       "4       249071508          ул.  \n",
       "...           ...          ...  \n",
       "547020  270789749           жк  \n",
       "547021  270789746           жк  \n",
       "547022  270789741           жк  \n",
       "547023  270789731           жк  \n",
       "547024  270789736           жк  \n",
       "\n",
       "[547025 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moscow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61acac5e-907f-4078-bbb8-f28cab9ef84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "moscow_df = moscow_df[moscow_df.price>10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b79b1b3-cfe8-4043-a834-8cd9b5c5aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = moscow_df.drop(columns=['price', 'address', 'updated', 'lat', 'lng', 'city']), moscow_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912e7a15-1f0e-4c1e-b98a-565561d06f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_new</th>\n",
       "      <th>rooms</th>\n",
       "      <th>area</th>\n",
       "      <th>area_live</th>\n",
       "      <th>area_kitchen</th>\n",
       "      <th>floor_</th>\n",
       "      <th>floors</th>\n",
       "      <th>closest_station</th>\n",
       "      <th>dist_to_station</th>\n",
       "      <th>time</th>\n",
       "      <th>address_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.60</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>Воронцовская</td>\n",
       "      <td>0.817926</td>\n",
       "      <td>243061860</td>\n",
       "      <td>ул.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>70.00</td>\n",
       "      <td>41.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>Авиамоторная</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>249401111</td>\n",
       "      <td>ул.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>128.40</td>\n",
       "      <td>92.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>Сокол</td>\n",
       "      <td>0.991473</td>\n",
       "      <td>245344012</td>\n",
       "      <td>пер.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Локомотив</td>\n",
       "      <td>1.641747</td>\n",
       "      <td>245369240</td>\n",
       "      <td>ул.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>54.40</td>\n",
       "      <td>32.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>Ясенево</td>\n",
       "      <td>1.857019</td>\n",
       "      <td>249071508</td>\n",
       "      <td>ул.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547020</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.08</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789749</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547021</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.61</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789746</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547022</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.62</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789741</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547023</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.84</td>\n",
       "      <td>12.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789731</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547024</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.94</td>\n",
       "      <td>10.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Отрадное</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789736</td>\n",
       "      <td>жк</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547025 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_new  rooms    area  area_live  area_kitchen  floor_  floors  \\\n",
       "0            0      2   58.60       31.0          10.4      11      17   \n",
       "1            0      3   70.00       41.7          11.0       6       8   \n",
       "2            0      3  128.40       92.5          20.0      12      57   \n",
       "3            1      1   41.30       20.0          10.0       2       5   \n",
       "4            0      2   54.40       32.2           9.5       8      17   \n",
       "...        ...    ...     ...        ...           ...     ...     ...   \n",
       "547020       1      0   23.08        9.6           5.6       2      14   \n",
       "547021       1      0   23.61       11.1           5.0       3      14   \n",
       "547022       1      0   26.62       11.8           6.6       7      14   \n",
       "547023       1      1   41.84       12.4          20.3       2      14   \n",
       "547024       1      1   37.94       10.8          18.1       3      14   \n",
       "\n",
       "       closest_station  dist_to_station       time address_type  \n",
       "0         Воронцовская         0.817926  243061860          ул.  \n",
       "1         Авиамоторная         0.867403  249401111          ул.  \n",
       "2                Сокол         0.991473  245344012         пер.  \n",
       "3            Локомотив         1.641747  245369240          ул.  \n",
       "4              Ясенево         1.857019  249071508          ул.  \n",
       "...                ...              ...        ...          ...  \n",
       "547020        Отрадное         2.076289  270789749           жк  \n",
       "547021        Отрадное         2.076289  270789746           жк  \n",
       "547022        Отрадное         2.076289  270789741           жк  \n",
       "547023        Отрадное         2.076289  270789731           жк  \n",
       "547024        Отрадное         2.076289  270789736           жк  \n",
       "\n",
       "[547025 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40aefae7-f45e-4782-9dcb-935bbdb12eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.CatBoostEncoder()\n",
    "X_cb = encoder.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b34a84-216e-4282-82de-5df901231853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_new</th>\n",
       "      <th>rooms</th>\n",
       "      <th>area</th>\n",
       "      <th>area_live</th>\n",
       "      <th>area_kitchen</th>\n",
       "      <th>floor_</th>\n",
       "      <th>floors</th>\n",
       "      <th>closest_station</th>\n",
       "      <th>dist_to_station</th>\n",
       "      <th>time</th>\n",
       "      <th>address_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.60</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>2.112412e+07</td>\n",
       "      <td>0.817926</td>\n",
       "      <td>243061860</td>\n",
       "      <td>2.112412e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>70.00</td>\n",
       "      <td>41.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2.112412e+07</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>249401111</td>\n",
       "      <td>1.866206e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>128.40</td>\n",
       "      <td>92.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>2.112412e+07</td>\n",
       "      <td>0.991473</td>\n",
       "      <td>245344012</td>\n",
       "      <td>2.112412e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2.112412e+07</td>\n",
       "      <td>1.641747</td>\n",
       "      <td>245369240</td>\n",
       "      <td>1.747471e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>54.40</td>\n",
       "      <td>32.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2.112412e+07</td>\n",
       "      <td>1.857019</td>\n",
       "      <td>249071508</td>\n",
       "      <td>1.506853e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547020</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.08</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1.350396e+07</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789749</td>\n",
       "      <td>1.493327e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547021</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.61</td>\n",
       "      <td>11.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1.350243e+07</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789746</td>\n",
       "      <td>1.493321e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547022</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.62</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>1.350098e+07</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789741</td>\n",
       "      <td>1.493314e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547023</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.84</td>\n",
       "      <td>12.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1.349975e+07</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789731</td>\n",
       "      <td>1.493309e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547024</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.94</td>\n",
       "      <td>10.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1.349955e+07</td>\n",
       "      <td>2.076289</td>\n",
       "      <td>270789736</td>\n",
       "      <td>1.493307e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547025 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_new  rooms    area  area_live  area_kitchen  floor_  floors  \\\n",
       "0            0      2   58.60       31.0          10.4      11      17   \n",
       "1            0      3   70.00       41.7          11.0       6       8   \n",
       "2            0      3  128.40       92.5          20.0      12      57   \n",
       "3            1      1   41.30       20.0          10.0       2       5   \n",
       "4            0      2   54.40       32.2           9.5       8      17   \n",
       "...        ...    ...     ...        ...           ...     ...     ...   \n",
       "547020       1      0   23.08        9.6           5.6       2      14   \n",
       "547021       1      0   23.61       11.1           5.0       3      14   \n",
       "547022       1      0   26.62       11.8           6.6       7      14   \n",
       "547023       1      1   41.84       12.4          20.3       2      14   \n",
       "547024       1      1   37.94       10.8          18.1       3      14   \n",
       "\n",
       "        closest_station  dist_to_station       time  address_type  \n",
       "0          2.112412e+07         0.817926  243061860  2.112412e+07  \n",
       "1          2.112412e+07         0.867403  249401111  1.866206e+07  \n",
       "2          2.112412e+07         0.991473  245344012  2.112412e+07  \n",
       "3          2.112412e+07         1.641747  245369240  1.747471e+07  \n",
       "4          2.112412e+07         1.857019  249071508  1.506853e+07  \n",
       "...                 ...              ...        ...           ...  \n",
       "547020     1.350396e+07         2.076289  270789749  1.493327e+07  \n",
       "547021     1.350243e+07         2.076289  270789746  1.493321e+07  \n",
       "547022     1.350098e+07         2.076289  270789741  1.493314e+07  \n",
       "547023     1.349975e+07         2.076289  270789731  1.493309e+07  \n",
       "547024     1.349955e+07         2.076289  270789736  1.493307e+07  \n",
       "\n",
       "[547025 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f6879e9-26ed-45cd-bc4a-1420c8d0ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cb, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d11f2c6-fb3f-4fc8-a4c0-86374fcd1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_objective_reg(trial):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "   \n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 24),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 5, 150),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 60),\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(criterion='squared_error', random_state=13, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_labels = model.predict(X_test)\n",
    "    ev = mean_absolute_percentage_error(y_test, pred_labels)\n",
    "    return ev\n",
    "\n",
    "def xgb_objective_reg(trial):\n",
    "    from xgboost import XGBRegressor\n",
    "\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('depth', 2, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.000001, 0.05),\n",
    "        \"lambda\": trial.suggest_float('lambda', 0, 1),\n",
    "        \"alpha\": trial.suggest_float('alpha', 0, 1),\n",
    "        \"subsample\": trial.suggest_float('subsample', 0.5, 1),\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'gpu_id': 0\n",
    "       \n",
    "    }\n",
    "\n",
    "    model = XGBRegressor( **param)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_labels = model.predict(X_test)\n",
    "    ev = mean_absolute_percentage_error(y_test, pred_labels)\n",
    "    return ev\n",
    "\n",
    "\n",
    "def lgbm_objective_reg(trial):\n",
    "    from lightgbm import LGBMRegressor\n",
    "\n",
    "    param = {\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 1.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 1.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'device': 'gpu',\n",
    "        'max_depth': trial.suggest_int('depth', 2, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.000001, 0.05)\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_labels = model.predict(X_test)\n",
    "    ev = mean_absolute_percentage_error(y_test, pred_labels)\n",
    "    return ev\n",
    "\n",
    "\n",
    "def cb_objective_reg(trial):\n",
    "    from catboost import CatBoostRegressor\n",
    "\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int(\"iterations\", 100, 3000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.000001, 0.05),\n",
    "        'depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0, 1),\n",
    "        'silent': True,\n",
    "        'task_type': \"GPU\",\n",
    "        'devices': \"0:1\",\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**param)\n",
    "    model.fit(X_train, y_train, silent=True, eval_set=(X_test, y_test), early_stopping_rounds=50)\n",
    "    pred_labels = model.predict(X_test)\n",
    "    ev = mean_absolute_percentage_error(y_test, pred_labels)\n",
    "    return ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088f71d-136b-491b-a3fb-c63b8cb35af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 14:37:27,450] A new study created in memory with name: no-name-e5c41445-a5d7-4815-9810-c294713297d9\n",
      "[I 2023-08-29 14:37:29,062] Trial 0 finished with value: 0.1428051028776049 and parameters: {'depth': 6, 'learning_rate': 0.022646208557249286, 'lambda': 0.9136078718014699, 'alpha': 0.5217890900939345, 'subsample': 0.5364345016722165}. Best is trial 0 with value: 0.1428051028776049.\n",
      "[I 2023-08-29 14:37:30,059] Trial 1 finished with value: 0.26517333631861595 and parameters: {'depth': 4, 'learning_rate': 0.012344240011818117, 'lambda': 0.8728582618910805, 'alpha': 0.2299610553659437, 'subsample': 0.7976493428432188}. Best is trial 0 with value: 0.1428051028776049.\n",
      "[I 2023-08-29 14:37:30,842] Trial 2 finished with value: 0.3012183865318729 and parameters: {'depth': 2, 'learning_rate': 0.01090897818693135, 'lambda': 0.7696354167811501, 'alpha': 0.6657456809276631, 'subsample': 0.9426106000182579}. Best is trial 0 with value: 0.1428051028776049.\n",
      "[I 2023-08-29 14:37:32,485] Trial 3 finished with value: 0.12365250772608613 and parameters: {'depth': 7, 'learning_rate': 0.029774320086220916, 'lambda': 0.5398877061658571, 'alpha': 0.486160669307224, 'subsample': 0.5597086475493344}. Best is trial 3 with value: 0.12365250772608613.\n",
      "[I 2023-08-29 14:37:33,317] Trial 4 finished with value: 0.29988905272846034 and parameters: {'depth': 2, 'learning_rate': 0.011008156440579104, 'lambda': 0.21966889177819704, 'alpha': 0.47790600715263787, 'subsample': 0.811586061689687}. Best is trial 3 with value: 0.12365250772608613.\n",
      "[I 2023-08-29 14:37:34,264] Trial 5 finished with value: 0.2451658916896891 and parameters: {'depth': 3, 'learning_rate': 0.013639738615532864, 'lambda': 0.9975577350698811, 'alpha': 0.26813018009897305, 'subsample': 0.8658025133364267}. Best is trial 3 with value: 0.12365250772608613.\n",
      "[I 2023-08-29 14:37:36,868] Trial 6 finished with value: 0.11045295508246106 and parameters: {'depth': 9, 'learning_rate': 0.03740689531048165, 'lambda': 0.2875103127289781, 'alpha': 0.09838190726085838, 'subsample': 0.5539372962331464}. Best is trial 6 with value: 0.11045295508246106.\n",
      "[I 2023-08-29 14:37:40,565] Trial 7 finished with value: 0.3634564254694125 and parameters: {'depth': 10, 'learning_rate': 0.009642594575667702, 'lambda': 0.9941636317714074, 'alpha': 0.6352821892460522, 'subsample': 0.958853506360207}. Best is trial 6 with value: 0.11045295508246106.\n",
      "[I 2023-08-29 14:37:43,967] Trial 8 finished with value: 0.10446719801202688 and parameters: {'depth': 10, 'learning_rate': 0.04977294177201864, 'lambda': 0.7385477779045181, 'alpha': 0.6455712088198146, 'subsample': 0.815095870161952}. Best is trial 8 with value: 0.10446719801202688.\n",
      "[I 2023-08-29 14:37:44,909] Trial 9 finished with value: 0.17873921765742593 and parameters: {'depth': 3, 'learning_rate': 0.044422990972839034, 'lambda': 0.8785114910676504, 'alpha': 0.5064420726138842, 'subsample': 0.9465881087604622}. Best is trial 8 with value: 0.10446719801202688.\n",
      "[I 2023-08-29 14:37:46,943] Trial 10 finished with value: 0.11607361720084931 and parameters: {'depth': 8, 'learning_rate': 0.049429492447895663, 'lambda': 0.6174987888014974, 'alpha': 0.9273123239554646, 'subsample': 0.7078909539635707}. Best is trial 8 with value: 0.10446719801202688.\n",
      "[I 2023-08-29 14:37:50,528] Trial 11 finished with value: 0.1048169329642098 and parameters: {'depth': 10, 'learning_rate': 0.03928969597525292, 'lambda': 0.279244670012543, 'alpha': 0.04344797692310158, 'subsample': 0.6771587425943428}. Best is trial 8 with value: 0.10446719801202688.\n",
      "[I 2023-08-29 14:37:54,287] Trial 12 finished with value: 0.10446716157386779 and parameters: {'depth': 10, 'learning_rate': 0.041035323102487545, 'lambda': 0.039750333939281846, 'alpha': 0.01620808417651244, 'subsample': 0.6922383532089815}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:37:56,289] Trial 13 finished with value: 0.11619168661618189 and parameters: {'depth': 8, 'learning_rate': 0.04935265903760544, 'lambda': 0.02711206839303726, 'alpha': 0.006148122434008925, 'subsample': 0.6508614631853203}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:37:57,723] Trial 14 finished with value: 0.12962690432108281 and parameters: {'depth': 6, 'learning_rate': 0.039913014604495214, 'lambda': 0.680461266269523, 'alpha': 0.29657445561882223, 'subsample': 0.7658160324447943}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:01,472] Trial 15 finished with value: 0.10662691579440074 and parameters: {'depth': 10, 'learning_rate': 0.031486899314994335, 'lambda': 0.3840748821940475, 'alpha': 0.15389854361370464, 'subsample': 0.8651626441999849}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:03,603] Trial 16 finished with value: 0.9912607304308779 and parameters: {'depth': 8, 'learning_rate': 8.40307672815982e-05, 'lambda': 0.4821329764285276, 'alpha': 0.0018999126688389323, 'subsample': 0.7202485850159389}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:06,224] Trial 17 finished with value: 0.11023715563177913 and parameters: {'depth': 9, 'learning_rate': 0.04384893720899662, 'lambda': 0.0003807734055205139, 'alpha': 0.3433927363429492, 'subsample': 0.6260570441981848}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:07,488] Trial 18 finished with value: 0.14065194836653844 and parameters: {'depth': 5, 'learning_rate': 0.04997374079727872, 'lambda': 0.7113099015224517, 'alpha': 0.1250685898567926, 'subsample': 0.6088402256913223}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:10,185] Trial 19 finished with value: 0.11053817247509778 and parameters: {'depth': 9, 'learning_rate': 0.033771567556641305, 'lambda': 0.13521098174139928, 'alpha': 0.8146029967003166, 'subsample': 0.7340547303404146}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:11,824] Trial 20 finished with value: 0.12215631747353008 and parameters: {'depth': 7, 'learning_rate': 0.04482759005702007, 'lambda': 0.4990339317187156, 'alpha': 0.3790808930485128, 'subsample': 0.6762818323883277}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:15,508] Trial 21 finished with value: 0.10500319435185827 and parameters: {'depth': 10, 'learning_rate': 0.03857350684285181, 'lambda': 0.11547802376969576, 'alpha': 0.08197751318726149, 'subsample': 0.6763053935248776}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:19,172] Trial 22 finished with value: 0.10450737384847852 and parameters: {'depth': 10, 'learning_rate': 0.04129488525226444, 'lambda': 0.32288164174290346, 'alpha': 0.18865282821099022, 'subsample': 0.7574163287078428}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:21,716] Trial 23 finished with value: 0.10980406363854471 and parameters: {'depth': 9, 'learning_rate': 0.043862831090840874, 'lambda': 0.39887980766395426, 'alpha': 0.18784264099655523, 'subsample': 0.763834410259384}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:25,398] Trial 24 finished with value: 0.10555847109016049 and parameters: {'depth': 10, 'learning_rate': 0.03337296746157099, 'lambda': 0.13115643429177204, 'alpha': 0.1825793853583466, 'subsample': 0.8096848755368424}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:27,968] Trial 25 finished with value: 0.109761507754799 and parameters: {'depth': 9, 'learning_rate': 0.046933135466431436, 'lambda': 0.38914722213990643, 'alpha': 0.09152235672161654, 'subsample': 0.7472775860074962}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:29,594] Trial 26 finished with value: 0.12208219617815697 and parameters: {'depth': 7, 'learning_rate': 0.03968480470886097, 'lambda': 0.5972882178845828, 'alpha': 0.22135452867831829, 'subsample': 0.7014306132165371}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:31,596] Trial 27 finished with value: 0.11536363640478244 and parameters: {'depth': 8, 'learning_rate': 0.04214281249299647, 'lambda': 0.21819224261259462, 'alpha': 0.13941830160157725, 'subsample': 0.8557888605520967}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:35,063] Trial 28 finished with value: 0.10588722672814982 and parameters: {'depth': 10, 'learning_rate': 0.0473384986734939, 'lambda': 0.08958615544958759, 'alpha': 0.003970223570277681, 'subsample': 0.5044384174424194}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:36,374] Trial 29 finished with value: 0.14398161935093398 and parameters: {'depth': 5, 'learning_rate': 0.02722754665445106, 'lambda': 0.7559610695468741, 'alpha': 0.41322242392480046, 'subsample': 0.7628089355466222}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:39,012] Trial 30 finished with value: 0.11021757000907777 and parameters: {'depth': 9, 'learning_rate': 0.03575070842090711, 'lambda': 0.060326710150411966, 'alpha': 0.317732776656329, 'subsample': 0.7266284139449182}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:43,678] Trial 31 finished with value: 0.10458354260501483 and parameters: {'depth': 10, 'learning_rate': 0.041095769689406564, 'lambda': 0.31177110296419797, 'alpha': 0.060216199469890014, 'subsample': 0.6809350986922194}. Best is trial 12 with value: 0.10446716157386779.\n",
      "[I 2023-08-29 14:38:48,532] Trial 32 finished with value: 0.10435676053001619 and parameters: {'depth': 10, 'learning_rate': 0.04167855482704197, 'lambda': 0.17366040915795866, 'alpha': 0.23258387673421785, 'subsample': 0.7846245575553609}. Best is trial 32 with value: 0.10435676053001619.\n",
      "[I 2023-08-29 14:38:51,184] Trial 33 finished with value: 0.1103116878249903 and parameters: {'depth': 9, 'learning_rate': 0.03590634126552429, 'lambda': 0.19467883387971568, 'alpha': 0.1803965995768746, 'subsample': 0.7965815271142094}. Best is trial 32 with value: 0.10435676053001619.\n",
      "[I 2023-08-29 14:38:54,971] Trial 34 finished with value: 0.10397062302620157 and parameters: {'depth': 10, 'learning_rate': 0.04629172537568723, 'lambda': 0.16587187911861911, 'alpha': 0.258042613266949, 'subsample': 0.8279566872123565}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:38:57,440] Trial 35 finished with value: 0.11555076778679226 and parameters: {'depth': 8, 'learning_rate': 0.046192753185220994, 'lambda': 0.05143067289828352, 'alpha': 0.26914026033082367, 'subsample': 0.8909485226256285}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:39:00,479] Trial 36 finished with value: 0.10938403788648865 and parameters: {'depth': 9, 'learning_rate': 0.046547748957996175, 'lambda': 0.14506544818233563, 'alpha': 0.4289465529090345, 'subsample': 0.8023330084356688}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:39:04,509] Trial 37 finished with value: 0.10403385327317005 and parameters: {'depth': 10, 'learning_rate': 0.042347373489861416, 'lambda': 0.003207946748340934, 'alpha': 0.5756015767288648, 'subsample': 0.8364665009448006}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:39:05,931] Trial 38 finished with value: 0.13012237177919164 and parameters: {'depth': 6, 'learning_rate': 0.04240585864850173, 'lambda': 0.07776940484682564, 'alpha': 0.24695406280007648, 'subsample': 0.9073784199335486}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:39:09,849] Trial 39 finished with value: 0.10472708961767631 and parameters: {'depth': 10, 'learning_rate': 0.03713431121232587, 'lambda': 0.00811366452276055, 'alpha': 0.5453660386057838, 'subsample': 0.827133249195005}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:39:11,557] Trial 40 finished with value: 0.13006314200354419 and parameters: {'depth': 7, 'learning_rate': 0.024714909797170788, 'lambda': 0.18303286676429098, 'alpha': 0.34439549090715027, 'subsample': 0.9852599686859249}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:39:15,280] Trial 41 finished with value: 0.10419866929364886 and parameters: {'depth': 10, 'learning_rate': 0.04295502116341357, 'lambda': 0.06360759613784268, 'alpha': 0.5784908726563205, 'subsample': 0.8413890794206501}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:39:17,987] Trial 42 finished with value: 0.10940334009304255 and parameters: {'depth': 9, 'learning_rate': 0.04254168469503638, 'lambda': 0.05887215840204711, 'alpha': 0.5589657540653238, 'subsample': 0.840350153713144}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:39:21,699] Trial 43 finished with value: 0.10483487085746797 and parameters: {'depth': 10, 'learning_rate': 0.03806159399332787, 'lambda': 0.16778538023425085, 'alpha': 0.5901648950343398, 'subsample': 0.7854722227289328}. Best is trial 34 with value: 0.10397062302620157.\n",
      "[I 2023-08-29 14:39:25,400] Trial 44 finished with value: 0.10367930234845257 and parameters: {'depth': 10, 'learning_rate': 0.04470067917902029, 'lambda': 0.10515517359632708, 'alpha': 0.45311239565297845, 'subsample': 0.8353981530150757}. Best is trial 44 with value: 0.10367930234845257.\n",
      "[I 2023-08-29 14:39:28,076] Trial 45 finished with value: 0.10984707195204163 and parameters: {'depth': 9, 'learning_rate': 0.04450734833712791, 'lambda': 0.2378019585789013, 'alpha': 0.4439970865692309, 'subsample': 0.839143838920542}. Best is trial 44 with value: 0.10367930234845257.\n",
      "[I 2023-08-29 14:39:31,752] Trial 46 finished with value: 0.10384210334803937 and parameters: {'depth': 10, 'learning_rate': 0.04759297406361464, 'lambda': 0.11979642241543341, 'alpha': 0.48547545581780777, 'subsample': 0.8848245939328787}. Best is trial 44 with value: 0.10367930234845257.\n",
      "[I 2023-08-29 14:39:32,761] Trial 47 finished with value: 0.17747877430095704 and parameters: {'depth': 3, 'learning_rate': 0.04739771916059209, 'lambda': 0.11181124623105347, 'alpha': 0.5175904426324694, 'subsample': 0.9003644574457549}. Best is trial 44 with value: 0.10367930234845257.\n",
      "[I 2023-08-29 14:39:33,753] Trial 48 finished with value: 0.2092348540067939 and parameters: {'depth': 2, 'learning_rate': 0.04805715358003813, 'lambda': 0.08477901859528393, 'alpha': 0.48252592141372663, 'subsample': 0.880404126537632}. Best is trial 44 with value: 0.10367930234845257.\n",
      "[I 2023-08-29 14:39:35,804] Trial 49 finished with value: 0.11559620739835641 and parameters: {'depth': 8, 'learning_rate': 0.04585033671307848, 'lambda': 0.005872581000685065, 'alpha': 0.6816045399313639, 'subsample': 0.9167330094195383}. Best is trial 44 with value: 0.10367930234845257.\n",
      "[I 2023-08-29 14:39:37,094] Trial 50 finished with value: 0.15676000266346113 and parameters: {'depth': 4, 'learning_rate': 0.04475464397826506, 'lambda': 0.120335936731874, 'alpha': 0.4678896822616143, 'subsample': 0.8525524686282294}. Best is trial 44 with value: 0.10367930234845257.\n",
      "[I 2023-08-29 14:39:40,818] Trial 51 finished with value: 0.1035622584433479 and parameters: {'depth': 10, 'learning_rate': 0.04812708994483626, 'lambda': 0.1587954356251775, 'alpha': 0.41012940516445495, 'subsample': 0.8284856232566905}. Best is trial 51 with value: 0.1035622584433479.\n",
      "[I 2023-08-29 14:39:44,459] Trial 52 finished with value: 0.1037406241018419 and parameters: {'depth': 10, 'learning_rate': 0.04999524424460251, 'lambda': 0.05676041224862377, 'alpha': 0.39952438081811514, 'subsample': 0.8742037488282479}. Best is trial 51 with value: 0.1035622584433479.\n",
      "[I 2023-08-29 14:39:48,079] Trial 53 finished with value: 0.10355748391322288 and parameters: {'depth': 10, 'learning_rate': 0.04906370982397699, 'lambda': 0.2481404158623008, 'alpha': 0.3909689325927807, 'subsample': 0.8746403260055056}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:39:50,645] Trial 54 finished with value: 0.10959771011349101 and parameters: {'depth': 9, 'learning_rate': 0.049948692135928216, 'lambda': 0.24249277822840362, 'alpha': 0.3858850172366425, 'subsample': 0.8761223224471006}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:39:54,099] Trial 55 finished with value: 0.10360987495088425 and parameters: {'depth': 10, 'learning_rate': 0.048261004756580114, 'lambda': 0.15823255209851922, 'alpha': 0.38918822054069735, 'subsample': 0.919797381049517}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:39:58,347] Trial 56 finished with value: 0.1095001217519076 and parameters: {'depth': 9, 'learning_rate': 0.048369238399688694, 'lambda': 0.20915432925979824, 'alpha': 0.39589982805948326, 'subsample': 0.9214502670496182}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:40:04,348] Trial 57 finished with value: 0.10395066891125605 and parameters: {'depth': 10, 'learning_rate': 0.04861849141695979, 'lambda': 0.26000373511441754, 'alpha': 0.4565171825614114, 'subsample': 0.9353033051799383}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:40:10,369] Trial 58 finished with value: 0.10380994044007201 and parameters: {'depth': 10, 'learning_rate': 0.04989658312245292, 'lambda': 0.0987211237110375, 'alpha': 0.3601845687807397, 'subsample': 0.8724555311665473}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:40:13,005] Trial 59 finished with value: 0.10946054235395802 and parameters: {'depth': 9, 'learning_rate': 0.04971013574271117, 'lambda': 0.20866538727915165, 'alpha': 0.35752431732571655, 'subsample': 0.8979948430255594}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:40:15,080] Trial 60 finished with value: 0.11583158118130484 and parameters: {'depth': 8, 'learning_rate': 0.04556154778204904, 'lambda': 0.15843883927248925, 'alpha': 0.31404027769298354, 'subsample': 0.8576943368016777}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:40:18,834] Trial 61 finished with value: 0.10368542496313336 and parameters: {'depth': 10, 'learning_rate': 0.048133238783713284, 'lambda': 0.09790111288517933, 'alpha': 0.4183686739258697, 'subsample': 0.881157246505455}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:40:22,541] Trial 62 finished with value: 0.10371948323060504 and parameters: {'depth': 10, 'learning_rate': 0.048531846883144165, 'lambda': 0.0342495600474442, 'alpha': 0.41471810539695003, 'subsample': 0.8644500078727622}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:40:26,351] Trial 63 finished with value: 0.10414204599205013 and parameters: {'depth': 10, 'learning_rate': 0.04823573074529112, 'lambda': 0.04882770497980063, 'alpha': 0.41793177452658925, 'subsample': 0.8678777653735812}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:40:29,115] Trial 64 finished with value: 0.1098473491181814 and parameters: {'depth': 9, 'learning_rate': 0.04410268900646442, 'lambda': 0.03712967835737736, 'alpha': 0.44297593338374813, 'subsample': 0.8942841184545245}. Best is trial 53 with value: 0.10355748391322288.\n",
      "[I 2023-08-29 14:40:32,908] Trial 65 finished with value: 0.10354828670143609 and parameters: {'depth': 10, 'learning_rate': 0.04535508091966333, 'lambda': 0.09291722170668129, 'alpha': 0.3822759626985845, 'subsample': 0.9289989568314088}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:40:36,809] Trial 66 finished with value: 0.10415067776100304 and parameters: {'depth': 10, 'learning_rate': 0.04504144938348307, 'lambda': 0.14316188860000356, 'alpha': 0.37440257717315617, 'subsample': 0.9498490856716983}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:40:39,453] Trial 67 finished with value: 0.10967048246637157 and parameters: {'depth': 9, 'learning_rate': 0.0398276977558742, 'lambda': 0.08835664397604354, 'alpha': 0.3169324224258281, 'subsample': 0.9284873993989042}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:40:43,306] Trial 68 finished with value: 0.1037652105340975 and parameters: {'depth': 10, 'learning_rate': 0.046706007845550936, 'lambda': 0.1864459401231771, 'alpha': 0.4157911073520478, 'subsample': 0.9156161754593157}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:40:46,863] Trial 69 finished with value: 0.10388433194972978 and parameters: {'depth': 10, 'learning_rate': 0.04836537016375301, 'lambda': 0.138740621246142, 'alpha': 0.5107765062918516, 'subsample': 0.9634053359426841}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:40:49,538] Trial 70 finished with value: 0.10966116672581608 and parameters: {'depth': 9, 'learning_rate': 0.044002189618486065, 'lambda': 0.11383894089347726, 'alpha': 0.4657798767720206, 'subsample': 0.8199086494426665}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:40:53,242] Trial 71 finished with value: 0.10386370711049056 and parameters: {'depth': 10, 'learning_rate': 0.04626257821590064, 'lambda': 0.03224949798164622, 'alpha': 0.3943695701786032, 'subsample': 0.906799204369156}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:40:57,612] Trial 72 finished with value: 0.10363000858253306 and parameters: {'depth': 10, 'learning_rate': 0.04831182407130382, 'lambda': 0.08337726931147757, 'alpha': 0.42459596022996926, 'subsample': 0.8858559481259218}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:01,481] Trial 73 finished with value: 0.1038502866583092 and parameters: {'depth': 10, 'learning_rate': 0.04765583483323335, 'lambda': 0.09215740464897854, 'alpha': 0.433491665805361, 'subsample': 0.8548878799719951}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:05,058] Trial 74 finished with value: 0.10406932161709576 and parameters: {'depth': 10, 'learning_rate': 0.04545122019191141, 'lambda': 0.15279082515585019, 'alpha': 0.34264078423438005, 'subsample': 0.8894356632246923}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:07,646] Trial 75 finished with value: 0.10988547625523098 and parameters: {'depth': 9, 'learning_rate': 0.040604500100017926, 'lambda': 0.07697514384150256, 'alpha': 0.3727760744171656, 'subsample': 0.9334442454018977}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:12,058] Trial 76 finished with value: 0.10409200286286048 and parameters: {'depth': 10, 'learning_rate': 0.04334173981800937, 'lambda': 0.024739362862904103, 'alpha': 0.28879050693898134, 'subsample': 0.8626452923100865}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:15,992] Trial 77 finished with value: 0.10422416615451784 and parameters: {'depth': 10, 'learning_rate': 0.04702700782952141, 'lambda': 0.19249759113633036, 'alpha': 0.4939840976494899, 'subsample': 0.8859144722939383}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:18,670] Trial 78 finished with value: 0.10943608025438183 and parameters: {'depth': 9, 'learning_rate': 0.04883348209834403, 'lambda': 0.10858545585643499, 'alpha': 0.4259645480386398, 'subsample': 0.9076637246854805}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:22,759] Trial 79 finished with value: 0.10375752683065903 and parameters: {'depth': 10, 'learning_rate': 0.042863742720353544, 'lambda': 0.147948905743247, 'alpha': 0.3334968453760767, 'subsample': 0.8147508240152701}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:26,747] Trial 80 finished with value: 0.1036500074161765 and parameters: {'depth': 10, 'learning_rate': 0.048646000993573815, 'lambda': 0.07243363970415984, 'alpha': 0.45479826136281126, 'subsample': 0.9198048699614729}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:30,779] Trial 81 finished with value: 0.10385712932222106 and parameters: {'depth': 10, 'learning_rate': 0.0455098483880981, 'lambda': 0.07009909574586677, 'alpha': 0.4514247712280131, 'subsample': 0.9427458622200036}. Best is trial 65 with value: 0.10354828670143609.\n",
      "[I 2023-08-29 14:41:34,472] Trial 82 finished with value: 0.10347656007956288 and parameters: {'depth': 10, 'learning_rate': 0.048635605625015635, 'lambda': 0.03710049592091107, 'alpha': 0.4042050053059054, 'subsample': 0.9221510195015966}. Best is trial 82 with value: 0.10347656007956288.\n",
      "[I 2023-08-29 14:41:35,789] Trial 83 finished with value: 0.14108354447546434 and parameters: {'depth': 5, 'learning_rate': 0.046905913038840466, 'lambda': 0.13326499310766504, 'alpha': 0.3635825524085706, 'subsample': 0.9228539394128595}. Best is trial 82 with value: 0.10347656007956288.\n",
      "[I 2023-08-29 14:41:39,533] Trial 84 finished with value: 0.10368570506827919 and parameters: {'depth': 10, 'learning_rate': 0.04891883015841191, 'lambda': 0.09654907521152296, 'alpha': 0.47190137389130565, 'subsample': 0.9073069633009941}. Best is trial 82 with value: 0.10347656007956288.\n",
      "[I 2023-08-29 14:41:42,139] Trial 85 finished with value: 0.1095010480613441 and parameters: {'depth': 9, 'learning_rate': 0.044409818857510594, 'lambda': 0.1749836872132447, 'alpha': 0.39221608224150883, 'subsample': 0.9638871230133018}. Best is trial 82 with value: 0.10347656007956288.\n",
      "[I 2023-08-29 14:41:46,024] Trial 86 finished with value: 0.10363342162830726 and parameters: {'depth': 10, 'learning_rate': 0.04728195277706148, 'lambda': 0.07296388228027816, 'alpha': 0.44019753654894134, 'subsample': 0.9334690904221002}. Best is trial 82 with value: 0.10347656007956288.\n",
      "[I 2023-08-29 14:41:50,014] Trial 87 finished with value: 0.1038459217860097 and parameters: {'depth': 10, 'learning_rate': 0.046136244885219106, 'lambda': 0.02720853085041819, 'alpha': 0.5246932699063995, 'subsample': 0.9520393807192201}. Best is trial 82 with value: 0.10347656007956288.\n",
      "[I 2023-08-29 14:41:54,046] Trial 88 finished with value: 0.1040997190075158 and parameters: {'depth': 10, 'learning_rate': 0.04144331308675438, 'lambda': 0.06884972515129258, 'alpha': 0.4427903821136218, 'subsample': 0.9355930731513077}. Best is trial 82 with value: 0.10347656007956288.\n",
      "[I 2023-08-29 14:41:56,910] Trial 89 finished with value: 0.10986318247865316 and parameters: {'depth': 9, 'learning_rate': 0.04361702439178408, 'lambda': 0.12538006369999632, 'alpha': 0.48569719691469465, 'subsample': 0.923472455002931}. Best is trial 82 with value: 0.10347656007956288.\n",
      "[I 2023-08-29 14:42:00,812] Trial 90 finished with value: 0.10338147389555992 and parameters: {'depth': 10, 'learning_rate': 0.04758781529920056, 'lambda': 0.1659742805005731, 'alpha': 0.378069181563076, 'subsample': 0.897452780658317}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:04,651] Trial 91 finished with value: 0.10356617686597007 and parameters: {'depth': 10, 'learning_rate': 0.04900635093292143, 'lambda': 0.1634628361576015, 'alpha': 0.37372553159570837, 'subsample': 0.8991457609016786}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:08,230] Trial 92 finished with value: 0.10383269274830403 and parameters: {'depth': 10, 'learning_rate': 0.04917770654738916, 'lambda': 0.22813238770072164, 'alpha': 0.3728918482721508, 'subsample': 0.8979374257641857}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:11,778] Trial 93 finished with value: 0.10356972630386768 and parameters: {'depth': 10, 'learning_rate': 0.04759117132287079, 'lambda': 0.16682513128354434, 'alpha': 0.34280033682206923, 'subsample': 0.9163930848100426}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:14,729] Trial 94 finished with value: 0.1098576616500085 and parameters: {'depth': 9, 'learning_rate': 0.04718390003582548, 'lambda': 0.21097004991867052, 'alpha': 0.3359933872462065, 'subsample': 0.9436441204721816}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:18,384] Trial 95 finished with value: 0.1036601256221557 and parameters: {'depth': 10, 'learning_rate': 0.04996557014616408, 'lambda': 0.1746005619353041, 'alpha': 0.3017781452221806, 'subsample': 0.9071523251785458}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:22,134] Trial 96 finished with value: 0.10375411946242655 and parameters: {'depth': 10, 'learning_rate': 0.047369844813935455, 'lambda': 0.2582904781915945, 'alpha': 0.284311831299354, 'subsample': 0.8924343520512271}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:25,822] Trial 97 finished with value: 0.10362719061318912 and parameters: {'depth': 10, 'learning_rate': 0.04600094602948021, 'lambda': 0.16219636706457752, 'alpha': 0.39620849845358697, 'subsample': 0.9130232527250279}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:29,620] Trial 98 finished with value: 0.10380407121547743 and parameters: {'depth': 10, 'learning_rate': 0.045470843837409326, 'lambda': 0.19527717337150313, 'alpha': 0.35224507553263956, 'subsample': 0.8742009146410328}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:32,436] Trial 99 finished with value: 0.10970774213487398 and parameters: {'depth': 9, 'learning_rate': 0.045725492358415616, 'lambda': 0.16156839711007603, 'alpha': 0.3990121008189296, 'subsample': 0.8989075636345029}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:34,309] Trial 100 finished with value: 0.12232428461021079 and parameters: {'depth': 7, 'learning_rate': 0.0435966783592469, 'lambda': 0.2960883220474129, 'alpha': 0.33133853813018327, 'subsample': 0.8844623194420304}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:38,141] Trial 101 finished with value: 0.10369655611543396 and parameters: {'depth': 10, 'learning_rate': 0.047656790405044634, 'lambda': 0.12796873306683784, 'alpha': 0.3796068008202465, 'subsample': 0.9319255675918638}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:41,919] Trial 102 finished with value: 0.10383954192457853 and parameters: {'depth': 10, 'learning_rate': 0.04670696866385242, 'lambda': 0.1542959459038761, 'alpha': 0.4091541498638859, 'subsample': 0.9118617806821786}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:45,795] Trial 103 finished with value: 0.10372343256829179 and parameters: {'depth': 10, 'learning_rate': 0.04897924259046973, 'lambda': 0.2177868835401733, 'alpha': 0.36523615381938684, 'subsample': 0.9245839511817475}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:49,771] Trial 104 finished with value: 0.10365899677738184 and parameters: {'depth': 10, 'learning_rate': 0.04781419179251587, 'lambda': 0.19002658922228632, 'alpha': 0.39505028743398285, 'subsample': 0.9570625124333484}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:53,622] Trial 105 finished with value: 0.10380239729321107 and parameters: {'depth': 10, 'learning_rate': 0.04473804483415389, 'lambda': 0.1219358307049801, 'alpha': 0.4307505114096482, 'subsample': 0.9380055743826975}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:56,326] Trial 106 finished with value: 0.10960363236525691 and parameters: {'depth': 9, 'learning_rate': 0.04923255599767691, 'lambda': 0.05128226154230929, 'alpha': 0.3463623140804621, 'subsample': 0.913973460230402}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:42:59,869] Trial 107 finished with value: 0.10340818965537417 and parameters: {'depth': 10, 'learning_rate': 0.04630979210952281, 'lambda': 0.1472887441377702, 'alpha': 0.31605463352383373, 'subsample': 0.8990555264475351}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:03,447] Trial 108 finished with value: 0.1042404675533539 and parameters: {'depth': 10, 'learning_rate': 0.04626961367972492, 'lambda': 0.17075579147009315, 'alpha': 0.3196973699303775, 'subsample': 0.8990736012546306}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:07,141] Trial 109 finished with value: 0.10392381212449162 and parameters: {'depth': 10, 'learning_rate': 0.041753940079622756, 'lambda': 0.14065698898111764, 'alpha': 0.295910699353661, 'subsample': 0.881513372045552}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:09,896] Trial 110 finished with value: 0.1096231206948445 and parameters: {'depth': 9, 'learning_rate': 0.04500585689554735, 'lambda': 0.22570414766805025, 'alpha': 0.2755061207126448, 'subsample': 0.8519553970439383}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:13,734] Trial 111 finished with value: 0.10343337861464567 and parameters: {'depth': 10, 'learning_rate': 0.0477329238261195, 'lambda': 0.10850992390187003, 'alpha': 0.3748350880619675, 'subsample': 0.9264243342837107}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:17,415] Trial 112 finished with value: 0.1035991427248872 and parameters: {'depth': 10, 'learning_rate': 0.04835017634614377, 'lambda': 0.11350817892447151, 'alpha': 0.3763949078912254, 'subsample': 0.9165925955850015}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:21,247] Trial 113 finished with value: 0.1037099364478001 and parameters: {'depth': 10, 'learning_rate': 0.049968871021254115, 'lambda': 0.10702682100620949, 'alpha': 0.35941015450793856, 'subsample': 0.9190716540686624}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:25,110] Trial 114 finished with value: 0.10399507396735679 and parameters: {'depth': 10, 'learning_rate': 0.046282852635279974, 'lambda': 0.1572333091205773, 'alpha': 0.31496841855669133, 'subsample': 0.9122141015806747}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:28,796] Trial 115 finished with value: 0.10415405529911612 and parameters: {'depth': 10, 'learning_rate': 0.04296142601625268, 'lambda': 0.19880271803961236, 'alpha': 0.3832239028385383, 'subsample': 0.9491539461719276}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:30,068] Trial 116 finished with value: 0.15462074220999544 and parameters: {'depth': 4, 'learning_rate': 0.04801413645438892, 'lambda': 0.1334457390301774, 'alpha': 0.3517358127887589, 'subsample': 0.9263873016671386}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:33,687] Trial 117 finished with value: 0.10373352938019269 and parameters: {'depth': 10, 'learning_rate': 0.04919161348729526, 'lambda': 0.2478242078785863, 'alpha': 0.3298712078080994, 'subsample': 0.9027913565410036}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:36,341] Trial 118 finished with value: 0.10989818008980935 and parameters: {'depth': 9, 'learning_rate': 0.046895210605147564, 'lambda': 0.16672512807420342, 'alpha': 0.40799832179322865, 'subsample': 0.8737513090517269}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:39,985] Trial 119 finished with value: 0.10418498201766983 and parameters: {'depth': 10, 'learning_rate': 0.04523885229536086, 'lambda': 0.2753130075277219, 'alpha': 0.2572985947255801, 'subsample': 0.9700639465005585}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:43,886] Trial 120 finished with value: 0.10372230132144152 and parameters: {'depth': 10, 'learning_rate': 0.047971897073413636, 'lambda': 0.1820451157829421, 'alpha': 0.38685439940533894, 'subsample': 0.944151200951326}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:47,726] Trial 121 finished with value: 0.10354908049141544 and parameters: {'depth': 10, 'learning_rate': 0.04863726133551455, 'lambda': 0.09729141541961973, 'alpha': 0.4242409531487692, 'subsample': 0.8944315146178085}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:53,580] Trial 122 finished with value: 0.10356410333518334 and parameters: {'depth': 10, 'learning_rate': 0.04899957638291701, 'lambda': 0.101416398889601, 'alpha': 0.3713924779894587, 'subsample': 0.8932465520849673}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:43:57,309] Trial 123 finished with value: 0.10364576235126527 and parameters: {'depth': 10, 'learning_rate': 0.048992414378079906, 'lambda': 0.10647485028642596, 'alpha': 0.3025841687560817, 'subsample': 0.8943253991617405}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:00,901] Trial 124 finished with value: 0.10378074512135198 and parameters: {'depth': 10, 'learning_rate': 0.049980221361786085, 'lambda': 0.05093382049017196, 'alpha': 0.373575136508866, 'subsample': 0.8924687182644798}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:04,683] Trial 125 finished with value: 0.10362915596473841 and parameters: {'depth': 10, 'learning_rate': 0.04779755366884427, 'lambda': 0.09470436722890022, 'alpha': 0.34361872637613616, 'subsample': 0.8669266437946499}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:07,273] Trial 126 finished with value: 0.10954047052992215 and parameters: {'depth': 9, 'learning_rate': 0.04884228029004058, 'lambda': 0.11946055919643422, 'alpha': 0.4099355501876487, 'subsample': 0.9269179720580256}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:10,922] Trial 127 finished with value: 0.10352318288434621 and parameters: {'depth': 10, 'learning_rate': 0.04693518903219218, 'lambda': 0.14489263793472223, 'alpha': 0.3660535720429287, 'subsample': 0.9050069892336746}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:14,701] Trial 128 finished with value: 0.10391200983210144 and parameters: {'depth': 10, 'learning_rate': 0.04409508502180355, 'lambda': 0.0868697436644587, 'alpha': 0.3277790027214635, 'subsample': 0.9022730149817735}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:18,429] Trial 129 finished with value: 0.10375423830729476 and parameters: {'depth': 10, 'learning_rate': 0.04693114404871893, 'lambda': 0.13659615825878563, 'alpha': 0.3661835095203903, 'subsample': 0.8808118594114792}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:23,355] Trial 130 finished with value: 0.10394694030454674 and parameters: {'depth': 10, 'learning_rate': 0.04634483246929693, 'lambda': 0.011905480474739685, 'alpha': 0.4216039782905568, 'subsample': 0.845749795946755}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:27,816] Trial 131 finished with value: 0.10384833459135664 and parameters: {'depth': 10, 'learning_rate': 0.048204288844887276, 'lambda': 0.14641893009141985, 'alpha': 0.35281093959549625, 'subsample': 0.9131265272277995}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:31,495] Trial 132 finished with value: 0.10407827245966732 and parameters: {'depth': 10, 'learning_rate': 0.04893757627567394, 'lambda': 0.2057902024665932, 'alpha': 0.38093732212867715, 'subsample': 0.8901834873973231}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:35,340] Trial 133 finished with value: 0.10379811447915663 and parameters: {'depth': 10, 'learning_rate': 0.04719365380364631, 'lambda': 0.11000894229607026, 'alpha': 0.30833328951814304, 'subsample': 0.9351257432878656}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:39,130] Trial 134 finished with value: 0.1038715906412236 and parameters: {'depth': 10, 'learning_rate': 0.045271616345645735, 'lambda': 0.059143071577994144, 'alpha': 0.46251712308876536, 'subsample': 0.9037811561933585}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:42,793] Trial 135 finished with value: 0.10371118451826052 and parameters: {'depth': 10, 'learning_rate': 0.04772822729957249, 'lambda': 0.08230509268597348, 'alpha': 0.43708943780235066, 'subsample': 0.863787201137794}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:46,566] Trial 136 finished with value: 0.10369793720961287 and parameters: {'depth': 10, 'learning_rate': 0.04933008664273732, 'lambda': 0.18639038759858778, 'alpha': 0.4011650249230738, 'subsample': 0.9237964459690969}. Best is trial 90 with value: 0.10338147389555992.\n",
      "[I 2023-08-29 14:44:50,238] Trial 137 finished with value: 0.10319008323080202 and parameters: {'depth': 10, 'learning_rate': 0.04995308869389948, 'lambda': 0.12916226398413766, 'alpha': 0.33668599754411377, 'subsample': 0.9169304513576173}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:44:53,030] Trial 138 finished with value: 0.10985415440251875 and parameters: {'depth': 9, 'learning_rate': 0.04993049708250869, 'lambda': 0.12257089774573207, 'alpha': 0.2804147088113204, 'subsample': 0.8773617940046343}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:44:54,494] Trial 139 finished with value: 0.12948175766279704 and parameters: {'depth': 6, 'learning_rate': 0.045954638401062405, 'lambda': 0.037704960101447665, 'alpha': 0.3276938111355377, 'subsample': 0.8894282265737496}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:44:58,362] Trial 140 finished with value: 0.10421796272771984 and parameters: {'depth': 10, 'learning_rate': 0.04455842031197729, 'lambda': 0.1429636699806372, 'alpha': 0.36312673532866335, 'subsample': 0.9063002785975549}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:02,363] Trial 141 finished with value: 0.10323276745856576 and parameters: {'depth': 10, 'learning_rate': 0.04843131541172269, 'lambda': 0.09388585586315523, 'alpha': 0.3735134557228281, 'subsample': 0.9183941518881926}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:06,377] Trial 142 finished with value: 0.10361450595821822 and parameters: {'depth': 10, 'learning_rate': 0.04691074255490324, 'lambda': 0.09476121216712538, 'alpha': 0.3400920878717545, 'subsample': 0.9446596473918347}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:12,617] Trial 143 finished with value: 0.10360099050371627 and parameters: {'depth': 10, 'learning_rate': 0.048615349122772544, 'lambda': 0.06405996470121614, 'alpha': 0.38440883766284095, 'subsample': 0.9169530644474809}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:16,713] Trial 144 finished with value: 0.10379025020675267 and parameters: {'depth': 10, 'learning_rate': 0.047615133189056164, 'lambda': 0.11643535938738855, 'alpha': 0.3646475790855319, 'subsample': 0.9278820147943564}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:20,452] Trial 145 finished with value: 0.10391937980975088 and parameters: {'depth': 10, 'learning_rate': 0.04883064860956495, 'lambda': 0.07654920104315145, 'alpha': 0.41134820753626167, 'subsample': 0.8984387381280351}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:24,334] Trial 146 finished with value: 0.10401899911148732 and parameters: {'depth': 10, 'learning_rate': 0.049983722129157866, 'lambda': 0.23384045128046593, 'alpha': 0.29843210516642416, 'subsample': 0.9385037297775612}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:25,356] Trial 147 finished with value: 0.21144462435020692 and parameters: {'depth': 2, 'learning_rate': 0.046205545574112265, 'lambda': 0.1721301712449268, 'alpha': 0.34162690626596315, 'subsample': 0.9164545511349022}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:29,420] Trial 148 finished with value: 0.10438879307846449 and parameters: {'depth': 10, 'learning_rate': 0.04771708308104866, 'lambda': 0.14138350975783215, 'alpha': 0.3185263278269021, 'subsample': 0.8864734552385036}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:33,358] Trial 149 finished with value: 0.10641268461759375 and parameters: {'depth': 10, 'learning_rate': 0.03181923619147261, 'lambda': 0.10283531388314113, 'alpha': 0.4250827009542706, 'subsample': 0.8690252467648528}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:36,004] Trial 150 finished with value: 0.11010988753704626 and parameters: {'depth': 9, 'learning_rate': 0.046768083699400775, 'lambda': 0.04640418549479289, 'alpha': 0.37414334659211435, 'subsample': 0.9069255060390182}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:39,749] Trial 151 finished with value: 0.10370093689508017 and parameters: {'depth': 10, 'learning_rate': 0.04886397058343847, 'lambda': 0.0654671085740782, 'alpha': 0.3846547842696181, 'subsample': 0.9178060610977985}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:43,359] Trial 152 finished with value: 0.10362595845173274 and parameters: {'depth': 10, 'learning_rate': 0.048256034546586696, 'lambda': 0.12994139173983177, 'alpha': 0.3947372131857044, 'subsample': 0.9317448324319232}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:47,115] Trial 153 finished with value: 0.10376650517460585 and parameters: {'depth': 10, 'learning_rate': 0.048490594905733035, 'lambda': 0.025361753717641246, 'alpha': 0.354142188668857, 'subsample': 0.8978297837837907}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:50,857] Trial 154 finished with value: 0.10334333403681349 and parameters: {'depth': 10, 'learning_rate': 0.04571691818652122, 'lambda': 0.0876417660355646, 'alpha': 0.4428011777529726, 'subsample': 0.9156142456749937}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:54,676] Trial 155 finished with value: 0.10361179984254307 and parameters: {'depth': 10, 'learning_rate': 0.04533929212650128, 'lambda': 0.09301058758032499, 'alpha': 0.45208900429234944, 'subsample': 0.9079879402185698}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:55,746] Trial 156 finished with value: 0.17787486585004508 and parameters: {'depth': 3, 'learning_rate': 0.043879871860949195, 'lambda': 0.15886943197349737, 'alpha': 0.4344727404946297, 'subsample': 0.8804887914717457}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:45:59,379] Trial 157 finished with value: 0.10375208548010957 and parameters: {'depth': 10, 'learning_rate': 0.04692096042102337, 'lambda': 0.1117984365258737, 'alpha': 0.41056323288384944, 'subsample': 0.9528307216420278}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:03,445] Trial 158 finished with value: 0.10394110354075015 and parameters: {'depth': 10, 'learning_rate': 0.04583011538325414, 'lambda': 0.3532962942816239, 'alpha': 0.40259181765621127, 'subsample': 0.9245789758320471}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:07,529] Trial 159 finished with value: 0.10426627106862543 and parameters: {'depth': 10, 'learning_rate': 0.04039765552363046, 'lambda': 0.20491898241666115, 'alpha': 0.4623274043316989, 'subsample': 0.8971687942372158}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:11,378] Trial 160 finished with value: 0.10474780488451439 and parameters: {'depth': 10, 'learning_rate': 0.03851521691661567, 'lambda': 0.1793509161512193, 'alpha': 0.33864783451263625, 'subsample': 0.9397616884119879}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:15,210] Trial 161 finished with value: 0.10408333222323533 and parameters: {'depth': 10, 'learning_rate': 0.04911049583922298, 'lambda': 0.06147711624618582, 'alpha': 0.3739263929905091, 'subsample': 0.9102800122101694}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:18,935] Trial 162 finished with value: 0.10386393625964321 and parameters: {'depth': 10, 'learning_rate': 0.047630308886265016, 'lambda': 0.08429732918134154, 'alpha': 0.3876142837156054, 'subsample': 0.9168908568547031}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:22,889] Trial 163 finished with value: 0.1521028914283819 and parameters: {'depth': 10, 'learning_rate': 0.01913652614034301, 'lambda': 0.12736479824799565, 'alpha': 0.35684750637279494, 'subsample': 0.9285825801951768}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:26,679] Trial 164 finished with value: 0.10372698177797705 and parameters: {'depth': 10, 'learning_rate': 0.049967815126213434, 'lambda': 0.041519070722571896, 'alpha': 0.4298668833284778, 'subsample': 0.889996276597354}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:30,361] Trial 165 finished with value: 0.10343839789057543 and parameters: {'depth': 10, 'learning_rate': 0.04834782216717557, 'lambda': 0.013033797023375135, 'alpha': 0.38317804220316454, 'subsample': 0.9175008951698274}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:34,170] Trial 166 finished with value: 0.1037430693821754 and parameters: {'depth': 10, 'learning_rate': 0.046550585159600734, 'lambda': 0.005241401570810163, 'alpha': 0.31778402326618016, 'subsample': 0.9029604996704321}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:37,939] Trial 167 finished with value: 0.10358531266626694 and parameters: {'depth': 10, 'learning_rate': 0.047635484326530184, 'lambda': 0.019767278518391874, 'alpha': 0.4098792276286233, 'subsample': 0.872861105778713}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:41,565] Trial 168 finished with value: 0.10387622744523585 and parameters: {'depth': 10, 'learning_rate': 0.0428405788233856, 'lambda': 0.018861175094812943, 'alpha': 0.4808724447308364, 'subsample': 0.8639782600154929}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:45,369] Trial 169 finished with value: 0.10392000998639109 and parameters: {'depth': 10, 'learning_rate': 0.04488894436949419, 'lambda': 0.03646552443489182, 'alpha': 0.4119255277763984, 'subsample': 0.8497994956539133}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:47,951] Trial 170 finished with value: 0.10954446532765474 and parameters: {'depth': 9, 'learning_rate': 0.04715838740309153, 'lambda': 0.02844619516337207, 'alpha': 0.4442558459895007, 'subsample': 0.8314094291815043}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:51,843] Trial 171 finished with value: 0.10399931334100189 and parameters: {'depth': 10, 'learning_rate': 0.04788898662042975, 'lambda': 0.009376649200373604, 'alpha': 0.367734153581339, 'subsample': 0.8843524493642886}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:55,611] Trial 172 finished with value: 0.10361546701394717 and parameters: {'depth': 10, 'learning_rate': 0.04913144743864534, 'lambda': 0.07907856031806001, 'alpha': 0.3937028694510922, 'subsample': 0.872478952587121}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:46:59,345] Trial 173 finished with value: 0.10402860337646982 and parameters: {'depth': 10, 'learning_rate': 0.04806652231469757, 'lambda': 0.14744953192399524, 'alpha': 0.354530965230344, 'subsample': 0.894111098466592}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:03,148] Trial 174 finished with value: 0.10389723117860239 and parameters: {'depth': 10, 'learning_rate': 0.045976827564282646, 'lambda': 0.10339149057840644, 'alpha': 0.42219509783551734, 'subsample': 0.8589001836400334}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:07,039] Trial 175 finished with value: 0.10397478261680893 and parameters: {'depth': 10, 'learning_rate': 0.047188624315004736, 'lambda': 0.4475670617273989, 'alpha': 0.33437512532321617, 'subsample': 0.9122229206600125}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:11,037] Trial 176 finished with value: 0.10448167122056248 and parameters: {'depth': 10, 'learning_rate': 0.037044596278774426, 'lambda': 0.1241597950857944, 'alpha': 0.3757866588337541, 'subsample': 0.9224492799783742}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:14,894] Trial 177 finished with value: 0.10345363032591742 and parameters: {'depth': 10, 'learning_rate': 0.04994629364732429, 'lambda': 0.051672972399068165, 'alpha': 0.3947367892784961, 'subsample': 0.9325872482945706}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:18,744] Trial 178 finished with value: 0.1033725889312992 and parameters: {'depth': 10, 'learning_rate': 0.049344861560366236, 'lambda': 0.06799284807609757, 'alpha': 0.4084542149846578, 'subsample': 0.9359352839473157}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:22,557] Trial 179 finished with value: 0.10376642243889195 and parameters: {'depth': 10, 'learning_rate': 0.049539877031252545, 'lambda': 0.05731182029651889, 'alpha': 0.43639966860046825, 'subsample': 0.947343763917019}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:26,651] Trial 180 finished with value: 0.10383041910184171 and parameters: {'depth': 10, 'learning_rate': 0.04917455906139995, 'lambda': 0.08027200477321211, 'alpha': 0.3957283285837003, 'subsample': 0.9349333426629317}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:30,750] Trial 181 finished with value: 0.1033432867165101 and parameters: {'depth': 10, 'learning_rate': 0.048327687929187055, 'lambda': 0.04580318434458934, 'alpha': 0.41065325483070575, 'subsample': 0.9572160764745796}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:34,628] Trial 182 finished with value: 0.10356054269969113 and parameters: {'depth': 10, 'learning_rate': 0.04981020465611647, 'lambda': 0.043400096532522886, 'alpha': 0.35423652855145715, 'subsample': 0.9522484211164469}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:38,384] Trial 183 finished with value: 0.1035247953256318 and parameters: {'depth': 10, 'learning_rate': 0.04957816014185894, 'lambda': 0.001134469103181629, 'alpha': 0.4175356641118126, 'subsample': 0.9621656396302417}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:42,166] Trial 184 finished with value: 0.10400227151106738 and parameters: {'depth': 10, 'learning_rate': 0.04992536896053762, 'lambda': 0.0470228053080387, 'alpha': 0.45923335613421595, 'subsample': 0.9652034084401447}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:45,874] Trial 185 finished with value: 0.10338925292684331 and parameters: {'depth': 10, 'learning_rate': 0.049947416198027415, 'lambda': 0.04115022521532369, 'alpha': 0.4207005007672401, 'subsample': 0.9904108042871895}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:49,724] Trial 186 finished with value: 0.10344212579994481 and parameters: {'depth': 10, 'learning_rate': 0.04999318549813588, 'lambda': 0.007683354809888281, 'alpha': 0.4228876019156705, 'subsample': 0.9916109109800761}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:53,472] Trial 187 finished with value: 0.10330383989817311 and parameters: {'depth': 10, 'learning_rate': 0.04995380872802051, 'lambda': 0.02369148762357411, 'alpha': 0.4231893961613749, 'subsample': 0.9929741320602409}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:47:57,459] Trial 188 finished with value: 0.1037321241790941 and parameters: {'depth': 10, 'learning_rate': 0.04995697398172699, 'lambda': 0.004328206960377647, 'alpha': 0.47428452967480944, 'subsample': 0.9891391839189706}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:01,467] Trial 189 finished with value: 0.103867257664448 and parameters: {'depth': 10, 'learning_rate': 0.04833806828303823, 'lambda': 0.002888072815819369, 'alpha': 0.4959404626699277, 'subsample': 0.9780991378111781}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:05,403] Trial 190 finished with value: 0.10418757176452775 and parameters: {'depth': 10, 'learning_rate': 0.04850048846080027, 'lambda': 0.034588019036323414, 'alpha': 0.4431547388377731, 'subsample': 0.9988423462707823}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:09,367] Trial 191 finished with value: 0.10352625330211827 and parameters: {'depth': 10, 'learning_rate': 0.049838396989341255, 'lambda': 0.029589719052771357, 'alpha': 0.4189163076344519, 'subsample': 0.9596626163124999}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:13,324] Trial 192 finished with value: 0.10390336627265356 and parameters: {'depth': 10, 'learning_rate': 0.049052903965825304, 'lambda': 0.024701862625921014, 'alpha': 0.4247321609383104, 'subsample': 0.974226923738681}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:17,337] Trial 193 finished with value: 0.10353175642226073 and parameters: {'depth': 10, 'learning_rate': 0.049898456234737806, 'lambda': 0.05289541717706285, 'alpha': 0.4208110320846685, 'subsample': 0.9584675782882485}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:21,317] Trial 194 finished with value: 0.10387657079940361 and parameters: {'depth': 10, 'learning_rate': 0.048478977468393615, 'lambda': 0.00030500419996230127, 'alpha': 0.4533577846720175, 'subsample': 0.9608346695205879}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:25,134] Trial 195 finished with value: 0.10385419534345182 and parameters: {'depth': 10, 'learning_rate': 0.0497150026219463, 'lambda': 0.0587093192862633, 'alpha': 0.42906589092915215, 'subsample': 0.9738757520990926}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:29,054] Trial 196 finished with value: 0.10512738451005828 and parameters: {'depth': 10, 'learning_rate': 0.034808790148984796, 'lambda': 0.023925415386107957, 'alpha': 0.40879218236393133, 'subsample': 0.9844417247224877}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:32,871] Trial 197 finished with value: 0.10371726722616667 and parameters: {'depth': 10, 'learning_rate': 0.04991714642137039, 'lambda': 0.05454346207998627, 'alpha': 0.4184291347145044, 'subsample': 0.968423088184107}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:36,648] Trial 198 finished with value: 0.10365637462100065 and parameters: {'depth': 10, 'learning_rate': 0.046780582788461665, 'lambda': 0.041928571893897815, 'alpha': 0.4714977618094446, 'subsample': 0.9584201950688079}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:40,638] Trial 199 finished with value: 0.11200316738480566 and parameters: {'depth': 10, 'learning_rate': 0.027071632720132723, 'lambda': 0.0718051083362977, 'alpha': 0.39847420019594937, 'subsample': 0.999951966347555}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:44,373] Trial 200 finished with value: 0.10377337043744746 and parameters: {'depth': 10, 'learning_rate': 0.04814247827245273, 'lambda': 0.023417821043799303, 'alpha': 0.43681911964471426, 'subsample': 0.9907953947703467}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:48,328] Trial 201 finished with value: 0.10352447233144953 and parameters: {'depth': 10, 'learning_rate': 0.04903928487438217, 'lambda': 0.06445297338170317, 'alpha': 0.3920647607117412, 'subsample': 0.9782299678364037}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:52,235] Trial 202 finished with value: 0.10384421113718341 and parameters: {'depth': 10, 'learning_rate': 0.04889119336235854, 'lambda': 0.06684871817039903, 'alpha': 0.4002063605055622, 'subsample': 0.9730957116099116}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:55,942] Trial 203 finished with value: 0.10361635511117873 and parameters: {'depth': 10, 'learning_rate': 0.04720344142107451, 'lambda': 0.04129810308617656, 'alpha': 0.4216277924729903, 'subsample': 0.9839569589663347}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:48:59,777] Trial 204 finished with value: 0.10342643129759292 and parameters: {'depth': 10, 'learning_rate': 0.04993803897134258, 'lambda': 0.017378228054968622, 'alpha': 0.4495304768319361, 'subsample': 0.9588256632235976}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:03,797] Trial 205 finished with value: 0.1037243086246574 and parameters: {'depth': 10, 'learning_rate': 0.049307847516909635, 'lambda': 0.017669434673909423, 'alpha': 0.4503987810614297, 'subsample': 0.9618317006673269}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:07,682] Trial 206 finished with value: 0.10359097472563002 and parameters: {'depth': 10, 'learning_rate': 0.047842776822163716, 'lambda': 0.04715887808972194, 'alpha': 0.38606814765255604, 'subsample': 0.9793652830165592}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:11,788] Trial 207 finished with value: 0.10376991973983594 and parameters: {'depth': 10, 'learning_rate': 0.04991895837908229, 'lambda': 0.025456827053018626, 'alpha': 0.4034581317393662, 'subsample': 0.9544644790806395}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:15,899] Trial 208 finished with value: 0.10378722003148527 and parameters: {'depth': 10, 'learning_rate': 0.04644555006295848, 'lambda': 0.003908894099918195, 'alpha': 0.4464459891451675, 'subsample': 0.9674342693765834}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:20,031] Trial 209 finished with value: 0.1035974499445396 and parameters: {'depth': 10, 'learning_rate': 0.048630913132207014, 'lambda': 0.07360347069516229, 'alpha': 0.4919583911106708, 'subsample': 0.9429296317677061}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:21,619] Trial 210 finished with value: 0.12955039629225587 and parameters: {'depth': 6, 'learning_rate': 0.04783236359609859, 'lambda': 0.03840223726051918, 'alpha': 0.4696674470459504, 'subsample': 0.9904628818518522}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:25,722] Trial 211 finished with value: 0.10340012612519449 and parameters: {'depth': 10, 'learning_rate': 0.049994516839576605, 'lambda': 0.05962133881760642, 'alpha': 0.423841651032877, 'subsample': 0.9807149747880445}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:29,802] Trial 212 finished with value: 0.10353116215242156 and parameters: {'depth': 10, 'learning_rate': 0.04988274185260979, 'lambda': 0.0005829172172353717, 'alpha': 0.4144669455147897, 'subsample': 0.9774553182860172}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:33,953] Trial 213 finished with value: 0.10341059194989365 and parameters: {'depth': 10, 'learning_rate': 0.049996192176562, 'lambda': 0.01762000467212404, 'alpha': 0.42785221332383105, 'subsample': 0.9817994008510689}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:38,131] Trial 214 finished with value: 0.10366098077001093 and parameters: {'depth': 10, 'learning_rate': 0.04908101266467255, 'lambda': 0.012099193619080045, 'alpha': 0.4402791304255758, 'subsample': 0.9789209571775677}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:39,513] Trial 215 finished with value: 0.1405894831424349 and parameters: {'depth': 5, 'learning_rate': 0.03955869833361946, 'lambda': 0.01966889981309758, 'alpha': 0.4061580961358661, 'subsample': 0.992036631508423}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:43,707] Trial 216 finished with value: 0.10359319944711949 and parameters: {'depth': 10, 'learning_rate': 0.049004602424438395, 'lambda': 0.029906429350080505, 'alpha': 0.3887330296216018, 'subsample': 0.9791905460344034}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:47,837] Trial 217 finished with value: 0.10372217945929788 and parameters: {'depth': 10, 'learning_rate': 0.049880989574111516, 'lambda': 0.0016301148079654534, 'alpha': 0.4529940162494903, 'subsample': 0.9706952620364171}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:51,845] Trial 218 finished with value: 0.10381768970262159 and parameters: {'depth': 10, 'learning_rate': 0.048046005860472335, 'lambda': 0.0626826455282701, 'alpha': 0.42748973318836003, 'subsample': 0.9880431666049893}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:49:55,926] Trial 219 finished with value: 0.10392689344061982 and parameters: {'depth': 10, 'learning_rate': 0.04861022420229052, 'lambda': 0.03376646332525967, 'alpha': 0.51434808176961, 'subsample': 0.9960589437543318}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:00,063] Trial 220 finished with value: 0.10359351181300006 and parameters: {'depth': 10, 'learning_rate': 0.0499461795707051, 'lambda': 0.052236797681600236, 'alpha': 0.40944944673451444, 'subsample': 0.982875159513916}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:04,239] Trial 221 finished with value: 0.10332454860937548 and parameters: {'depth': 10, 'learning_rate': 0.04909994703000336, 'lambda': 0.05425751887256685, 'alpha': 0.42282365982599973, 'subsample': 0.9572720984402876}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:08,528] Trial 222 finished with value: 0.1036653351522079 and parameters: {'depth': 10, 'learning_rate': 0.04878810620080417, 'lambda': 0.0023196976607185414, 'alpha': 0.388987170400334, 'subsample': 0.9700273601227063}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:12,556] Trial 223 finished with value: 0.10374077998228333 and parameters: {'depth': 10, 'learning_rate': 0.047321572406848304, 'lambda': 0.028901313384054016, 'alpha': 0.43736153976452374, 'subsample': 0.9505405919403009}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:16,476] Trial 224 finished with value: 0.10416173768977068 and parameters: {'depth': 10, 'learning_rate': 0.04998816288154293, 'lambda': 0.07920194393765695, 'alpha': 0.41501922846556, 'subsample': 0.9995877686360917}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:20,154] Trial 225 finished with value: 0.10648575121239813 and parameters: {'depth': 10, 'learning_rate': 0.03172680765437224, 'lambda': 0.5546234959782359, 'alpha': 0.46260015841266106, 'subsample': 0.9640774495510143}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:23,825] Trial 226 finished with value: 0.10351124526326891 and parameters: {'depth': 10, 'learning_rate': 0.04809519176076795, 'lambda': 0.04956370218166228, 'alpha': 0.37098855702837086, 'subsample': 0.9835370365417896}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:27,598] Trial 227 finished with value: 0.10375949439328915 and parameters: {'depth': 10, 'learning_rate': 0.0476111107514505, 'lambda': 0.06412987512522479, 'alpha': 0.36875509150462976, 'subsample': 0.9569204410032215}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:31,438] Trial 228 finished with value: 0.10381143615160342 and parameters: {'depth': 10, 'learning_rate': 0.048455322903834475, 'lambda': 0.04518595543897083, 'alpha': 0.3891160403906859, 'subsample': 0.9837326734350612}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:35,202] Trial 229 finished with value: 0.10374782204460258 and parameters: {'depth': 10, 'learning_rate': 0.04686663920712973, 'lambda': 0.08843157254906837, 'alpha': 0.36067549027713686, 'subsample': 0.9367136110938279}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:38,841] Trial 230 finished with value: 0.10388343854197342 and parameters: {'depth': 10, 'learning_rate': 0.048948079814482424, 'lambda': 0.05913107145938058, 'alpha': 0.906526424474242, 'subsample': 0.9887507316350298}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:42,600] Trial 231 finished with value: 0.10364074764856503 and parameters: {'depth': 10, 'learning_rate': 0.04910723762825265, 'lambda': 0.024842740717197952, 'alpha': 0.4015859868906904, 'subsample': 0.976442954325435}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:46,403] Trial 232 finished with value: 0.1036006016559343 and parameters: {'depth': 10, 'learning_rate': 0.047831601972064604, 'lambda': 0.0010735028119306794, 'alpha': 0.4306938995036145, 'subsample': 0.9664925765528951}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:50,289] Trial 233 finished with value: 0.10347316845748113 and parameters: {'depth': 10, 'learning_rate': 0.049874949578524494, 'lambda': 0.03949319455305497, 'alpha': 0.3821517051280228, 'subsample': 0.9479132110917249}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:54,261] Trial 234 finished with value: 0.10341093486787671 and parameters: {'depth': 10, 'learning_rate': 0.049008514924396174, 'lambda': 0.041396864960423406, 'alpha': 0.3779504951715997, 'subsample': 0.9385581265060574}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:50:58,115] Trial 235 finished with value: 0.10348164793883552 and parameters: {'depth': 10, 'learning_rate': 0.048412356948557986, 'lambda': 0.07942042754474607, 'alpha': 0.3756871405207138, 'subsample': 0.9455874332610941}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:02,116] Trial 236 finished with value: 0.10369517279401473 and parameters: {'depth': 10, 'learning_rate': 0.04634961216366764, 'lambda': 0.07759401280443834, 'alpha': 0.3660857634657943, 'subsample': 0.9440266230263656}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:06,079] Trial 237 finished with value: 0.10453334957403604 and parameters: {'depth': 10, 'learning_rate': 0.03584689080605779, 'lambda': 0.09495580280344847, 'alpha': 0.34929559596720056, 'subsample': 0.9448093875098729}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:10,014] Trial 238 finished with value: 0.10350710868736152 and parameters: {'depth': 10, 'learning_rate': 0.04815304433050897, 'lambda': 0.05239488211349611, 'alpha': 0.3792667964175166, 'subsample': 0.9310416529111224}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:13,943] Trial 239 finished with value: 0.1038470078555044 and parameters: {'depth': 10, 'learning_rate': 0.0475406336229185, 'lambda': 0.05021890966783186, 'alpha': 0.36687927417923727, 'subsample': 0.9322943906412016}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:17,801] Trial 240 finished with value: 0.10347368502392496 and parameters: {'depth': 10, 'learning_rate': 0.048277807602290494, 'lambda': 0.08400499271421968, 'alpha': 0.33007295326819125, 'subsample': 0.9318873027858541}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:21,660] Trial 241 finished with value: 0.10524547540754618 and parameters: {'depth': 10, 'learning_rate': 0.03362000041415133, 'lambda': 0.08550020264744194, 'alpha': 0.32822450844437046, 'subsample': 0.9373602027101664}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:25,671] Trial 242 finished with value: 0.10700951763973443 and parameters: {'depth': 10, 'learning_rate': 0.03068940883859135, 'lambda': 0.043853756057089424, 'alpha': 0.34995775895300135, 'subsample': 0.9278675421841807}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:29,365] Trial 243 finished with value: 0.10406664694879628 and parameters: {'depth': 10, 'learning_rate': 0.04822816601799661, 'lambda': 0.07153669209912403, 'alpha': 0.3823867647607512, 'subsample': 0.9480334910974784}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:33,181] Trial 244 finished with value: 0.10358408490584436 and parameters: {'depth': 10, 'learning_rate': 0.04698368668861018, 'lambda': 0.10681225393986815, 'alpha': 0.30929932918928643, 'subsample': 0.9314073267068447}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:37,129] Trial 245 finished with value: 0.10373590402539497 and parameters: {'depth': 10, 'learning_rate': 0.04852839502582075, 'lambda': 0.04575252008855846, 'alpha': 0.33722044323384776, 'subsample': 0.940888679427386}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:40,998] Trial 246 finished with value: 0.10355264728653557 and parameters: {'depth': 10, 'learning_rate': 0.047920567501335866, 'lambda': 0.35241434356178164, 'alpha': 0.37240067638123364, 'subsample': 0.9224866759835669}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:44,753] Trial 247 finished with value: 0.31749993030910517 and parameters: {'depth': 10, 'learning_rate': 0.010932315808217134, 'lambda': 0.714946093539627, 'alpha': 0.3785290155345539, 'subsample': 0.9502435592154007}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:46,932] Trial 248 finished with value: 0.5659832778195713 and parameters: {'depth': 8, 'learning_rate': 0.005380487021701526, 'lambda': 0.29577822035586443, 'alpha': 0.3529337318817469, 'subsample': 0.9296783385056122}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:50,479] Trial 249 finished with value: 0.10409441072114967 and parameters: {'depth': 10, 'learning_rate': 0.04546196981687103, 'lambda': 0.6508786782709757, 'alpha': 0.10543450843958702, 'subsample': 0.7174532696550951}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:54,524] Trial 250 finished with value: 0.10854422980338693 and parameters: {'depth': 10, 'learning_rate': 0.028954416810771315, 'lambda': 0.07170988582698826, 'alpha': 0.3228388102966442, 'subsample': 0.8052312124155246}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:51:58,404] Trial 251 finished with value: 0.10382440821940296 and parameters: {'depth': 10, 'learning_rate': 0.046559783374479705, 'lambda': 0.09087246732366722, 'alpha': 0.39110224199111565, 'subsample': 0.9387628588554523}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:02,202] Trial 252 finished with value: 0.10328521241806587 and parameters: {'depth': 10, 'learning_rate': 0.04875849657884895, 'lambda': 0.0349864303711022, 'alpha': 0.3680706338509326, 'subsample': 0.9170686586180972}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:07,259] Trial 253 finished with value: 0.10338080053878652 and parameters: {'depth': 10, 'learning_rate': 0.04884478179542724, 'lambda': 0.03448740291061158, 'alpha': 0.2969373604932818, 'subsample': 0.9225082940208479}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:11,409] Trial 254 finished with value: 0.10379542247181929 and parameters: {'depth': 10, 'learning_rate': 0.04881768372403514, 'lambda': 0.023847244941643968, 'alpha': 0.2980049925264586, 'subsample': 0.9234902794378504}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:15,086] Trial 255 finished with value: 0.10359910083542245 and parameters: {'depth': 10, 'learning_rate': 0.049950580764783536, 'lambda': 0.03458299629188591, 'alpha': 0.02756817113879917, 'subsample': 0.9195119967437901}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:18,864] Trial 256 finished with value: 0.10369083229855935 and parameters: {'depth': 10, 'learning_rate': 0.04892975332633352, 'lambda': 0.0609074576177732, 'alpha': 0.27186722665371166, 'subsample': 0.7695290173781412}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:22,685] Trial 257 finished with value: 0.10361250644177485 and parameters: {'depth': 10, 'learning_rate': 0.04897510971455235, 'lambda': 0.02298319621440236, 'alpha': 0.31466894123457473, 'subsample': 0.9520288694834015}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:26,487] Trial 258 finished with value: 0.10373677431379577 and parameters: {'depth': 10, 'learning_rate': 0.047806531117381264, 'lambda': 0.0418525973081834, 'alpha': 0.24734175999097974, 'subsample': 0.9325970784043642}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:28,171] Trial 259 finished with value: 0.14962267233846638 and parameters: {'depth': 7, 'learning_rate': 0.0202055037969285, 'lambda': 0.4656849172572366, 'alpha': 0.2779420324308001, 'subsample': 0.7411470586801518}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:31,761] Trial 260 finished with value: 0.10333798761787862 and parameters: {'depth': 10, 'learning_rate': 0.04999723224341761, 'lambda': 0.06758155354432713, 'alpha': 0.40109578766475823, 'subsample': 0.9144975917296174}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:35,470] Trial 261 finished with value: 0.10361071111795374 and parameters: {'depth': 10, 'learning_rate': 0.049290661650268235, 'lambda': 0.09444905332852767, 'alpha': 0.2322101232238502, 'subsample': 0.9070372610835056}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:38,127] Trial 262 finished with value: 0.10967373446286548 and parameters: {'depth': 9, 'learning_rate': 0.049142951716574124, 'lambda': 0.07843371981179137, 'alpha': 0.40077038370610124, 'subsample': 0.9162284878675104}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:41,907] Trial 263 finished with value: 0.10375308891013688 and parameters: {'depth': 10, 'learning_rate': 0.049878381875160124, 'lambda': 0.11501564063188413, 'alpha': 0.4440128703091925, 'subsample': 0.9218459852062774}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:45,567] Trial 264 finished with value: 0.10340123063797425 and parameters: {'depth': 10, 'learning_rate': 0.04992698689102838, 'lambda': 0.021615298496437115, 'alpha': 0.2934370391127844, 'subsample': 0.9419623333321492}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:49,520] Trial 265 finished with value: 0.10427446189421324 and parameters: {'depth': 10, 'learning_rate': 0.03837631188144075, 'lambda': 0.018488758517896657, 'alpha': 0.4824155504255159, 'subsample': 0.9126205987865089}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:53,446] Trial 266 finished with value: 0.1036007909811504 and parameters: {'depth': 10, 'learning_rate': 0.04989105811634241, 'lambda': 0.01902585934920028, 'alpha': 0.3334631866170919, 'subsample': 0.9368353236225956}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:52:57,272] Trial 267 finished with value: 0.10343864781290721 and parameters: {'depth': 10, 'learning_rate': 0.04998008625372898, 'lambda': 0.03596940156489171, 'alpha': 0.27963040592660215, 'subsample': 0.7924053518710859}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:01,014] Trial 268 finished with value: 0.10421091790452011 and parameters: {'depth': 10, 'learning_rate': 0.042003654349946754, 'lambda': 0.03167728164326988, 'alpha': 0.3045516473160058, 'subsample': 0.7731568571118959}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:04,814] Trial 269 finished with value: 0.10490384437098463 and parameters: {'depth': 10, 'learning_rate': 0.03751137878499177, 'lambda': 0.05958302230567837, 'alpha': 0.2756232186160575, 'subsample': 0.7944007886611248}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:08,529] Trial 270 finished with value: 0.10454057802299833 and parameters: {'depth': 10, 'learning_rate': 0.04990421761372649, 'lambda': 0.4369553530297968, 'alpha': 0.28365842620815473, 'subsample': 0.6668060582237352}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:12,383] Trial 271 finished with value: 0.10467654941047332 and parameters: {'depth': 10, 'learning_rate': 0.048850268657851366, 'lambda': 0.5025206705981843, 'alpha': 0.2550849420045208, 'subsample': 0.7028408155595153}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:16,093] Trial 272 finished with value: 0.10454300800926146 and parameters: {'depth': 10, 'learning_rate': 0.049961389864179084, 'lambda': 0.03776352721046942, 'alpha': 0.29270851220527944, 'subsample': 0.6182992132368588}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:20,053] Trial 273 finished with value: 0.10361631990352456 and parameters: {'depth': 10, 'learning_rate': 0.0475140350874085, 'lambda': 0.020280549636340933, 'alpha': 0.20958279040968364, 'subsample': 0.9985872878923945}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:23,793] Trial 274 finished with value: 0.10401792454198656 and parameters: {'depth': 10, 'learning_rate': 0.048829525282084695, 'lambda': 0.3256795636980035, 'alpha': 0.25734965664070325, 'subsample': 0.9458963025660547}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:27,580] Trial 275 finished with value: 0.10359873492625611 and parameters: {'depth': 10, 'learning_rate': 0.047340933085237576, 'lambda': 0.06072293335759457, 'alpha': 0.3084468513791192, 'subsample': 0.9559903814700741}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:31,538] Trial 276 finished with value: 0.10418048151951083 and parameters: {'depth': 10, 'learning_rate': 0.039975130942268434, 'lambda': 0.040820843266481645, 'alpha': 0.3449461401083703, 'subsample': 0.9251588826629698}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:34,268] Trial 277 finished with value: 0.1098475878626762 and parameters: {'depth': 9, 'learning_rate': 0.049941637648730816, 'lambda': 0.01771736317212251, 'alpha': 0.6204122543271999, 'subsample': 0.9119011204083377}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:37,765] Trial 278 finished with value: 0.10450242294650797 and parameters: {'depth': 10, 'learning_rate': 0.04818057166202285, 'lambda': 0.2632837707412067, 'alpha': 0.2919161673687337, 'subsample': 0.5805777420328181}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:41,381] Trial 279 finished with value: 0.10458666585653006 and parameters: {'depth': 10, 'learning_rate': 0.04606216708660295, 'lambda': 0.8125925331184037, 'alpha': 0.42999137021085665, 'subsample': 0.8295917901848622}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:44,860] Trial 280 finished with value: 0.10450080586835779 and parameters: {'depth': 10, 'learning_rate': 0.04896469965963041, 'lambda': 0.9197351226433454, 'alpha': 0.4480645756729816, 'subsample': 0.788126404375322}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:48,609] Trial 281 finished with value: 0.10422778578016226 and parameters: {'depth': 10, 'learning_rate': 0.04702323281550269, 'lambda': 0.10502045544869362, 'alpha': 0.3184866690966337, 'subsample': 0.8361924243929052}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:52,480] Trial 282 finished with value: 0.2648207238351198 and parameters: {'depth': 10, 'learning_rate': 0.012703777601955818, 'lambda': 0.07372454813673157, 'alpha': 0.46571347927982265, 'subsample': 0.8052457331643957}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:53:56,308] Trial 283 finished with value: 0.1038273763513259 and parameters: {'depth': 10, 'learning_rate': 0.04899041569136528, 'lambda': 0.05183412087154947, 'alpha': 0.40950134818866035, 'subsample': 0.817595549533544}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:00,084] Trial 284 finished with value: 0.10390076660245949 and parameters: {'depth': 10, 'learning_rate': 0.04829501984414638, 'lambda': 0.5961775979815035, 'alpha': 0.33577088928691734, 'subsample': 0.7346762471893683}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:03,864] Trial 285 finished with value: 0.10390586856299733 and parameters: {'depth': 10, 'learning_rate': 0.04997936406119743, 'lambda': 0.018450232614301555, 'alpha': 0.5289247029108448, 'subsample': 0.6924621286695748}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:06,781] Trial 286 finished with value: 0.1260711401113328 and parameters: {'depth': 9, 'learning_rate': 0.02325520939256927, 'lambda': 0.1308253257361447, 'alpha': 0.49996546309585316, 'subsample': 0.96735624494321}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:10,758] Trial 287 finished with value: 0.10398767678205197 and parameters: {'depth': 10, 'learning_rate': 0.047590100499642324, 'lambda': 0.068374734727082, 'alpha': 0.7359359573494983, 'subsample': 0.9362971281574555}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:14,482] Trial 288 finished with value: 0.10384326606133924 and parameters: {'depth': 10, 'learning_rate': 0.048953976511720156, 'lambda': 0.04034630608231171, 'alpha': 0.3984317929968101, 'subsample': 0.9585409366536817}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:18,350] Trial 289 finished with value: 0.10409004194193294 and parameters: {'depth': 10, 'learning_rate': 0.04341458146189637, 'lambda': 0.09539437672527235, 'alpha': 0.4199881707048324, 'subsample': 0.9900239728490997}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:22,154] Trial 290 finished with value: 0.10448765474534634 and parameters: {'depth': 10, 'learning_rate': 0.04624141265797217, 'lambda': 0.003412917255797076, 'alpha': 0.35947459202117654, 'subsample': 0.7640040043901617}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:25,822] Trial 291 finished with value: 0.10396315906796075 and parameters: {'depth': 10, 'learning_rate': 0.044845752247027686, 'lambda': 0.05687993593850861, 'alpha': 0.2717099020725336, 'subsample': 0.9047577054038265}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:28,600] Trial 292 finished with value: 0.10998532576632977 and parameters: {'depth': 9, 'learning_rate': 0.04163245892373048, 'lambda': 0.03757896176857528, 'alpha': 0.1791353564209294, 'subsample': 0.8210086161534456}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:32,326] Trial 293 finished with value: 0.10370099596135215 and parameters: {'depth': 10, 'learning_rate': 0.04806970407194237, 'lambda': 0.07686609125122697, 'alpha': 0.43176734853021465, 'subsample': 0.9445917613106228}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:36,037] Trial 294 finished with value: 0.1046175728425799 and parameters: {'depth': 10, 'learning_rate': 0.039581060930494794, 'lambda': 0.42050206522090194, 'alpha': 0.395033521940403, 'subsample': 0.7590514524471988}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:39,739] Trial 295 finished with value: 0.10400921560595239 and parameters: {'depth': 10, 'learning_rate': 0.04112332278849017, 'lambda': 0.1162183696241717, 'alpha': 0.4566952579196549, 'subsample': 0.9252390547599308}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:43,618] Trial 296 finished with value: 0.10343752327885047 and parameters: {'depth': 10, 'learning_rate': 0.04916901087390998, 'lambda': 0.017870187455955568, 'alpha': 0.34471085835386317, 'subsample': 0.9728362459275938}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:47,288] Trial 297 finished with value: 0.1033531241212113 and parameters: {'depth': 10, 'learning_rate': 0.04990203810318871, 'lambda': 0.014253607699516523, 'alpha': 0.35364619187088886, 'subsample': 0.9746240061428494}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:51,176] Trial 298 finished with value: 0.10360430211365533 and parameters: {'depth': 10, 'learning_rate': 0.04999549274592653, 'lambda': 0.01530724015908273, 'alpha': 0.3504487208172127, 'subsample': 0.9745607667611281}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:55,029] Trial 299 finished with value: 0.10494424666071683 and parameters: {'depth': 10, 'learning_rate': 0.03522078005727762, 'lambda': 0.021876169679295385, 'alpha': 0.3045742969220372, 'subsample': 0.9919414273804096}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:54:58,831] Trial 300 finished with value: 0.1036645247560978 and parameters: {'depth': 10, 'learning_rate': 0.04894847789458012, 'lambda': 0.008290535193940437, 'alpha': 0.47338237251076487, 'subsample': 0.9700931632093255}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:02,753] Trial 301 finished with value: 0.10484053120693529 and parameters: {'depth': 10, 'learning_rate': 0.03702954869594374, 'lambda': 0.003011291965009686, 'alpha': 0.4078225379725302, 'subsample': 0.9770531459517472}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:04,084] Trial 302 finished with value: 0.14023184243200462 and parameters: {'depth': 5, 'learning_rate': 0.047067473107485394, 'lambda': 0.03072905136719039, 'alpha': 0.4405178523809334, 'subsample': 0.9862319952117595}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:05,795] Trial 303 finished with value: 0.12452558942075442 and parameters: {'depth': 7, 'learning_rate': 0.028291358812929462, 'lambda': 0.053703233101601695, 'alpha': 0.32464143273837376, 'subsample': 0.7794011735657616}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:09,691] Trial 304 finished with value: 0.10381848078192592 and parameters: {'depth': 10, 'learning_rate': 0.04906131021264436, 'lambda': 0.03490024836469073, 'alpha': 0.3513834991226175, 'subsample': 0.9607554322819912}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:13,619] Trial 305 finished with value: 0.10551594008696616 and parameters: {'depth': 10, 'learning_rate': 0.03339509920338639, 'lambda': 0.003732178631237454, 'alpha': 0.3799738987680991, 'subsample': 0.9998374425978933}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:17,613] Trial 306 finished with value: 0.18045013488691378 and parameters: {'depth': 10, 'learning_rate': 0.01684592597059426, 'lambda': 0.05764405830389835, 'alpha': 0.12969855158295585, 'subsample': 0.9684084929866814}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:21,431] Trial 307 finished with value: 0.10419871996343973 and parameters: {'depth': 10, 'learning_rate': 0.04787211126208709, 'lambda': 0.022018127310326274, 'alpha': 0.42039276099799205, 'subsample': 0.7452075572775736}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:25,350] Trial 308 finished with value: 0.10575260434328697 and parameters: {'depth': 10, 'learning_rate': 0.03264137718988512, 'lambda': 0.00016986944697254362, 'alpha': 0.3625315770551563, 'subsample': 0.9152859060340017}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:28,137] Trial 309 finished with value: 0.11006503836817672 and parameters: {'depth': 9, 'learning_rate': 0.04998391882964094, 'lambda': 0.38754967123452955, 'alpha': 0.3985599221213211, 'subsample': 0.9842017969609562}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:31,908] Trial 310 finished with value: 0.10375575904578625 and parameters: {'depth': 10, 'learning_rate': 0.048891289442933056, 'lambda': 0.23214063087113895, 'alpha': 0.0664669495271556, 'subsample': 0.955344487392362}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:35,722] Trial 311 finished with value: 0.10357344591161288 and parameters: {'depth': 10, 'learning_rate': 0.047117937484874424, 'lambda': 0.043159499503388904, 'alpha': 0.2981816915736289, 'subsample': 0.917573550827261}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:39,484] Trial 312 finished with value: 0.10508979845116927 and parameters: {'depth': 10, 'learning_rate': 0.03633207730612761, 'lambda': 0.30216573379411593, 'alpha': 0.43543307398400855, 'subsample': 0.7557175903015277}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:43,273] Trial 313 finished with value: 0.10419697089442105 and parameters: {'depth': 10, 'learning_rate': 0.045815691810245626, 'lambda': 0.3367058489469331, 'alpha': 0.2377745791976634, 'subsample': 0.9039710038035623}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:47,117] Trial 314 finished with value: 0.10402821129704629 and parameters: {'depth': 10, 'learning_rate': 0.04813962686095525, 'lambda': 0.06414013210496584, 'alpha': 0.9547806229870387, 'subsample': 0.8451530030400184}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:51,161] Trial 315 finished with value: 0.11541181208314348 and parameters: {'depth': 10, 'learning_rate': 0.02550279652345987, 'lambda': 0.09550851554093225, 'alpha': 0.5534110593827191, 'subsample': 0.9774511858049415}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:53,269] Trial 316 finished with value: 0.11672966410967632 and parameters: {'depth': 8, 'learning_rate': 0.03076281628684025, 'lambda': 0.1318304022620406, 'alpha': 0.3462262341798322, 'subsample': 0.9668871890816544}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:55:57,318] Trial 317 finished with value: 0.3696548007526603 and parameters: {'depth': 10, 'learning_rate': 0.009474585845957874, 'lambda': 0.028391165653934153, 'alpha': 0.2643736238174719, 'subsample': 0.8546329466475951}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:01,254] Trial 318 finished with value: 0.105324912515259 and parameters: {'depth': 10, 'learning_rate': 0.03407160832230261, 'lambda': 0.050889675330896264, 'alpha': 0.38251900628788915, 'subsample': 0.9911110019599386}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:02,428] Trial 319 finished with value: 0.15490974335474064 and parameters: {'depth': 4, 'learning_rate': 0.04907770998419203, 'lambda': 0.07639039080525076, 'alpha': 0.32753810324971466, 'subsample': 0.7128549054592893}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:06,310] Trial 320 finished with value: 0.10485605087357933 and parameters: {'depth': 10, 'learning_rate': 0.039216288153443975, 'lambda': 0.10920753721494453, 'alpha': 0.41073084621765327, 'subsample': 0.6309899311512215}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:09,906] Trial 321 finished with value: 0.1037495887633675 and parameters: {'depth': 10, 'learning_rate': 0.049930369743815595, 'lambda': 0.2889790274300411, 'alpha': 0.4590750174560653, 'subsample': 0.8049725312619288}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:13,763] Trial 322 finished with value: 0.10353918868099411 and parameters: {'depth': 10, 'learning_rate': 0.048111599801825625, 'lambda': 0.0294711071930523, 'alpha': 0.2877448206049017, 'subsample': 0.9393789536253698}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:17,451] Trial 323 finished with value: 0.1039782457519094 and parameters: {'depth': 10, 'learning_rate': 0.046820367924503704, 'lambda': 0.14828160682551417, 'alpha': 0.48665182749874736, 'subsample': 0.7786919061245303}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:20,096] Trial 324 finished with value: 0.10970517633235971 and parameters: {'depth': 9, 'learning_rate': 0.049997872654675674, 'lambda': 0.0206756743815718, 'alpha': 0.42455186260916217, 'subsample': 0.9097845668387025}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:21,200] Trial 325 finished with value: 0.17771320036228833 and parameters: {'depth': 3, 'learning_rate': 0.04894867018787911, 'lambda': 0.06669180922682243, 'alpha': 0.3676560349503689, 'subsample': 0.8122182760531352}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:24,908] Trial 326 finished with value: 0.1043115106150969 and parameters: {'depth': 10, 'learning_rate': 0.04419768999681808, 'lambda': 0.5219448748710886, 'alpha': 0.3979348001096465, 'subsample': 0.8988273898197574}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:28,741] Trial 327 finished with value: 0.10595977927031035 and parameters: {'depth': 10, 'learning_rate': 0.03273260466208269, 'lambda': 0.04598430811381879, 'alpha': 0.44806756678392134, 'subsample': 0.7943703935609473}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:32,505] Trial 328 finished with value: 0.10419077826626859 and parameters: {'depth': 10, 'learning_rate': 0.04748755714940437, 'lambda': 0.672140783901166, 'alpha': 0.3122685006947111, 'subsample': 0.9551645908626375}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:36,137] Trial 329 finished with value: 0.10346667484032394 and parameters: {'depth': 10, 'learning_rate': 0.048970062528604044, 'lambda': 0.0916496340546655, 'alpha': 0.33795559217070703, 'subsample': 0.9246510514741307}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:39,979] Trial 330 finished with value: 0.10531180746684599 and parameters: {'depth': 10, 'learning_rate': 0.034697525418655235, 'lambda': 0.018956723803182814, 'alpha': 0.3825300167284968, 'subsample': 0.9797163222932446}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:43,549] Trial 331 finished with value: 0.10409357894673851 and parameters: {'depth': 10, 'learning_rate': 0.045961437228669945, 'lambda': 0.2660147818383638, 'alpha': 0.35867836398047587, 'subsample': 0.7280159147997162}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:47,323] Trial 332 finished with value: 0.10437082440784166 and parameters: {'depth': 10, 'learning_rate': 0.04258576709901671, 'lambda': 0.043959956699804376, 'alpha': 0.22059383650874698, 'subsample': 0.7223956224766714}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:51,104] Trial 333 finished with value: 0.10369312611750911 and parameters: {'depth': 10, 'learning_rate': 0.04832649097843579, 'lambda': 0.18025686316653386, 'alpha': 0.5346151097113009, 'subsample': 0.9313772490286546}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:55,061] Trial 334 finished with value: 0.10334469864765214 and parameters: {'depth': 10, 'learning_rate': 0.04998271124302894, 'lambda': 0.06746749392234865, 'alpha': 0.412686623886274, 'subsample': 0.964592557244803}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:56:59,209] Trial 335 finished with value: 0.10410882222574573 and parameters: {'depth': 10, 'learning_rate': 0.04754559401810092, 'lambda': 0.3612648645451657, 'alpha': 0.5010830502044419, 'subsample': 0.9662609399772772}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:03,168] Trial 336 finished with value: 0.10371497687750704 and parameters: {'depth': 10, 'learning_rate': 0.04908549994143797, 'lambda': 0.2856709425614497, 'alpha': 0.4279186362732783, 'subsample': 0.9740523529061306}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:07,270] Trial 337 finished with value: 0.10412643460899745 and parameters: {'depth': 10, 'learning_rate': 0.048239889728285384, 'lambda': 0.31089934660377766, 'alpha': 0.4111439797368386, 'subsample': 0.9522417008787536}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:11,214] Trial 338 finished with value: 0.10405059283009324 and parameters: {'depth': 10, 'learning_rate': 0.04516836566979179, 'lambda': 0.3981914413814667, 'alpha': 0.47181154696012556, 'subsample': 0.989509913679201}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:15,287] Trial 339 finished with value: 0.1046121060425968 and parameters: {'depth': 10, 'learning_rate': 0.03820432165931352, 'lambda': 0.3646203364529619, 'alpha': 0.44006579590687867, 'subsample': 0.9632167549172949}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:18,068] Trial 340 finished with value: 0.10971727567909119 and parameters: {'depth': 9, 'learning_rate': 0.049103085251250504, 'lambda': 0.1234708933541416, 'alpha': 0.570038778976605, 'subsample': 0.7493124841775974}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:22,206] Trial 341 finished with value: 0.10375753775240526 and parameters: {'depth': 10, 'learning_rate': 0.04663140662959543, 'lambda': 0.0015893727628725624, 'alpha': 0.8335108901939312, 'subsample': 0.8340434107674051}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:26,198] Trial 342 finished with value: 0.10424512535369145 and parameters: {'depth': 10, 'learning_rate': 0.04762373464940414, 'lambda': 0.07756572600680219, 'alpha': 0.6061725365656749, 'subsample': 0.9994496818674908}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:30,324] Trial 343 finished with value: 0.1035922238468629 and parameters: {'depth': 10, 'learning_rate': 0.04910083062599368, 'lambda': 0.10991603211052328, 'alpha': 0.0018939590411145568, 'subsample': 0.9838943405403181}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:34,388] Trial 344 finished with value: 0.10408579282437276 and parameters: {'depth': 10, 'learning_rate': 0.04989255743207491, 'lambda': 0.06059676955244216, 'alpha': 0.4103245113147422, 'subsample': 0.8855517084420791}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:38,355] Trial 345 finished with value: 0.10400038778442595 and parameters: {'depth': 10, 'learning_rate': 0.048268080737394706, 'lambda': 0.08940074995201377, 'alpha': 0.25592516461061027, 'subsample': 0.9133791773735819}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:42,413] Trial 346 finished with value: 0.10394077417640434 and parameters: {'depth': 10, 'learning_rate': 0.0466520338077051, 'lambda': 0.19953389671499422, 'alpha': 0.28764142657096003, 'subsample': 0.9437951726283872}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:46,400] Trial 347 finished with value: 0.11211579818014146 and parameters: {'depth': 10, 'learning_rate': 0.02693697373151305, 'lambda': 0.41632697581772765, 'alpha': 0.3885302969164586, 'subsample': 0.7070355084901714}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:50,406] Trial 348 finished with value: 0.10421256166179764 and parameters: {'depth': 10, 'learning_rate': 0.04993787054050786, 'lambda': 0.03280872737649428, 'alpha': 0.32051824207368357, 'subsample': 0.9020568992151917}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:54,541] Trial 349 finished with value: 0.1048066182839795 and parameters: {'depth': 10, 'learning_rate': 0.03625954671481186, 'lambda': 0.01802533457465374, 'alpha': 0.363246516553092, 'subsample': 0.9723989669876085}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:57:58,504] Trial 350 finished with value: 0.10345592647384355 and parameters: {'depth': 10, 'learning_rate': 0.04835443341593561, 'lambda': 0.06826099540297323, 'alpha': 0.45614055224435807, 'subsample': 0.9555370747454914}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:02,517] Trial 351 finished with value: 0.10705880031535603 and parameters: {'depth': 10, 'learning_rate': 0.03068264440057253, 'lambda': 0.4838571583042131, 'alpha': 0.43319247789538584, 'subsample': 0.9216356148451257}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:06,350] Trial 352 finished with value: 0.10355552040249603 and parameters: {'depth': 10, 'learning_rate': 0.049068881012391874, 'lambda': 0.15867149692849206, 'alpha': 0.3399081134500935, 'subsample': 0.9826611916274649}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:09,212] Trial 353 finished with value: 0.11383221469895088 and parameters: {'depth': 9, 'learning_rate': 0.02842592143055196, 'lambda': 0.24115348195379666, 'alpha': 0.39562691047944143, 'subsample': 0.6946283315522995}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:12,724] Trial 354 finished with value: 0.10449533698536784 and parameters: {'depth': 10, 'learning_rate': 0.04999573729717689, 'lambda': 0.45926766256285234, 'alpha': 0.3742210408682702, 'subsample': 0.8406455215971332}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:16,522] Trial 355 finished with value: 0.10397670893959111 and parameters: {'depth': 10, 'learning_rate': 0.04735168170789929, 'lambda': 0.036791019198937076, 'alpha': 0.4226153629277326, 'subsample': 0.9629895792412781}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:20,096] Trial 356 finished with value: 0.10560626039182763 and parameters: {'depth': 10, 'learning_rate': 0.04135516607522128, 'lambda': 0.13538354215721599, 'alpha': 0.16767004588009515, 'subsample': 0.5375699748789775}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:23,908] Trial 357 finished with value: 0.10394917989744841 and parameters: {'depth': 10, 'learning_rate': 0.045267942943572906, 'lambda': 0.09813699616966484, 'alpha': 0.3043608027016384, 'subsample': 0.8203584623252808}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:27,566] Trial 358 finished with value: 0.10442615310444692 and parameters: {'depth': 10, 'learning_rate': 0.048331721835659265, 'lambda': 0.7884183564586797, 'alpha': 0.5146578337531496, 'subsample': 0.9410824900875683}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:31,305] Trial 359 finished with value: 0.10419398234602756 and parameters: {'depth': 10, 'learning_rate': 0.040840240215448784, 'lambda': 0.002261842990417623, 'alpha': 0.35231878930976385, 'subsample': 0.8977236709826626}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:35,538] Trial 360 finished with value: 0.11877054197251367 and parameters: {'depth': 10, 'learning_rate': 0.02432666478730728, 'lambda': 0.057229036942506764, 'alpha': 0.06502673127053249, 'subsample': 0.9141123425611892}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:39,727] Trial 361 finished with value: 0.9846943256715867 and parameters: {'depth': 10, 'learning_rate': 0.00014899781485181243, 'lambda': 0.723340206742455, 'alpha': 0.4092597878306689, 'subsample': 0.9895362173596028}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:42,866] Trial 362 finished with value: 0.129116916573661 and parameters: {'depth': 9, 'learning_rate': 0.02251018138648147, 'lambda': 0.32411351685544565, 'alpha': 0.4445067513860397, 'subsample': 0.8621746192282363}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:46,928] Trial 363 finished with value: 0.10388512554494254 and parameters: {'depth': 10, 'learning_rate': 0.046239406366576814, 'lambda': 0.03504933234485865, 'alpha': 0.47756305777457714, 'subsample': 0.9510737376786684}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:51,025] Trial 364 finished with value: 0.10367366641262485 and parameters: {'depth': 10, 'learning_rate': 0.04366551406600942, 'lambda': 0.07597907025898659, 'alpha': 0.6869516417453513, 'subsample': 0.9749635374710565}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:55,207] Trial 365 finished with value: 0.10392948445629183 and parameters: {'depth': 10, 'learning_rate': 0.04900353870927757, 'lambda': 0.21859900704819407, 'alpha': 0.38085765359963514, 'subsample': 0.9298391701122043}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:58:59,172] Trial 366 finished with value: 0.10403331361208393 and parameters: {'depth': 10, 'learning_rate': 0.04735150002075403, 'lambda': 0.5315541925253288, 'alpha': 0.20849105205100005, 'subsample': 0.8489179319965783}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:03,468] Trial 367 finished with value: 0.10388181919441947 and parameters: {'depth': 10, 'learning_rate': 0.0499761787089499, 'lambda': 0.0009001346588442261, 'alpha': 0.32129468996399996, 'subsample': 0.8772715198466016}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:07,400] Trial 368 finished with value: 0.10425166879079656 and parameters: {'depth': 10, 'learning_rate': 0.048217742228038526, 'lambda': 0.04771845028756719, 'alpha': 0.39895765046465564, 'subsample': 0.7870886916599721}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:11,437] Trial 369 finished with value: 0.10431501436004949 and parameters: {'depth': 10, 'learning_rate': 0.048989543732384816, 'lambda': 0.01943842559243644, 'alpha': 0.2679011773804634, 'subsample': 0.7386734877589869}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:15,412] Trial 370 finished with value: 0.1038558424126316 and parameters: {'depth': 10, 'learning_rate': 0.04697145845131366, 'lambda': 0.11230178269603948, 'alpha': 0.4238475192908668, 'subsample': 0.9650629330029338}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:19,508] Trial 371 finished with value: 0.10350833524249935 and parameters: {'depth': 10, 'learning_rate': 0.04904103292971296, 'lambda': 0.08321813244509703, 'alpha': 0.3426967710340198, 'subsample': 0.8885761368021796}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:20,440] Trial 372 finished with value: 0.2086860161792464 and parameters: {'depth': 2, 'learning_rate': 0.04786449527918082, 'lambda': 0.05744484882680612, 'alpha': 0.37216626092025656, 'subsample': 0.6620011331066378}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:24,335] Trial 373 finished with value: 0.10489752043690759 and parameters: {'depth': 10, 'learning_rate': 0.039086142609208056, 'lambda': 0.0243553111711312, 'alpha': 0.4603015470924655, 'subsample': 0.7737803523964463}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:28,222] Trial 374 finished with value: 0.10456885296427414 and parameters: {'depth': 10, 'learning_rate': 0.03730025731312001, 'lambda': 0.04408986785660679, 'alpha': 0.412361799151495, 'subsample': 0.9220530068187399}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:32,004] Trial 375 finished with value: 0.10514220198698924 and parameters: {'depth': 10, 'learning_rate': 0.03531427040610846, 'lambda': 0.37714208486905126, 'alpha': 0.3570197647243941, 'subsample': 0.9081967963871251}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:35,897] Trial 376 finished with value: 0.21124755128464637 and parameters: {'depth': 10, 'learning_rate': 0.015045421715092745, 'lambda': 0.7404971722306869, 'alpha': 0.2857443259168653, 'subsample': 0.9999358423631305}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:39,482] Trial 377 finished with value: 0.1044968063722696 and parameters: {'depth': 10, 'learning_rate': 0.046100638980171825, 'lambda': 0.9318999095173981, 'alpha': 0.4438113124182985, 'subsample': 0.9424649758986736}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:42,221] Trial 378 finished with value: 0.10960661153201129 and parameters: {'depth': 9, 'learning_rate': 0.04455974400622409, 'lambda': 0.14166424452208956, 'alpha': 0.5469779721383425, 'subsample': 0.7541632622236447}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:43,660] Trial 379 finished with value: 0.13004122328465897 and parameters: {'depth': 6, 'learning_rate': 0.04994391536283383, 'lambda': 0.0744344443953753, 'alpha': 0.3849727706294039, 'subsample': 0.7973690738905521}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:45,409] Trial 380 finished with value: 0.12230726178919049 and parameters: {'depth': 7, 'learning_rate': 0.04903005722730417, 'lambda': 0.2574619078940898, 'alpha': 0.33883308141030394, 'subsample': 0.6735909538879536}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:49,262] Trial 381 finished with value: 0.10350632922016943 and parameters: {'depth': 10, 'learning_rate': 0.04774505544085179, 'lambda': 0.020956747295265102, 'alpha': 0.2352912734861034, 'subsample': 0.9565413928851795}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:52,833] Trial 382 finished with value: 0.10414621214990592 and parameters: {'depth': 10, 'learning_rate': 0.049977563317707564, 'lambda': 0.6045097208753266, 'alpha': 0.04981853034547035, 'subsample': 0.9811492565812606}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:56,507] Trial 383 finished with value: 0.10351055467829431 and parameters: {'depth': 10, 'learning_rate': 0.04845919034665237, 'lambda': 0.09869525328067194, 'alpha': 0.39961736329262293, 'subsample': 0.9368788838746301}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 14:59:57,789] Trial 384 finished with value: 0.15492688421646075 and parameters: {'depth': 4, 'learning_rate': 0.04699377162263524, 'lambda': 0.1219416192673745, 'alpha': 0.14041778855581066, 'subsample': 0.9711140735101422}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:01,516] Trial 385 finished with value: 0.10408735543283826 and parameters: {'depth': 10, 'learning_rate': 0.04305932833609524, 'lambda': 0.17479886290308416, 'alpha': 0.4295015018638937, 'subsample': 0.9093863747158208}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:05,053] Trial 386 finished with value: 0.10512026923936317 and parameters: {'depth': 10, 'learning_rate': 0.048289266127509854, 'lambda': 0.5693727349498475, 'alpha': 0.3058073266178072, 'subsample': 0.5765233923385739}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:08,633] Trial 387 finished with value: 0.10414377797737696 and parameters: {'depth': 10, 'learning_rate': 0.048883975919701284, 'lambda': 0.6754969375797373, 'alpha': 0.3645600287975837, 'subsample': 0.9249006485411728}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:12,558] Trial 388 finished with value: 0.1066038093997033 and parameters: {'depth': 10, 'learning_rate': 0.03153128929185053, 'lambda': 0.408162534300439, 'alpha': 0.48446448537642123, 'subsample': 0.8962690378260445}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:15,365] Trial 389 finished with value: 0.10952073287675348 and parameters: {'depth': 9, 'learning_rate': 0.0456535967666889, 'lambda': 0.0001749819621441849, 'alpha': 0.4127942014437951, 'subsample': 0.99103716065021}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:19,012] Trial 390 finished with value: 0.10378043626245013 and parameters: {'depth': 10, 'learning_rate': 0.049205005287933555, 'lambda': 0.04110872155112109, 'alpha': 0.3929016179807031, 'subsample': 0.9510564244930284}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:22,793] Trial 391 finished with value: 0.10378451568613792 and parameters: {'depth': 10, 'learning_rate': 0.047530632100979464, 'lambda': 0.502197526643993, 'alpha': 0.3245450908227317, 'subsample': 0.9176559791677853}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:26,549] Trial 392 finished with value: 0.10322672617966475 and parameters: {'depth': 10, 'learning_rate': 0.04911461419466048, 'lambda': 0.06332511930217444, 'alpha': 0.4514973360160145, 'subsample': 0.9321824586918611}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:30,263] Trial 393 finished with value: 0.1039694097346238 and parameters: {'depth': 10, 'learning_rate': 0.04666378996647235, 'lambda': 0.06747409482398167, 'alpha': 0.5025473616356725, 'subsample': 0.9294502794758743}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:34,062] Trial 394 finished with value: 0.1084031424502385 and parameters: {'depth': 10, 'learning_rate': 0.029042869040455974, 'lambda': 0.08796228181515066, 'alpha': 0.4411370176629304, 'subsample': 0.9428460662530938}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:37,975] Trial 395 finished with value: 0.10499458138727921 and parameters: {'depth': 10, 'learning_rate': 0.037931468413289586, 'lambda': 0.05693996770714468, 'alpha': 0.46662922769699694, 'subsample': 0.7634344511599177}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:41,809] Trial 396 finished with value: 0.10777680557785835 and parameters: {'depth': 10, 'learning_rate': 0.029919401471534084, 'lambda': 0.8555420493111352, 'alpha': 0.45270878321603286, 'subsample': 0.814274993451249}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:45,497] Trial 397 finished with value: 0.10365181556702853 and parameters: {'depth': 10, 'learning_rate': 0.04787962018675365, 'lambda': 0.11623100716514367, 'alpha': 0.26655430165803884, 'subsample': 0.9343899030303797}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:49,199] Trial 398 finished with value: 0.10378048308476386 and parameters: {'depth': 10, 'learning_rate': 0.0489839413565204, 'lambda': 0.09267431617314784, 'alpha': 0.37186956896722734, 'subsample': 0.827938094285473}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:52,888] Trial 399 finished with value: 0.1035793204010517 and parameters: {'depth': 10, 'learning_rate': 0.04721830099637483, 'lambda': 0.06836306189244021, 'alpha': 0.2904228571610619, 'subsample': 0.9036988144633065}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:55,649] Trial 400 finished with value: 0.10959280690063196 and parameters: {'depth': 9, 'learning_rate': 0.048323190305416173, 'lambda': 0.34962754220336684, 'alpha': 0.34630410148759294, 'subsample': 0.9183066612173214}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:00:59,514] Trial 401 finished with value: 0.10346104451331105 and parameters: {'depth': 10, 'learning_rate': 0.04997077683213419, 'lambda': 0.037768956316895155, 'alpha': 0.4814892256354587, 'subsample': 0.9581139605873665}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:03,234] Trial 402 finished with value: 0.10417180572644888 and parameters: {'depth': 10, 'learning_rate': 0.04540712906022306, 'lambda': 0.14498594591488168, 'alpha': 0.3858140458432905, 'subsample': 0.6342477238535495}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:06,976] Trial 403 finished with value: 0.11534255773096391 and parameters: {'depth': 10, 'learning_rate': 0.025478376901610884, 'lambda': 0.42871005741589935, 'alpha': 0.42838342671682506, 'subsample': 0.7167381441747778}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:10,863] Trial 404 finished with value: 0.10402585626882477 and parameters: {'depth': 10, 'learning_rate': 0.044380146043492955, 'lambda': 0.3963960584283157, 'alpha': 0.32064561267974, 'subsample': 0.944594734548471}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:14,867] Trial 405 finished with value: 0.1328452953055017 and parameters: {'depth': 10, 'learning_rate': 0.02145977128666568, 'lambda': 0.05428342388004337, 'alpha': 0.24259364520111082, 'subsample': 0.8685938785705769}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:18,803] Trial 406 finished with value: 0.10516346899076841 and parameters: {'depth': 10, 'learning_rate': 0.03444057168398548, 'lambda': 0.028614710166662005, 'alpha': 0.10562392381440366, 'subsample': 0.9279358459978648}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:22,479] Trial 407 finished with value: 0.10569258048864014 and parameters: {'depth': 10, 'learning_rate': 0.04898823633789103, 'lambda': 0.4685633541152245, 'alpha': 0.360551288855483, 'subsample': 0.5210987555933406}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:26,723] Trial 408 finished with value: 0.105643478854109 and parameters: {'depth': 10, 'learning_rate': 0.03297781597527889, 'lambda': 0.09920927281502714, 'alpha': 0.03165563060366383, 'subsample': 0.8861510746070284}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:31,013] Trial 409 finished with value: 0.10473912272959865 and parameters: {'depth': 10, 'learning_rate': 0.03579501561243263, 'lambda': 0.07543882437268479, 'alpha': 0.45649678494647916, 'subsample': 0.9662308780101668}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:35,159] Trial 410 finished with value: 0.10427152888831438 and parameters: {'depth': 10, 'learning_rate': 0.04653329180608856, 'lambda': 0.44346999556735484, 'alpha': 0.4106612868554067, 'subsample': 0.9074980547601922}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:39,198] Trial 411 finished with value: 0.10391385444316431 and parameters: {'depth': 10, 'learning_rate': 0.047960892754123026, 'lambda': 0.20413588529227994, 'alpha': 0.3951853059028487, 'subsample': 0.9492662936565687}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:43,059] Trial 412 finished with value: 0.10444361669820774 and parameters: {'depth': 10, 'learning_rate': 0.04922122103645348, 'lambda': 0.6252132616705945, 'alpha': 0.33876137466801914, 'subsample': 0.6827624137820789}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:45,372] Trial 413 finished with value: 0.11569754173630725 and parameters: {'depth': 8, 'learning_rate': 0.04817707890733952, 'lambda': 0.16286157312510655, 'alpha': 0.9649623473844158, 'subsample': 0.8580863246976731}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:49,482] Trial 414 finished with value: 0.10347988060609188 and parameters: {'depth': 10, 'learning_rate': 0.04929456089323932, 'lambda': 0.05089699281713993, 'alpha': 0.3022742070589083, 'subsample': 0.935507499519345}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:53,646] Trial 415 finished with value: 0.10435751433233674 and parameters: {'depth': 10, 'learning_rate': 0.04731349400093289, 'lambda': 0.029731489869183076, 'alpha': 0.982305398802729, 'subsample': 0.7892415485628071}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:01:56,502] Trial 416 finished with value: 0.10956772013649413 and parameters: {'depth': 9, 'learning_rate': 0.04606588174204737, 'lambda': 0.31236928580302326, 'alpha': 0.4354057670496012, 'subsample': 0.922805673575955}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:00,563] Trial 417 finished with value: 0.10377996336241056 and parameters: {'depth': 10, 'learning_rate': 0.04888949140453349, 'lambda': 0.12994409002877277, 'alpha': 0.5318281006497482, 'subsample': 0.7279965244251223}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:04,630] Trial 418 finished with value: 0.10414352442838673 and parameters: {'depth': 10, 'learning_rate': 0.04812764026497442, 'lambda': 0.08549635994807694, 'alpha': 0.3719463947395761, 'subsample': 0.8420397944931612}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:08,533] Trial 419 finished with value: 0.10353477386330842 and parameters: {'depth': 10, 'learning_rate': 0.0498807502073654, 'lambda': 0.22795256185703494, 'alpha': 0.7605469884990635, 'subsample': 0.915053409649783}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:12,700] Trial 420 finished with value: 0.10332422680559782 and parameters: {'depth': 10, 'learning_rate': 0.04999095217909451, 'lambda': 0.019054827199805384, 'alpha': 0.42102594199567833, 'subsample': 0.9615627791606065}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:17,036] Trial 421 finished with value: 0.15460660021171713 and parameters: {'depth': 10, 'learning_rate': 0.018891773674326748, 'lambda': 0.02130599565385028, 'alpha': 0.41551177678952805, 'subsample': 0.9739592849818954}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:20,785] Trial 422 finished with value: 0.10436993571588297 and parameters: {'depth': 10, 'learning_rate': 0.04735698255143976, 'lambda': 0.9659881752660182, 'alpha': 0.5800505896955265, 'subsample': 0.9588449211430679}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:24,858] Trial 423 finished with value: 0.10354392729990537 and parameters: {'depth': 10, 'learning_rate': 0.04903174846971599, 'lambda': 0.0653652894059286, 'alpha': 0.45688320624832, 'subsample': 0.9508498924041932}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:29,005] Trial 424 finished with value: 0.10383252684934341 and parameters: {'depth': 10, 'learning_rate': 0.048387283909976854, 'lambda': 0.10836705716568325, 'alpha': 0.4006530105308925, 'subsample': 0.9646509569205528}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:33,254] Trial 425 finished with value: 0.1082551258045955 and parameters: {'depth': 10, 'learning_rate': 0.029410292644505717, 'lambda': 0.01713370969314064, 'alpha': 0.4339604856181934, 'subsample': 0.9800455461693903}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:37,428] Trial 426 finished with value: 0.11982654352431982 and parameters: {'depth': 10, 'learning_rate': 0.024070875397955577, 'lambda': 0.4852889906646965, 'alpha': 0.3857527038321692, 'subsample': 0.9374533755387173}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:41,466] Trial 427 finished with value: 0.10397469416781088 and parameters: {'depth': 10, 'learning_rate': 0.049998990999839524, 'lambda': 0.04739723488675711, 'alpha': 0.4717094954933306, 'subsample': 0.9722598719200009}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:45,446] Trial 428 finished with value: 0.10372539614879278 and parameters: {'depth': 10, 'learning_rate': 0.046579718067504224, 'lambda': 0.01761282794394026, 'alpha': 0.41903759276995695, 'subsample': 0.9570053856778105}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:49,545] Trial 429 finished with value: 0.10360637169062575 and parameters: {'depth': 10, 'learning_rate': 0.04365402900483284, 'lambda': 0.0010652099610046761, 'alpha': 0.44244933124708563, 'subsample': 0.9392788284878535}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:52,390] Trial 430 finished with value: 0.1101281702752751 and parameters: {'depth': 9, 'learning_rate': 0.04761164741220939, 'lambda': 0.2711640701556775, 'alpha': 0.5056334613723105, 'subsample': 0.8977258563299472}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:02:56,238] Trial 431 finished with value: 0.10384665383078166 and parameters: {'depth': 10, 'learning_rate': 0.042794074651985196, 'lambda': 0.5121858664381091, 'alpha': 0.3505544931370005, 'subsample': 0.9250840824844088}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:00,297] Trial 432 finished with value: 0.1058298610010584 and parameters: {'depth': 10, 'learning_rate': 0.03204285438763765, 'lambda': 0.06436283035232573, 'alpha': 0.4070596748222966, 'subsample': 0.9463111698390346}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:04,111] Trial 433 finished with value: 0.10448418246694345 and parameters: {'depth': 10, 'learning_rate': 0.03990854531289957, 'lambda': 0.6914443234015264, 'alpha': 0.3713078543776522, 'subsample': 0.9835195708029999}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:08,209] Trial 434 finished with value: 0.16706238739291507 and parameters: {'depth': 10, 'learning_rate': 0.017824361128979917, 'lambda': 0.04115646129731049, 'alpha': 0.38377881735586084, 'subsample': 0.9648775176322468}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:11,824] Trial 435 finished with value: 0.10375219800659682 and parameters: {'depth': 10, 'learning_rate': 0.04904037708673238, 'lambda': 0.1857884256610117, 'alpha': 0.4279873629633225, 'subsample': 0.9111322848634057}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:15,840] Trial 436 finished with value: 0.2714640554848435 and parameters: {'depth': 10, 'learning_rate': 0.012453890447119436, 'lambda': 0.08767670383663188, 'alpha': 0.4544724396780606, 'subsample': 0.9306917197035169}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:19,711] Trial 437 finished with value: 0.1039386030267386 and parameters: {'depth': 10, 'learning_rate': 0.04551723126674123, 'lambda': 0.560914265474602, 'alpha': 0.3587134460706887, 'subsample': 0.9774690928851438}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:23,712] Trial 438 finished with value: 0.1033663052169865 and parameters: {'depth': 10, 'learning_rate': 0.048299892111799206, 'lambda': 0.11254473816195348, 'alpha': 0.4082373102946055, 'subsample': 0.9911354915168408}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:27,658] Trial 439 finished with value: 0.1038501859242342 and parameters: {'depth': 10, 'learning_rate': 0.049976064832045905, 'lambda': 0.133881081215348, 'alpha': 0.48903095886802017, 'subsample': 0.9871637995315762}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:31,838] Trial 440 finished with value: 0.2285658463413306 and parameters: {'depth': 10, 'learning_rate': 0.014208598295197071, 'lambda': 0.33246983683759573, 'alpha': 0.4138304178122733, 'subsample': 0.9927417865412551}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:35,713] Trial 441 finished with value: 0.10405534867341348 and parameters: {'depth': 10, 'learning_rate': 0.048359613872280986, 'lambda': 0.11314276147323288, 'alpha': 0.8370855618237371, 'subsample': 0.9998762995993291}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:37,049] Trial 442 finished with value: 0.1419933373939858 and parameters: {'depth': 5, 'learning_rate': 0.03916544967263108, 'lambda': 0.15820094402515286, 'alpha': 0.4371102276096978, 'subsample': 0.9718259679434179}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:40,976] Trial 443 finished with value: 0.10365260152467061 and parameters: {'depth': 10, 'learning_rate': 0.04718526250284587, 'lambda': 0.10312251288444203, 'alpha': 0.6087434174291084, 'subsample': 0.9598575383590912}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:45,058] Trial 444 finished with value: 0.10475510453365211 and parameters: {'depth': 10, 'learning_rate': 0.03765622597415051, 'lambda': 0.1246470719160296, 'alpha': 0.1677427482917843, 'subsample': 0.9848447907416883}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:49,027] Trial 445 finished with value: 0.103728294618986 and parameters: {'depth': 10, 'learning_rate': 0.049014778749638534, 'lambda': 0.276794423895241, 'alpha': 0.3964536529207501, 'subsample': 0.950700019659118}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:52,961] Trial 446 finished with value: 0.10372011766988924 and parameters: {'depth': 10, 'learning_rate': 0.044685145287000044, 'lambda': 0.08608318159980408, 'alpha': 0.4640823143434226, 'subsample': 0.9703729820723571}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:55,778] Trial 447 finished with value: 0.10979283035274752 and parameters: {'depth': 9, 'learning_rate': 0.04633528541633062, 'lambda': 0.1460744686973912, 'alpha': 0.4217104211511632, 'subsample': 0.9895734599842672}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:03:59,536] Trial 448 finished with value: 0.14857677115592888 and parameters: {'depth': 10, 'learning_rate': 0.019500523966426125, 'lambda': 0.42619880480235567, 'alpha': 0.32400973232455654, 'subsample': 0.9645003507801289}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:03,098] Trial 449 finished with value: 0.10396167299920535 and parameters: {'depth': 10, 'learning_rate': 0.04823516960898059, 'lambda': 0.24221989737286437, 'alpha': 0.40118655221708016, 'subsample': 0.9779165769316843}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:07,311] Trial 450 finished with value: 0.43165067603352253 and parameters: {'depth': 10, 'learning_rate': 0.008003038668376247, 'lambda': 0.06876536819349494, 'alpha': 0.4418397342054893, 'subsample': 0.8921166692077998}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:11,162] Trial 451 finished with value: 0.10374722255216054 and parameters: {'depth': 10, 'learning_rate': 0.04905220646976257, 'lambda': 0.45210024551304323, 'alpha': 0.8712601457014145, 'subsample': 0.9436395538707821}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:14,016] Trial 452 finished with value: 0.10981249107253067 and parameters: {'depth': 9, 'learning_rate': 0.04995764797126221, 'lambda': 0.04862543350570775, 'alpha': 0.33714175720175793, 'subsample': 0.8766302937307515}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:18,126] Trial 453 finished with value: 0.1076597706686482 and parameters: {'depth': 10, 'learning_rate': 0.0303018928933522, 'lambda': 0.10433665241750416, 'alpha': 0.10056112016669527, 'subsample': 0.9999990839953845}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:22,216] Trial 454 finished with value: 0.10383277741562778 and parameters: {'depth': 10, 'learning_rate': 0.04751155720111679, 'lambda': 0.07541574909313234, 'alpha': 0.016441174098963618, 'subsample': 0.9565920479128123}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:26,186] Trial 455 finished with value: 0.10374154012435277 and parameters: {'depth': 10, 'learning_rate': 0.04900327422112684, 'lambda': 0.1738407897413323, 'alpha': 0.19234042132711549, 'subsample': 0.9308482362863612}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:30,302] Trial 456 finished with value: 0.11015859077929391 and parameters: {'depth': 10, 'learning_rate': 0.027954753829249876, 'lambda': 0.5492505689310446, 'alpha': 0.3784657275782852, 'subsample': 0.9800824491756713}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:34,342] Trial 457 finished with value: 0.29298270968792184 and parameters: {'depth': 10, 'learning_rate': 0.011711713168879, 'lambda': 0.768153101617725, 'alpha': 0.41601368695947266, 'subsample': 0.9057841471358808}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:38,614] Trial 458 finished with value: 0.137663876064201 and parameters: {'depth': 10, 'learning_rate': 0.02078309679757671, 'lambda': 0.059115912021487846, 'alpha': 0.4748538721192652, 'subsample': 0.9206158350994416}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:42,485] Trial 459 finished with value: 0.1044985741169579 and parameters: {'depth': 10, 'learning_rate': 0.04686955546953268, 'lambda': 0.6298471965959397, 'alpha': 0.39457057643350957, 'subsample': 0.9517335028952137}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:46,436] Trial 460 finished with value: 0.10353258435031042 and parameters: {'depth': 10, 'learning_rate': 0.048186965215528454, 'lambda': 0.031162623638219724, 'alpha': 0.36068788174902294, 'subsample': 0.9379195049470823}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:50,292] Trial 461 finished with value: 0.1051811007315324 and parameters: {'depth': 10, 'learning_rate': 0.04087421227595013, 'lambda': 0.11939909545428135, 'alpha': 0.4501275378909577, 'subsample': 0.5570030502993389}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:54,447] Trial 462 finished with value: 0.20994790620611614 and parameters: {'depth': 10, 'learning_rate': 0.015112944617733262, 'lambda': 0.08245307468209444, 'alpha': 0.515828935663384, 'subsample': 0.9702763276052566}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:04:58,577] Trial 463 finished with value: 0.11183661975001151 and parameters: {'depth': 10, 'learning_rate': 0.02694492446419947, 'lambda': 0.047112715617471046, 'alpha': 0.41277563644948945, 'subsample': 0.9847992206007101}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:01,416] Trial 464 finished with value: 0.11054511122917703 and parameters: {'depth': 9, 'learning_rate': 0.0353215608099336, 'lambda': 0.8566965804211619, 'alpha': 0.5712235663553664, 'subsample': 0.9611063729430865}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:05,398] Trial 465 finished with value: 0.1036656108114991 and parameters: {'depth': 10, 'learning_rate': 0.04922655903428995, 'lambda': 0.1906288352362165, 'alpha': 0.43325038075898875, 'subsample': 0.9147830029679275}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:09,299] Trial 466 finished with value: 0.10418476030452563 and parameters: {'depth': 10, 'learning_rate': 0.049979177147415274, 'lambda': 0.5282324638453346, 'alpha': 0.3152781721796278, 'subsample': 0.7430358776900742}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:13,212] Trial 467 finished with value: 0.10484557427025153 and parameters: {'depth': 10, 'learning_rate': 0.04169503250121593, 'lambda': 0.5822774539510964, 'alpha': 0.37330521384636256, 'subsample': 0.6523116661711488}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:17,064] Trial 468 finished with value: 0.10405995056386576 and parameters: {'depth': 10, 'learning_rate': 0.049997424684344476, 'lambda': 0.5457020048687906, 'alpha': 0.3563238474971432, 'subsample': 0.9405916742346426}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:21,174] Trial 469 finished with value: 0.13667255571414394 and parameters: {'depth': 10, 'learning_rate': 0.020947195889538087, 'lambda': 0.10018286766657401, 'alpha': 0.3921779475515289, 'subsample': 0.6420083045756713}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:25,168] Trial 470 finished with value: 0.11676164485653392 and parameters: {'depth': 10, 'learning_rate': 0.02492206164346767, 'lambda': 0.5771205242124893, 'alpha': 0.46613172347534015, 'subsample': 0.6896964263015264}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:29,238] Trial 471 finished with value: 0.10365568651899496 and parameters: {'depth': 10, 'learning_rate': 0.04775199842304379, 'lambda': 0.029264822746861888, 'alpha': 0.778809716356222, 'subsample': 0.9899036957926465}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:30,258] Trial 472 finished with value: 0.17836882066540705 and parameters: {'depth': 3, 'learning_rate': 0.03387542628706807, 'lambda': 0.14584279116156348, 'alpha': 0.5880095564619133, 'subsample': 0.7709490565565713}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:34,445] Trial 473 finished with value: 0.1273998992701494 and parameters: {'depth': 10, 'learning_rate': 0.022396695123294202, 'lambda': 0.06404059061515113, 'alpha': 0.3401031081075275, 'subsample': 0.9281735832821681}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:36,747] Trial 474 finished with value: 0.11572285431847867 and parameters: {'depth': 8, 'learning_rate': 0.04610789238795438, 'lambda': 0.35783246334011554, 'alpha': 0.5535797331819466, 'subsample': 0.9014900549935635}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:40,907] Trial 475 finished with value: 0.11067250385713277 and parameters: {'depth': 10, 'learning_rate': 0.028064251190024862, 'lambda': 0.016464170670617572, 'alpha': 0.4281397227145215, 'subsample': 0.5803019306948615}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:44,816] Trial 476 finished with value: 0.10376769181325597 and parameters: {'depth': 10, 'learning_rate': 0.048563672955881536, 'lambda': 0.04146713619287841, 'alpha': 0.40455427771721253, 'subsample': 0.9486832915620447}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:49,426] Trial 477 finished with value: 0.12009221249666988 and parameters: {'depth': 10, 'learning_rate': 0.024028029148884366, 'lambda': 0.0008870702485912624, 'alpha': 0.45163983098283816, 'subsample': 0.9738263009362804}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:53,934] Trial 478 finished with value: 0.12854903871254064 and parameters: {'depth': 10, 'learning_rate': 0.02232883320230069, 'lambda': 0.0728305051792074, 'alpha': 0.3083191841699754, 'subsample': 0.5687432719195631}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:05:57,874] Trial 479 finished with value: 0.16506349646412594 and parameters: {'depth': 10, 'learning_rate': 0.017959095503256098, 'lambda': 0.8934844886666498, 'alpha': 0.37780646563433506, 'subsample': 0.7335732025008594}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:01,838] Trial 480 finished with value: 0.10379636213962216 and parameters: {'depth': 10, 'learning_rate': 0.04726399645002004, 'lambda': 0.1283150954111283, 'alpha': 0.4097040859864318, 'subsample': 0.882845970653447}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:03,275] Trial 481 finished with value: 0.13031730047443554 and parameters: {'depth': 6, 'learning_rate': 0.04904447387546256, 'lambda': 0.33623761507981065, 'alpha': 0.9940178356510275, 'subsample': 0.9630233194877232}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:05,032] Trial 482 finished with value: 0.1220341658129667 and parameters: {'depth': 7, 'learning_rate': 0.048153182173215237, 'lambda': 0.7364498985229679, 'alpha': 0.49151847553729267, 'subsample': 0.9186534368683993}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:08,944] Trial 483 finished with value: 0.10672433771690432 and parameters: {'depth': 10, 'learning_rate': 0.03305020788363928, 'lambda': 0.09763107268048096, 'alpha': 0.6781553904482229, 'subsample': 0.5470093595734244}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:12,879] Trial 484 finished with value: 0.10426402080607858 and parameters: {'depth': 10, 'learning_rate': 0.04559521613275365, 'lambda': 0.20710935591665985, 'alpha': 0.333037063301245, 'subsample': 0.712405629363316}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:16,795] Trial 485 finished with value: 0.1036442387260425 and parameters: {'depth': 10, 'learning_rate': 0.04910222542086544, 'lambda': 0.05497462041743814, 'alpha': 0.06294182390842329, 'subsample': 0.8923988343303492}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:20,693] Trial 486 finished with value: 0.10333997372235922 and parameters: {'depth': 10, 'learning_rate': 0.04999614967843734, 'lambda': 0.2450596003089473, 'alpha': 0.6247141352654149, 'subsample': 0.932130593928766}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:23,341] Trial 487 finished with value: 0.11134155286205313 and parameters: {'depth': 9, 'learning_rate': 0.04995651044525897, 'lambda': 0.38932948331745887, 'alpha': 0.6756551802525341, 'subsample': 0.5068967850307495}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:27,429] Trial 488 finished with value: 0.1053629350534161 and parameters: {'depth': 10, 'learning_rate': 0.034592703030638175, 'lambda': 0.25582339344305705, 'alpha': 0.7344683587366048, 'subsample': 0.9335020817103948}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:30,207] Trial 489 finished with value: 0.10977528701339603 and parameters: {'depth': 9, 'learning_rate': 0.048135475211862656, 'lambda': 0.12760610299507133, 'alpha': 0.5618969873432758, 'subsample': 0.9222745801661933}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:34,431] Trial 490 finished with value: 0.1958272659442923 and parameters: {'depth': 10, 'learning_rate': 0.015883331184739374, 'lambda': 0.21441080891615136, 'alpha': 0.5922007628050239, 'subsample': 0.9110549133738558}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:38,473] Trial 491 finished with value: 0.11156352377046774 and parameters: {'depth': 10, 'learning_rate': 0.026999694170089617, 'lambda': 0.17116966902018013, 'alpha': 0.49563493817874504, 'subsample': 0.9433040694737116}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:42,445] Trial 492 finished with value: 0.10356860219224545 and parameters: {'depth': 10, 'learning_rate': 0.04997051499115664, 'lambda': 0.14364827399157998, 'alpha': 0.4395352522966494, 'subsample': 0.9298160870462954}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:46,350] Trial 493 finished with value: 0.10513449221924015 and parameters: {'depth': 10, 'learning_rate': 0.04022225668765063, 'lambda': 0.22964083005228697, 'alpha': 0.6769182461975394, 'subsample': 0.5864137299259542}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:50,253] Trial 494 finished with value: 0.10617936085804228 and parameters: {'depth': 10, 'learning_rate': 0.032447191446734226, 'lambda': 0.1611087718821174, 'alpha': 0.6894955370519135, 'subsample': 0.905749679917884}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:53,747] Trial 495 finished with value: 0.10403512319463187 and parameters: {'depth': 10, 'learning_rate': 0.04685456061922552, 'lambda': 0.9958530121245386, 'alpha': 0.713987827534051, 'subsample': 0.9363093045990107}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:06:57,596] Trial 496 finished with value: 0.10355928992653761 and parameters: {'depth': 10, 'learning_rate': 0.048476640328722176, 'lambda': 0.08807543478987753, 'alpha': 0.47649430968970063, 'subsample': 0.9512213047609699}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:01,307] Trial 497 finished with value: 0.10395312767063317 and parameters: {'depth': 10, 'learning_rate': 0.043944537731120385, 'lambda': 0.11201776764386995, 'alpha': 0.5462516122283217, 'subsample': 0.9241053299944388}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:05,334] Trial 498 finished with value: 0.1122295823302352 and parameters: {'depth': 10, 'learning_rate': 0.02665944008477021, 'lambda': 0.07925881698208709, 'alpha': 0.6552447068404462, 'subsample': 0.89932451563419}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:09,144] Trial 499 finished with value: 0.10782380678843478 and parameters: {'depth': 10, 'learning_rate': 0.029846295420248237, 'lambda': 0.18645705497515128, 'alpha': 0.42482626531621187, 'subsample': 0.86921028992957}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:13,349] Trial 500 finished with value: 0.11440218080162538 and parameters: {'depth': 10, 'learning_rate': 0.02572424769156799, 'lambda': 0.2704127088011491, 'alpha': 0.6064641104013954, 'subsample': 0.7036411490174798}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:17,396] Trial 501 finished with value: 0.1037447897734151 and parameters: {'depth': 10, 'learning_rate': 0.04770586269613061, 'lambda': 0.311807874678575, 'alpha': 0.5177063915814692, 'subsample': 0.9147909778010976}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:21,564] Trial 502 finished with value: 0.17657391286314508 and parameters: {'depth': 10, 'learning_rate': 0.017118744662101434, 'lambda': 0.4656467127654077, 'alpha': 0.5242689686972481, 'subsample': 0.9938678506929155}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:25,862] Trial 503 finished with value: 0.10463075289513124 and parameters: {'depth': 10, 'learning_rate': 0.03676555282085671, 'lambda': 0.059863927985132404, 'alpha': 0.7879280108573918, 'subsample': 0.855807460344145}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:29,992] Trial 504 finished with value: 0.10478941793264225 and parameters: {'depth': 10, 'learning_rate': 0.03603595882163503, 'lambda': 0.3048828556626807, 'alpha': 0.4539106655981425, 'subsample': 0.9432561045975025}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:33,957] Trial 505 finished with value: 0.10382075096653873 and parameters: {'depth': 10, 'learning_rate': 0.049058266334592475, 'lambda': 0.10972800941733504, 'alpha': 0.3941195203613542, 'subsample': 0.9564131071233785}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:37,995] Trial 506 finished with value: 0.10373831816802402 and parameters: {'depth': 10, 'learning_rate': 0.04513846347727812, 'lambda': 0.15677188110255752, 'alpha': 0.4221517330139468, 'subsample': 0.828799663849234}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:41,942] Trial 507 finished with value: 0.10351916117516544 and parameters: {'depth': 10, 'learning_rate': 0.04999597087615744, 'lambda': 0.04026022781054604, 'alpha': 0.27715191789767785, 'subsample': 0.9323844746023624}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:44,713] Trial 508 finished with value: 0.11034682288330999 and parameters: {'depth': 9, 'learning_rate': 0.04219832882186034, 'lambda': 0.08515648686865092, 'alpha': 0.3815092239375932, 'subsample': 0.6052106316828632}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:48,530] Trial 509 finished with value: 0.3415565674639986 and parameters: {'depth': 10, 'learning_rate': 0.010231982911113909, 'lambda': 0.6408674987763228, 'alpha': 0.4427002975740372, 'subsample': 0.98062951060093}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:52,217] Trial 510 finished with value: 0.10422834446025733 and parameters: {'depth': 10, 'learning_rate': 0.04654533649078997, 'lambda': 0.06533713341343854, 'alpha': 0.8478256215913054, 'subsample': 0.6575549188524294}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:55,691] Trial 511 finished with value: 0.10422021547022943 and parameters: {'depth': 10, 'learning_rate': 0.048394707141419364, 'lambda': 0.6992891585460601, 'alpha': 0.6330776154517558, 'subsample': 0.7838754206909404}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:07:59,418] Trial 512 finished with value: 0.10382274987232362 and parameters: {'depth': 10, 'learning_rate': 0.04743395157643646, 'lambda': 0.5157609106947559, 'alpha': 0.6002622289306112, 'subsample': 0.9231240804578167}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:03,252] Trial 513 finished with value: 0.10382506836327024 and parameters: {'depth': 10, 'learning_rate': 0.049049716049276895, 'lambda': 0.03516071424434342, 'alpha': 0.7807825390233591, 'subsample': 0.9532872452848523}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:07,211] Trial 514 finished with value: 0.1066362504503688 and parameters: {'depth': 10, 'learning_rate': 0.03111597992728777, 'lambda': 0.2888419474789532, 'alpha': 0.7163523966597667, 'subsample': 0.8433056981286444}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:11,157] Trial 515 finished with value: 0.10405010843711203 and parameters: {'depth': 10, 'learning_rate': 0.04998153650681599, 'lambda': 0.12557263598833912, 'alpha': 0.4061262830881049, 'subsample': 0.8046670741230495}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:15,109] Trial 516 finished with value: 0.1048251330900632 and parameters: {'depth': 10, 'learning_rate': 0.03774781278947644, 'lambda': 0.2047443751654262, 'alpha': 0.4670501929697778, 'subsample': 0.9106127379492899}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:19,072] Trial 517 finished with value: 0.10431997442151662 and parameters: {'depth': 10, 'learning_rate': 0.04819008686825478, 'lambda': 0.09435224451947614, 'alpha': 0.36219296592920613, 'subsample': 0.7226493485512645}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:23,120] Trial 518 finished with value: 0.10373688444773752 and parameters: {'depth': 10, 'learning_rate': 0.04898275341944008, 'lambda': 0.4073027526215835, 'alpha': 0.4272648923379658, 'subsample': 0.9395377641983377}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:27,109] Trial 519 finished with value: 0.10399557494739058 and parameters: {'depth': 10, 'learning_rate': 0.0462044677968494, 'lambda': 0.0515636640234786, 'alpha': 0.872947068672127, 'subsample': 0.9997202397354649}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:31,373] Trial 520 finished with value: 0.12417262710913936 and parameters: {'depth': 10, 'learning_rate': 0.02306062555528719, 'lambda': 0.021728821419309798, 'alpha': 0.5739825717276229, 'subsample': 0.9681357378268539}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:35,548] Trial 521 finished with value: 0.6788053860590559 and parameters: {'depth': 10, 'learning_rate': 0.0037160595194673587, 'lambda': 0.1445524154944514, 'alpha': 0.39166501438986007, 'subsample': 0.9834196078170462}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:38,361] Trial 522 finished with value: 0.10946981833487252 and parameters: {'depth': 9, 'learning_rate': 0.04730719246378177, 'lambda': 0.07549121255735972, 'alpha': 0.5368380723853465, 'subsample': 0.9294504019071987}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:42,369] Trial 523 finished with value: 0.10621052008048108 and parameters: {'depth': 10, 'learning_rate': 0.031733949457329456, 'lambda': 0.2549236473047031, 'alpha': 0.08606005900272307, 'subsample': 0.8996048221004234}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:46,146] Trial 524 finished with value: 0.10776897988874391 and parameters: {'depth': 10, 'learning_rate': 0.029919484371717826, 'lambda': 0.6530134441132824, 'alpha': 0.25988833803499756, 'subsample': 0.886038285231337}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:47,092] Trial 525 finished with value: 0.2059224276094966 and parameters: {'depth': 2, 'learning_rate': 0.04907830138008788, 'lambda': 0.11390798320093608, 'alpha': 0.413902081215992, 'subsample': 0.8135934610528935}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:50,889] Trial 526 finished with value: 0.10399550706207851 and parameters: {'depth': 10, 'learning_rate': 0.04492780234425415, 'lambda': 0.0332015830389416, 'alpha': 0.8078551293151073, 'subsample': 0.9473845668791758}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:54,518] Trial 527 finished with value: 0.1040743766980667 and parameters: {'depth': 10, 'learning_rate': 0.04789962716365162, 'lambda': 0.05609153586432425, 'alpha': 0.6084168358177445, 'subsample': 0.7991733529810962}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:08:58,292] Trial 528 finished with value: 0.10430200352779573 and parameters: {'depth': 10, 'learning_rate': 0.049034350610209415, 'lambda': 0.09571375924698927, 'alpha': 0.19387897274333427, 'subsample': 0.9165148411709456}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:01,902] Trial 529 finished with value: 0.10385040240087992 and parameters: {'depth': 10, 'learning_rate': 0.04691877412411107, 'lambda': 0.37492483822365363, 'alpha': 0.9529412731262358, 'subsample': 0.9614162544082947}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:05,972] Trial 530 finished with value: 0.26052293902627943 and parameters: {'depth': 10, 'learning_rate': 0.012869957498424938, 'lambda': 0.025192749129056332, 'alpha': 0.4999785808136767, 'subsample': 0.9922174782490175}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:07,108] Trial 531 finished with value: 0.15606777406409358 and parameters: {'depth': 4, 'learning_rate': 0.048205079707955865, 'lambda': 0.0003494416093906133, 'alpha': 0.29125122652932495, 'subsample': 0.6041251016553106}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:10,033] Trial 532 finished with value: 0.11007911484160457 and parameters: {'depth': 9, 'learning_rate': 0.049148637731975496, 'lambda': 0.2365279808674649, 'alpha': 0.2318470470005229, 'subsample': 0.9724403617445674}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:13,893] Trial 533 finished with value: 0.1048476768410917 and parameters: {'depth': 10, 'learning_rate': 0.03670927507780768, 'lambda': 0.43303288115740346, 'alpha': 0.3762991467042975, 'subsample': 0.6733752051528517}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:17,719] Trial 534 finished with value: 0.10416426316971199 and parameters: {'depth': 10, 'learning_rate': 0.04264268902557098, 'lambda': 0.1773623657289326, 'alpha': 0.4586173944221484, 'subsample': 0.92304113163703}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:21,525] Trial 535 finished with value: 0.10539188926359597 and parameters: {'depth': 10, 'learning_rate': 0.03372159452601524, 'lambda': 0.34501893572620385, 'alpha': 0.4406613250535002, 'subsample': 0.9366198069659362}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:25,193] Trial 536 finished with value: 0.10384488749780416 and parameters: {'depth': 10, 'learning_rate': 0.04921669842674986, 'lambda': 0.050154235651695744, 'alpha': 0.4088074142688808, 'subsample': 0.9085969487477152}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:28,825] Trial 537 finished with value: 0.10395272470178958 and parameters: {'depth': 10, 'learning_rate': 0.04752876547665239, 'lambda': 0.07992141883821897, 'alpha': 0.6596133648636531, 'subsample': 0.6879889545361191}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:32,493] Trial 538 finished with value: 0.10410077880421546 and parameters: {'depth': 10, 'learning_rate': 0.04573664292263963, 'lambda': 0.1365071027414205, 'alpha': 0.1229300825903834, 'subsample': 0.8781617265325524}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:36,289] Trial 539 finished with value: 0.1038702747570371 and parameters: {'depth': 10, 'learning_rate': 0.04379102510837954, 'lambda': 0.03350293173405776, 'alpha': 0.6219601785044184, 'subsample': 0.9498434271390183}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:40,031] Trial 540 finished with value: 0.13695338823259604 and parameters: {'depth': 10, 'learning_rate': 0.020848476740495184, 'lambda': 0.6710308473959723, 'alpha': 0.4813625311272221, 'subsample': 0.893849618442593}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:44,046] Trial 541 finished with value: 0.10341440100980594 and parameters: {'depth': 10, 'learning_rate': 0.04998971358561451, 'lambda': 0.06512336004866283, 'alpha': 0.3582554364725691, 'subsample': 0.9814685092467983}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:45,401] Trial 542 finished with value: 0.14151333172666763 and parameters: {'depth': 5, 'learning_rate': 0.0499977116150203, 'lambda': 0.06511827377935323, 'alpha': 0.3255810765227232, 'subsample': 0.9840878685200992}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:49,076] Trial 543 finished with value: 0.103826379365547 and parameters: {'depth': 10, 'learning_rate': 0.04999334024995526, 'lambda': 0.018776329057660107, 'alpha': 0.3458834405097617, 'subsample': 0.9777910669157797}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:50,109] Trial 544 finished with value: 0.39972423652388933 and parameters: {'depth': 3, 'learning_rate': 0.007740813961757732, 'lambda': 0.62200836959904, 'alpha': 0.3556070154542052, 'subsample': 0.9888098792093215}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:54,033] Trial 545 finished with value: 0.1155996793657891 and parameters: {'depth': 10, 'learning_rate': 0.025358515070557985, 'lambda': 0.5329170328414128, 'alpha': 0.6663857006194274, 'subsample': 0.96859371721473}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:09:57,791] Trial 546 finished with value: 0.152750509986602 and parameters: {'depth': 10, 'learning_rate': 0.019064686851676182, 'lambda': 0.49997945048553893, 'alpha': 0.2992869422570126, 'subsample': 0.9636308031533299}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:10:01,743] Trial 547 finished with value: 0.10338674851334421 and parameters: {'depth': 10, 'learning_rate': 0.04994867328508124, 'lambda': 0.05025973172228945, 'alpha': 0.39116200624910075, 'subsample': 0.9728933865279891}. Best is trial 137 with value: 0.10319008323080202.\n",
      "[I 2023-08-29 15:10:05,988] Trial 548 finished with value: 0.10313543781773155 and parameters: {'depth': 10, 'learning_rate': 0.04997590541942759, 'lambda': 0.0704821218024878, 'alpha': 0.38527237892202787, 'subsample': 0.9919547695879909}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:10,453] Trial 549 finished with value: 0.10945976749094166 and parameters: {'depth': 9, 'learning_rate': 0.04857592682762781, 'lambda': 0.08064651944081862, 'alpha': 0.39584801675075326, 'subsample': 0.9949744345147246}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:15,072] Trial 550 finished with value: 0.10428446223522692 and parameters: {'depth': 10, 'learning_rate': 0.04837740774665185, 'lambda': 0.04770837981085546, 'alpha': 0.3849484448943417, 'subsample': 0.9994056786040354}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:19,071] Trial 551 finished with value: 0.10366185203152448 and parameters: {'depth': 10, 'learning_rate': 0.0491591618967471, 'lambda': 0.29435969422235886, 'alpha': 0.400624557764646, 'subsample': 0.9886549463813403}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:23,241] Trial 552 finished with value: 0.13213108338927293 and parameters: {'depth': 10, 'learning_rate': 0.021584317911567733, 'lambda': 0.38147185663852523, 'alpha': 0.3757167220186488, 'subsample': 0.9766535669367444}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:27,146] Trial 553 finished with value: 0.10396379500097103 and parameters: {'depth': 10, 'learning_rate': 0.04911264531049925, 'lambda': 0.10014091885259746, 'alpha': 0.4185194945584133, 'subsample': 0.8272069288862722}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:30,929] Trial 554 finished with value: 0.10460629121019874 and parameters: {'depth': 10, 'learning_rate': 0.047830206272294035, 'lambda': 0.7568489665671986, 'alpha': 0.9050005851472815, 'subsample': 0.6762053854692651}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:34,839] Trial 555 finished with value: 0.10460281357251923 and parameters: {'depth': 10, 'learning_rate': 0.04709581962754929, 'lambda': 0.047895385414290566, 'alpha': 0.4276449459949953, 'subsample': 0.7819994484815097}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:37,772] Trial 556 finished with value: 0.10989665593790815 and parameters: {'depth': 9, 'learning_rate': 0.049990633704125265, 'lambda': 0.06882641587225916, 'alpha': 0.14260176600515306, 'subsample': 0.9726100094185225}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:41,566] Trial 557 finished with value: 0.10374869320941868 and parameters: {'depth': 10, 'learning_rate': 0.04839411688041102, 'lambda': 0.039653334002660294, 'alpha': 0.7461294800970598, 'subsample': 0.6991639423712255}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:45,733] Trial 558 finished with value: 0.23430941647058237 and parameters: {'depth': 10, 'learning_rate': 0.013950676913104025, 'lambda': 0.21023528936205757, 'alpha': 0.3899108939098076, 'subsample': 0.9877736323955395}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:49,530] Trial 559 finished with value: 0.10415385586344598 and parameters: {'depth': 10, 'learning_rate': 0.04905814790689812, 'lambda': 0.4897357918173055, 'alpha': 0.3667565285802829, 'subsample': 0.9998436675274835}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:53,535] Trial 560 finished with value: 0.10889212136889433 and parameters: {'depth': 10, 'learning_rate': 0.02896225301382729, 'lambda': 0.4691534855687143, 'alpha': 0.4055628866458795, 'subsample': 0.6415965241341874}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:10:57,586] Trial 561 finished with value: 0.10372475190831958 and parameters: {'depth': 10, 'learning_rate': 0.04647891046991687, 'lambda': 0.08787116356974425, 'alpha': 0.5847712665881156, 'subsample': 0.851743023289886}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:01,414] Trial 562 finished with value: 0.1038181551916835 and parameters: {'depth': 10, 'learning_rate': 0.04813933097531913, 'lambda': 0.11668809071138572, 'alpha': 0.658008338486872, 'subsample': 0.9570127356389261}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:05,608] Trial 563 finished with value: 0.10964452324828448 and parameters: {'depth': 10, 'learning_rate': 0.028280726043656813, 'lambda': 0.06274576888364239, 'alpha': 0.4335963551369462, 'subsample': 0.979183018785453}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:09,881] Trial 564 finished with value: 0.20827824190745733 and parameters: {'depth': 10, 'learning_rate': 0.015204358581205184, 'lambda': 0.1546120396908588, 'alpha': 0.24885902020310577, 'subsample': 0.9687422363566013}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:13,885] Trial 565 finished with value: 0.10442723881649653 and parameters: {'depth': 10, 'learning_rate': 0.0413402853588772, 'lambda': 0.021357615051838023, 'alpha': 0.37991184067736766, 'subsample': 0.9022610366078642}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:18,239] Trial 566 finished with value: 0.3048309755612194 and parameters: {'depth': 10, 'learning_rate': 0.011322789729395807, 'lambda': 0.08053578874780756, 'alpha': 0.6913822477563261, 'subsample': 0.9479103530435434}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:22,253] Trial 567 finished with value: 0.10427924921694645 and parameters: {'depth': 10, 'learning_rate': 0.03850262632512449, 'lambda': 0.038535400290949734, 'alpha': 0.7168919870706942, 'subsample': 0.9165120201115132}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:26,425] Trial 568 finished with value: 0.10515995874641093 and parameters: {'depth': 10, 'learning_rate': 0.035304117374317504, 'lambda': 0.05842936874897582, 'alpha': 0.08048762490637451, 'subsample': 0.8343574915931051}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:30,516] Trial 569 finished with value: 0.1043739898690034 and parameters: {'depth': 10, 'learning_rate': 0.03873128861451919, 'lambda': 0.10235166438107837, 'alpha': 0.6490880315791324, 'subsample': 0.937325504144993}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:34,412] Trial 570 finished with value: 0.10396022346178987 and parameters: {'depth': 10, 'learning_rate': 0.049135948449809376, 'lambda': 0.19278862766172902, 'alpha': 0.3139540533247934, 'subsample': 0.7530659722923434}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:38,523] Trial 571 finished with value: 0.23661786640793733 and parameters: {'depth': 10, 'learning_rate': 0.01384536629007039, 'lambda': 0.2330188749781607, 'alpha': 0.4128039390721061, 'subsample': 0.9907567708813909}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:42,501] Trial 572 finished with value: 0.18015848179265775 and parameters: {'depth': 10, 'learning_rate': 0.01685656465233419, 'lambda': 0.8225286766100227, 'alpha': 0.6166450110571514, 'subsample': 0.8674078229310396}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:46,170] Trial 573 finished with value: 0.10383678697047939 and parameters: {'depth': 10, 'learning_rate': 0.04997462973805997, 'lambda': 0.27860609770239003, 'alpha': 0.327442264765126, 'subsample': 0.7650326480358942}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:49,801] Trial 574 finished with value: 0.10467689089082946 and parameters: {'depth': 10, 'learning_rate': 0.04729833164650792, 'lambda': 0.00018954407734438593, 'alpha': 0.39792293866487544, 'subsample': 0.6452314472443751}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:53,553] Trial 575 finished with value: 0.10349721176621558 and parameters: {'depth': 10, 'learning_rate': 0.04997949660560447, 'lambda': 0.37295443908813297, 'alpha': 0.6305476706319078, 'subsample': 0.9808596007036998}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:11:56,260] Trial 576 finished with value: 0.11151973185391029 and parameters: {'depth': 9, 'learning_rate': 0.03123491610315799, 'lambda': 0.7845259048504755, 'alpha': 0.346837932299666, 'subsample': 0.9604731771128113}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:00,066] Trial 577 finished with value: 0.10380325258412869 and parameters: {'depth': 10, 'learning_rate': 0.04460411481496486, 'lambda': 0.04045427912041551, 'alpha': 0.44605980784923577, 'subsample': 0.8884157704283342}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:03,657] Trial 578 finished with value: 0.10321239843022219 and parameters: {'depth': 10, 'learning_rate': 0.048317068529334574, 'lambda': 0.12973698209468074, 'alpha': 0.629878725046649, 'subsample': 0.925408092507011}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:07,545] Trial 579 finished with value: 0.10424336865268105 and parameters: {'depth': 10, 'learning_rate': 0.04603647151826737, 'lambda': 0.13878050736055636, 'alpha': 0.6331632447022991, 'subsample': 0.908003707990208}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:11,464] Trial 580 finished with value: 0.10377135118869432 and parameters: {'depth': 10, 'learning_rate': 0.04805719801815237, 'lambda': 0.17151495167722935, 'alpha': 0.6382595666640948, 'subsample': 0.9220515698588638}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:15,504] Trial 581 finished with value: 0.10368460581458955 and parameters: {'depth': 10, 'learning_rate': 0.04683905434950668, 'lambda': 0.13091686163003552, 'alpha': 0.5853707164396103, 'subsample': 0.9293711263613182}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:19,612] Trial 582 finished with value: 0.10499885015673323 and parameters: {'depth': 10, 'learning_rate': 0.03470944918669182, 'lambda': 0.115950806826208, 'alpha': 0.6374736630182783, 'subsample': 0.9140713309937095}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:23,528] Trial 583 finished with value: 0.1041364097684665 and parameters: {'depth': 10, 'learning_rate': 0.04843894928127577, 'lambda': 0.16162131766219628, 'alpha': 0.6548961094632445, 'subsample': 0.8611896878773325}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:26,182] Trial 584 finished with value: 0.11153118108011219 and parameters: {'depth': 9, 'learning_rate': 0.049120863428890424, 'lambda': 0.09927917544066718, 'alpha': 0.2847840177652967, 'subsample': 0.5310468174417464}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:30,281] Trial 585 finished with value: 0.28516534257038423 and parameters: {'depth': 10, 'learning_rate': 0.011975797222045587, 'lambda': 0.5539130303231481, 'alpha': 0.6201812764714798, 'subsample': 0.7163931880221994}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:34,367] Trial 586 finished with value: 0.10412995397072802 and parameters: {'depth': 10, 'learning_rate': 0.04067922534676741, 'lambda': 0.11846255215347806, 'alpha': 0.5674136061863488, 'subsample': 0.9003862978883186}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:38,400] Trial 587 finished with value: 0.10375827910415371 and parameters: {'depth': 10, 'learning_rate': 0.047691611981881404, 'lambda': 0.34088019035521055, 'alpha': 0.42846930334778444, 'subsample': 0.9711759441082692}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:42,311] Trial 588 finished with value: 0.1043320623334957 and parameters: {'depth': 10, 'learning_rate': 0.0499984895691378, 'lambda': 0.45285810713628805, 'alpha': 0.734356556790952, 'subsample': 0.9901232138854561}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:44,044] Trial 589 finished with value: 0.12646803367195256 and parameters: {'depth': 7, 'learning_rate': 0.026739737841849874, 'lambda': 0.4049435343570291, 'alpha': 0.4677415423403838, 'subsample': 0.8907907611661716}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:48,040] Trial 590 finished with value: 0.10441604897668053 and parameters: {'depth': 10, 'learning_rate': 0.04275162080537692, 'lambda': 0.3231472023576547, 'alpha': 0.6932254230571314, 'subsample': 0.7400248238652274}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:52,151] Trial 591 finished with value: 0.14327605553000222 and parameters: {'depth': 10, 'learning_rate': 0.020050372898944, 'lambda': 0.9713654264519952, 'alpha': 0.6427111204618833, 'subsample': 0.8773456617029699}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:56,355] Trial 592 finished with value: 0.8139145426423294 and parameters: {'depth': 10, 'learning_rate': 0.0019813818329701277, 'lambda': 0.08262125441483635, 'alpha': 0.4204532609980003, 'subsample': 0.9267148203101062}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:12:58,622] Trial 593 finished with value: 0.12687440227706867 and parameters: {'depth': 8, 'learning_rate': 0.024048544703513593, 'lambda': 0.1507626471303813, 'alpha': 0.04380626886067851, 'subsample': 0.9766201076543315}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:02,306] Trial 594 finished with value: 0.103687674814439 and parameters: {'depth': 10, 'learning_rate': 0.048342879988643964, 'lambda': 0.19138018713299834, 'alpha': 0.43656191677388684, 'subsample': 0.9638827956011534}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:05,994] Trial 595 finished with value: 0.1045650040457496 and parameters: {'depth': 10, 'learning_rate': 0.04682395834356642, 'lambda': 0.8291537282166445, 'alpha': 0.6154394190096599, 'subsample': 0.9999153693931181}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:09,808] Trial 596 finished with value: 0.6185479841973035 and parameters: {'depth': 10, 'learning_rate': 0.004605150310950292, 'lambda': 0.6973619266826099, 'alpha': 0.3989667618852547, 'subsample': 0.7753788258436132}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:13,752] Trial 597 finished with value: 0.10427948704744149 and parameters: {'depth': 10, 'learning_rate': 0.0489753033820766, 'lambda': 0.22099292768182266, 'alpha': 0.5920541666754289, 'subsample': 0.9391896272833898}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:17,834] Trial 598 finished with value: 0.10374129733824193 and parameters: {'depth': 10, 'learning_rate': 0.045212119573847416, 'lambda': 0.07615095369165589, 'alpha': 0.3668146758948699, 'subsample': 0.954042977118693}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:22,061] Trial 599 finished with value: 0.5530727251989828 and parameters: {'depth': 10, 'learning_rate': 0.0056580666478215115, 'lambda': 0.09795973224716095, 'alpha': 0.5537424070754717, 'subsample': 0.5073347030333831}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:26,217] Trial 600 finished with value: 0.15995996291504652 and parameters: {'depth': 10, 'learning_rate': 0.018418925994103094, 'lambda': 0.06092606103956351, 'alpha': 0.6990151806936322, 'subsample': 0.9841027995994199}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:29,048] Trial 601 finished with value: 0.10995166247897459 and parameters: {'depth': 9, 'learning_rate': 0.042075857303720154, 'lambda': 0.6075811126718024, 'alpha': 0.2061796163377957, 'subsample': 0.7955536236939799}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:33,047] Trial 602 finished with value: 0.10365991969777757 and parameters: {'depth': 10, 'learning_rate': 0.04757753485314534, 'lambda': 0.13480820039867658, 'alpha': 0.27414466989951136, 'subsample': 0.9136856573187213}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:37,051] Trial 603 finished with value: 0.10383450178561839 and parameters: {'depth': 10, 'learning_rate': 0.04878171497016957, 'lambda': 0.021992452359006646, 'alpha': 0.15578769252483238, 'subsample': 0.9454085162519407}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:40,800] Trial 604 finished with value: 0.10358515545485894 and parameters: {'depth': 10, 'learning_rate': 0.049149497291419264, 'lambda': 0.058110047894280877, 'alpha': 0.5128762488969598, 'subsample': 0.9233054058053412}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:44,222] Trial 605 finished with value: 0.10431114105768817 and parameters: {'depth': 10, 'learning_rate': 0.049982545545467175, 'lambda': 0.7139248489305132, 'alpha': 0.4558283371634816, 'subsample': 0.7047122108477111}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:48,023] Trial 606 finished with value: 0.10437445081092478 and parameters: {'depth': 10, 'learning_rate': 0.038336948422422565, 'lambda': 0.1050425659913371, 'alpha': 0.7497785082021848, 'subsample': 0.9046647617145331}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:51,648] Trial 607 finished with value: 0.10398828081653776 and parameters: {'depth': 10, 'learning_rate': 0.045968469629396505, 'lambda': 0.36117630483019497, 'alpha': 0.22498750297288728, 'subsample': 0.9321463472411484}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:55,655] Trial 608 finished with value: 0.13105659526859562 and parameters: {'depth': 10, 'learning_rate': 0.021729823706434396, 'lambda': 0.021424304829084563, 'alpha': 0.30063304856947526, 'subsample': 0.9660949195852234}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:13:59,603] Trial 609 finished with value: 0.1247467274022449 and parameters: {'depth': 10, 'learning_rate': 0.022912453778363755, 'lambda': 0.08171636359511245, 'alpha': 0.717917689134135, 'subsample': 0.983763738056816}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:03,422] Trial 610 finished with value: 0.10446870139895137 and parameters: {'depth': 10, 'learning_rate': 0.039541157046858066, 'lambda': 0.2581617536078229, 'alpha': 0.4891588613349662, 'subsample': 0.8513575246108347}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:07,429] Trial 611 finished with value: 0.11365692726321365 and parameters: {'depth': 10, 'learning_rate': 0.026127948081773215, 'lambda': 0.043374621248788936, 'alpha': 0.4174711381898569, 'subsample': 0.9903704995281837}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:11,281] Trial 612 finished with value: 0.1779434706928598 and parameters: {'depth': 10, 'learning_rate': 0.017008932889348467, 'lambda': 0.1739152583071105, 'alpha': 0.38675237623870445, 'subsample': 0.8937221225861349}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:15,085] Trial 613 finished with value: 0.10341958114456466 and parameters: {'depth': 10, 'learning_rate': 0.0477566236686423, 'lambda': 0.07776555634419206, 'alpha': 0.6569725462525247, 'subsample': 0.9562011728499977}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:18,988] Trial 614 finished with value: 0.14367302055877132 and parameters: {'depth': 10, 'learning_rate': 0.020024048630564176, 'lambda': 0.12974544519198258, 'alpha': 0.03532291496787998, 'subsample': 0.9161639097984592}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:21,664] Trial 615 finished with value: 0.11144666844064151 and parameters: {'depth': 9, 'learning_rate': 0.04852220300884782, 'lambda': 0.020003736680774167, 'alpha': 0.44670173858944184, 'subsample': 0.5454573860250733}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:25,345] Trial 616 finished with value: 0.1041552051205491 and parameters: {'depth': 10, 'learning_rate': 0.04409036123283569, 'lambda': 0.05517485569429458, 'alpha': 0.34604746895878846, 'subsample': 0.7521549761599299}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:28,950] Trial 617 finished with value: 0.1041995595925578 and parameters: {'depth': 10, 'learning_rate': 0.0470745720327325, 'lambda': 0.5623910792743625, 'alpha': 0.31553104133701654, 'subsample': 0.8407934928643579}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:32,508] Trial 618 finished with value: 0.10488287804255571 and parameters: {'depth': 10, 'learning_rate': 0.03746408038940896, 'lambda': 0.7582084723828317, 'alpha': 0.4081256847511749, 'subsample': 0.6608444856009716}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:36,327] Trial 619 finished with value: 0.10419316653025787 and parameters: {'depth': 10, 'learning_rate': 0.04917400343136192, 'lambda': 0.00013439422742476947, 'alpha': 0.7677938937837256, 'subsample': 0.670893790153819}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:38,967] Trial 620 finished with value: 0.10959346349174251 and parameters: {'depth': 9, 'learning_rate': 0.04800158881327353, 'lambda': 0.11411138098844575, 'alpha': 0.5315271274223091, 'subsample': 0.9772119529060277}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:42,869] Trial 621 finished with value: 0.24321769181151962 and parameters: {'depth': 10, 'learning_rate': 0.0135632465640649, 'lambda': 0.040729911743915395, 'alpha': 0.3615973049630254, 'subsample': 0.9441138379343833}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:44,343] Trial 622 finished with value: 0.1302176213850731 and parameters: {'depth': 6, 'learning_rate': 0.03145576486562765, 'lambda': 0.6420159381663482, 'alpha': 0.3873960121951366, 'subsample': 0.5627876823333048}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:48,231] Trial 623 finished with value: 0.11614225031907459 and parameters: {'depth': 10, 'learning_rate': 0.02527369636626512, 'lambda': 0.09059602991681809, 'alpha': 0.7583513857716102, 'subsample': 0.6577539727055098}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:51,913] Trial 624 finished with value: 0.10378415341321562 and parameters: {'depth': 10, 'learning_rate': 0.04914413057355972, 'lambda': 0.06897367805439997, 'alpha': 0.4733550766201648, 'subsample': 0.9343217703178545}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:55,764] Trial 625 finished with value: 0.10581464400727403 and parameters: {'depth': 10, 'learning_rate': 0.03341860285887466, 'lambda': 0.43604470558397823, 'alpha': 0.25669891329566347, 'subsample': 0.8233151914985481}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:14:59,773] Trial 626 finished with value: 0.1645772022981409 and parameters: {'depth': 10, 'learning_rate': 0.018020680714019233, 'lambda': 0.03355757899428374, 'alpha': 0.4307159280537144, 'subsample': 0.9678693248366139}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:03,854] Trial 627 finished with value: 0.10749971747233428 and parameters: {'depth': 10, 'learning_rate': 0.030426082094112284, 'lambda': 0.49108645406077056, 'alpha': 0.3337518485230952, 'subsample': 0.9075927154996781}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:07,778] Trial 628 finished with value: 0.10436569142744218 and parameters: {'depth': 10, 'learning_rate': 0.046719504793083406, 'lambda': 0.5832368609682519, 'alpha': 0.40464904804208396, 'subsample': 0.6924073395571437}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:11,604] Trial 629 finished with value: 0.10511840014609708 and parameters: {'depth': 10, 'learning_rate': 0.04999816091316605, 'lambda': 0.5836474319894367, 'alpha': 0.8327007158522394, 'subsample': 0.5917625738962282}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:16,316] Trial 630 finished with value: 0.10916101051623568 and parameters: {'depth': 10, 'learning_rate': 0.029026442741518624, 'lambda': 0.2507141072575728, 'alpha': 0.4509562149081685, 'subsample': 0.6078407458640549}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:21,548] Trial 631 finished with value: 0.10367039609921355 and parameters: {'depth': 10, 'learning_rate': 0.0484017330322726, 'lambda': 0.3141593613449924, 'alpha': 0.6684091985706401, 'subsample': 0.9260681971200598}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:26,234] Trial 632 finished with value: 0.10471462152227076 and parameters: {'depth': 10, 'learning_rate': 0.045626299956743915, 'lambda': 0.14284415604582526, 'alpha': 0.7982803686620631, 'subsample': 0.6161601214391403}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:30,222] Trial 633 finished with value: 0.10427553189833101 and parameters: {'depth': 10, 'learning_rate': 0.04912999136315004, 'lambda': 0.6103102120649777, 'alpha': 0.7044793612179651, 'subsample': 0.8780573451650302}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:34,131] Trial 634 finished with value: 0.10384082001464386 and parameters: {'depth': 10, 'learning_rate': 0.047681230733503784, 'lambda': 0.15569424136852866, 'alpha': 0.8991634990291801, 'subsample': 0.9919420866197736}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:38,040] Trial 635 finished with value: 0.4300424871837894 and parameters: {'depth': 10, 'learning_rate': 0.008039907258624066, 'lambda': 0.21316305437803204, 'alpha': 0.3729766814515487, 'subsample': 0.5213236288555998}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:42,343] Trial 636 finished with value: 0.3760115933269782 and parameters: {'depth': 10, 'learning_rate': 0.009311592110760276, 'lambda': 0.05224057201491203, 'alpha': 0.600890474142, 'subsample': 0.81811073775281}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:45,356] Trial 637 finished with value: 0.11009425063230302 and parameters: {'depth': 9, 'learning_rate': 0.03702080488687379, 'lambda': 0.5159077931648799, 'alpha': 0.42388683294654206, 'subsample': 0.959820865130464}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:49,627] Trial 638 finished with value: 0.19520906562083729 and parameters: {'depth': 10, 'learning_rate': 0.015931748237001164, 'lambda': 0.0997137372681094, 'alpha': 0.39440204157479597, 'subsample': 0.726601685797026}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:53,843] Trial 639 finished with value: 0.10396042979470584 and parameters: {'depth': 10, 'learning_rate': 0.04914581532571534, 'lambda': 0.19526596149088848, 'alpha': 0.7316979543534944, 'subsample': 0.9760389537593064}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:15:58,095] Trial 640 finished with value: 0.10451430066620275 and parameters: {'depth': 10, 'learning_rate': 0.03574838735066858, 'lambda': 0.020440115334441525, 'alpha': 0.8291485919028269, 'subsample': 0.917049855395156}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:02,497] Trial 641 finished with value: 0.9149184448877716 and parameters: {'depth': 10, 'learning_rate': 0.0008574886262613414, 'lambda': 0.07348906760259728, 'alpha': 0.29767515281657536, 'subsample': 0.9493586419004975}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:06,669] Trial 642 finished with value: 0.10969569226372806 and parameters: {'depth': 10, 'learning_rate': 0.02812541115870579, 'lambda': 0.12762404936677643, 'alpha': 0.36830487128505635, 'subsample': 0.9359607579462578}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:10,623] Trial 643 finished with value: 0.10538255036005054 and parameters: {'depth': 10, 'learning_rate': 0.04838850444815647, 'lambda': 0.039294679508311336, 'alpha': 0.4190437015525879, 'subsample': 0.5689225221603889}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:14,629] Trial 644 finished with value: 0.10455108076322495 and parameters: {'depth': 10, 'learning_rate': 0.04647355291933744, 'lambda': 0.6745710812703805, 'alpha': 0.33396300209492585, 'subsample': 0.8986236751113431}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:16,850] Trial 645 finished with value: 0.11566335410470487 and parameters: {'depth': 8, 'learning_rate': 0.04344111313260097, 'lambda': 0.0642451827654588, 'alpha': 0.6428687439828261, 'subsample': 0.76275100463071}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:20,714] Trial 646 finished with value: 0.10448605687045125 and parameters: {'depth': 10, 'learning_rate': 0.04005302960266307, 'lambda': 0.28413150420314354, 'alpha': 0.46002336374934855, 'subsample': 0.8128456512166676}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:21,907] Trial 647 finished with value: 0.15496576870233358 and parameters: {'depth': 4, 'learning_rate': 0.04988417437951619, 'lambda': 0.9409273747682767, 'alpha': 0.5455546246909501, 'subsample': 0.98385581050655}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:25,691] Trial 648 finished with value: 0.10400428451516494 and parameters: {'depth': 10, 'learning_rate': 0.04999989214526431, 'lambda': 0.11273619477585356, 'alpha': 0.4381692704860066, 'subsample': 0.9721151477202522}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:28,589] Trial 649 finished with value: 0.10963055065583495 and parameters: {'depth': 9, 'learning_rate': 0.0474421305188663, 'lambda': 0.015939352135070976, 'alpha': 0.3860774531334491, 'subsample': 0.924019223952305}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:32,457] Trial 650 finished with value: 0.10402786285245615 and parameters: {'depth': 10, 'learning_rate': 0.048388232145884516, 'lambda': 0.16188155810123642, 'alpha': 0.9398638040258048, 'subsample': 0.8022636282800845}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:36,606] Trial 651 finished with value: 0.10395560008612058 and parameters: {'depth': 10, 'learning_rate': 0.04137863335440442, 'lambda': 0.0927306969597311, 'alpha': 0.5047583299405852, 'subsample': 0.9570502797464774}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:40,668] Trial 652 finished with value: 0.10413294318027595 and parameters: {'depth': 10, 'learning_rate': 0.04461868154302537, 'lambda': 0.389800373521264, 'alpha': 0.8668301642383848, 'subsample': 0.8864118778358929}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:44,554] Trial 653 finished with value: 0.1059006589059294 and parameters: {'depth': 10, 'learning_rate': 0.03346893593872208, 'lambda': 0.540108317465231, 'alpha': 0.920930202048914, 'subsample': 0.6487887464129051}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:48,648] Trial 654 finished with value: 0.12939594517413244 and parameters: {'depth': 10, 'learning_rate': 0.02205491678505715, 'lambda': 0.913100591104605, 'alpha': 0.34694146766379813, 'subsample': 0.9929484890366482}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:49,976] Trial 655 finished with value: 0.14744018349544824 and parameters: {'depth': 5, 'learning_rate': 0.02449615581960123, 'lambda': 0.0003790302599569473, 'alpha': 0.9332639887358858, 'subsample': 0.9453339348119127}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:53,964] Trial 656 finished with value: 0.10424041129985824 and parameters: {'depth': 10, 'learning_rate': 0.04912993199009132, 'lambda': 0.4790612357317909, 'alpha': 0.40839764178605675, 'subsample': 0.9069648436012951}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:55,753] Trial 657 finished with value: 0.3149769576400309 and parameters: {'depth': 7, 'learning_rate': 0.010813422036193752, 'lambda': 0.04973584317332227, 'alpha': 0.31196401519373335, 'subsample': 0.7069576363440861}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:16:59,831] Trial 658 finished with value: 0.10365027520336205 and parameters: {'depth': 10, 'learning_rate': 0.04725621452242394, 'lambda': 0.03155896867068024, 'alpha': 0.5712523867426336, 'subsample': 0.9663396230321273}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:03,661] Trial 659 finished with value: 0.10485498550598518 and parameters: {'depth': 10, 'learning_rate': 0.0482536101867521, 'lambda': 0.07581243630613234, 'alpha': 0.8912117801253969, 'subsample': 0.6380416139781129}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:07,506] Trial 660 finished with value: 0.10439270159940227 and parameters: {'depth': 10, 'learning_rate': 0.049134214543420845, 'lambda': 0.6513807482993921, 'alpha': 0.4731919807814207, 'subsample': 0.7704327290322129}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:11,611] Trial 661 finished with value: 0.1105696036834975 and parameters: {'depth': 10, 'learning_rate': 0.027647600356241125, 'lambda': 0.05988941976695409, 'alpha': 0.3663668566791093, 'subsample': 0.9303452566126298}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:14,574] Trial 662 finished with value: 0.11106324222861941 and parameters: {'depth': 9, 'learning_rate': 0.03251433550664803, 'lambda': 0.9979296762976885, 'alpha': 0.6249775780306431, 'subsample': 0.8669842476245377}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:18,517] Trial 663 finished with value: 0.10344024927574297 and parameters: {'depth': 10, 'learning_rate': 0.04999079725178987, 'lambda': 0.09467578580813081, 'alpha': 0.4425932649603257, 'subsample': 0.9177027140205991}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:22,829] Trial 664 finished with value: 0.7426571712719192 and parameters: {'depth': 10, 'learning_rate': 0.002858156027861925, 'lambda': 0.11912093211415814, 'alpha': 0.39829802078262766, 'subsample': 0.9757381602767758}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:26,923] Trial 665 finished with value: 0.10391097323029326 and parameters: {'depth': 10, 'learning_rate': 0.04621154623917275, 'lambda': 0.1793920763181531, 'alpha': 0.9801180615193035, 'subsample': 0.9994616136830811}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:30,896] Trial 666 finished with value: 0.10331326937139441 and parameters: {'depth': 10, 'learning_rate': 0.04999253240577473, 'lambda': 0.025238287895871583, 'alpha': 0.4272331137960434, 'subsample': 0.984537750959582}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:34,913] Trial 667 finished with value: 0.10358651743627711 and parameters: {'depth': 10, 'learning_rate': 0.04758235766889474, 'lambda': 0.05261960934361928, 'alpha': 0.27805222781478983, 'subsample': 0.9411805906248704}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:38,779] Trial 668 finished with value: 0.1035536468677912 and parameters: {'depth': 10, 'learning_rate': 0.04862721708492007, 'lambda': 0.22399166113874888, 'alpha': 0.8196847605619304, 'subsample': 0.9856245279320023}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:42,789] Trial 669 finished with value: 0.1033995478729547 and parameters: {'depth': 10, 'learning_rate': 0.0499703820593836, 'lambda': 0.03473658540104446, 'alpha': 0.21093273762102882, 'subsample': 0.9522982969177023}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:46,846] Trial 670 finished with value: 0.10359395246837858 and parameters: {'depth': 10, 'learning_rate': 0.04933446867329598, 'lambda': 0.038479024793008076, 'alpha': 0.22604720378740095, 'subsample': 0.9525164313243701}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:50,874] Trial 671 finished with value: 0.10345907888237547 and parameters: {'depth': 10, 'learning_rate': 0.04918997807906952, 'lambda': 0.02165290947345093, 'alpha': 0.23034979709050996, 'subsample': 0.9560664797346955}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:54,592] Trial 672 finished with value: 0.10600893665664354 and parameters: {'depth': 10, 'learning_rate': 0.049930630461219094, 'lambda': 0.407643923186525, 'alpha': 0.2325204229744505, 'subsample': 0.5542618993918523}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:17:58,771] Trial 673 finished with value: 0.10479639418717944 and parameters: {'depth': 10, 'learning_rate': 0.03628833863989492, 'lambda': 0.06862982627194322, 'alpha': 0.24431053638193284, 'subsample': 0.9621847313679291}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:02,671] Trial 674 finished with value: 0.10412337112240008 and parameters: {'depth': 10, 'learning_rate': 0.04851371627035979, 'lambda': 0.721788466311376, 'alpha': 0.19015872902874323, 'subsample': 0.9435363057410475}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:06,552] Trial 675 finished with value: 0.10460380263896703 and parameters: {'depth': 10, 'learning_rate': 0.04995966842874403, 'lambda': 0.8644332517017633, 'alpha': 0.07106185657843397, 'subsample': 0.9341340884005113}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:09,328] Trial 676 finished with value: 0.10988275934359758 and parameters: {'depth': 9, 'learning_rate': 0.04829543645766696, 'lambda': 0.0374297893039602, 'alpha': 0.026217341039716624, 'subsample': 0.7505704832122928}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:13,293] Trial 677 finished with value: 0.10398487490589935 and parameters: {'depth': 10, 'learning_rate': 0.047844495866059204, 'lambda': 0.29428233677483145, 'alpha': 0.18215881356743044, 'subsample': 0.6862234408822049}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:17,522] Trial 678 finished with value: 0.15815215144000797 and parameters: {'depth': 10, 'learning_rate': 0.018582840382005705, 'lambda': 0.019219370212714984, 'alpha': 0.8172866961687146, 'subsample': 0.7834856723680046}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:21,604] Trial 679 finished with value: 0.11281151184783626 and parameters: {'depth': 10, 'learning_rate': 0.02655781300226227, 'lambda': 0.05464134871705878, 'alpha': 0.176354585234611, 'subsample': 0.9688832645532265}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:25,807] Trial 680 finished with value: 0.18997277354893885 and parameters: {'depth': 10, 'learning_rate': 0.016246208362885012, 'lambda': 0.08587289997706245, 'alpha': 0.18296981620264638, 'subsample': 0.9997984795675166}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:29,817] Trial 681 finished with value: 0.10340192437260914 and parameters: {'depth': 10, 'learning_rate': 0.04906943999903108, 'lambda': 0.033164774017128085, 'alpha': 0.15697750750053216, 'subsample': 0.9496465057877828}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:34,157] Trial 682 finished with value: 0.8977017175354217 and parameters: {'depth': 10, 'learning_rate': 0.0010401386664515948, 'lambda': 0.06673518788235458, 'alpha': 0.7548213203571521, 'subsample': 0.8426190502826045}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:38,360] Trial 683 finished with value: 0.10534862328857214 and parameters: {'depth': 10, 'learning_rate': 0.03458704707817868, 'lambda': 0.010698794190281725, 'alpha': 0.11557592333922462, 'subsample': 0.9801272192243621}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:42,178] Trial 684 finished with value: 0.10467372333797494 and parameters: {'depth': 10, 'learning_rate': 0.049080664276831325, 'lambda': 0.5925624761312696, 'alpha': 0.10003182272980296, 'subsample': 0.962901339780265}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:46,505] Trial 685 finished with value: 0.5692107603250283 and parameters: {'depth': 10, 'learning_rate': 0.005388933932674131, 'lambda': 0.26725135494519914, 'alpha': 0.7773036290428397, 'subsample': 0.926875852942533}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:50,829] Trial 686 finished with value: 0.361274573908967 and parameters: {'depth': 10, 'learning_rate': 0.009696110773973669, 'lambda': 0.46109178141181134, 'alpha': 0.3808212382331244, 'subsample': 0.9440917889697646}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:54,841] Trial 687 finished with value: 0.10401461291958419 and parameters: {'depth': 10, 'learning_rate': 0.04996953228482984, 'lambda': 0.046361572477877075, 'alpha': 0.42282778976099794, 'subsample': 0.8309597005794567}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:18:58,977] Trial 688 finished with value: 0.1035136314944307 and parameters: {'depth': 10, 'learning_rate': 0.04733771816610745, 'lambda': 0.08237395143986846, 'alpha': 0.40438029332786907, 'subsample': 0.9743525163805651}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:03,116] Trial 689 finished with value: 0.14516090663631398 and parameters: {'depth': 10, 'learning_rate': 0.0198617259813474, 'lambda': 0.37457100957425266, 'alpha': 0.20255094270190496, 'subsample': 0.7205140193015467}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:07,076] Trial 690 finished with value: 0.10356564485273367 and parameters: {'depth': 10, 'learning_rate': 0.049972838254518696, 'lambda': 0.031668462574773425, 'alpha': 0.12602815916186147, 'subsample': 0.9877676676958428}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:09,808] Trial 691 finished with value: 0.10949146243165492 and parameters: {'depth': 9, 'learning_rate': 0.04823787024408776, 'lambda': 0.06696876579549185, 'alpha': 0.2234154828533772, 'subsample': 0.9362341200166137}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:13,664] Trial 692 finished with value: 0.10398665574896032 and parameters: {'depth': 10, 'learning_rate': 0.048530117549099354, 'lambda': 0.0984685200438804, 'alpha': 0.21175807997173182, 'subsample': 0.7959302327880713}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:17,153] Trial 693 finished with value: 0.10457837406166849 and parameters: {'depth': 10, 'learning_rate': 0.04675475702788323, 'lambda': 0.8421083264163504, 'alpha': 0.1270197799231482, 'subsample': 0.7573306612977485}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:20,985] Trial 694 finished with value: 0.10377942667013834 and parameters: {'depth': 10, 'learning_rate': 0.04999978614475054, 'lambda': 0.34050883609063215, 'alpha': 0.09822157343724142, 'subsample': 0.9515441494988115}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:21,955] Trial 695 finished with value: 0.2543462975990744 and parameters: {'depth': 2, 'learning_rate': 0.02407078467792828, 'lambda': 0.013056236120979885, 'alpha': 0.351602987364245, 'subsample': 0.5979307532466301}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:25,889] Trial 696 finished with value: 0.17318615155112388 and parameters: {'depth': 10, 'learning_rate': 0.017360666870675945, 'lambda': 0.050868416877340276, 'alpha': 0.13442263534490895, 'subsample': 0.9151262511158778}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:29,784] Trial 697 finished with value: 0.1339434736287846 and parameters: {'depth': 10, 'learning_rate': 0.021313302905247872, 'lambda': 0.0747845651320175, 'alpha': 0.25372648621008886, 'subsample': 0.9644661024989659}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:33,615] Trial 698 finished with value: 0.1061358972613357 and parameters: {'depth': 10, 'learning_rate': 0.03202025138993711, 'lambda': 0.5038899161210046, 'alpha': 0.6751034050536635, 'subsample': 0.9274258910943881}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:37,431] Trial 699 finished with value: 0.10513625365877459 and parameters: {'depth': 10, 'learning_rate': 0.03858206392309034, 'lambda': 0.00045452045038548924, 'alpha': 0.383885550015176, 'subsample': 0.6293678595900725}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:41,392] Trial 700 finished with value: 0.10889327720396141 and parameters: {'depth': 10, 'learning_rate': 0.029274660188213345, 'lambda': 0.0339709676129967, 'alpha': 0.2730231066682597, 'subsample': 0.5953274782369375}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:45,365] Trial 701 finished with value: 0.10407087716095884 and parameters: {'depth': 10, 'learning_rate': 0.04192334138986131, 'lambda': 0.11317633220382203, 'alpha': 0.4895251283305553, 'subsample': 0.6642715746775496}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:49,550] Trial 702 finished with value: 0.10366025750764134 and parameters: {'depth': 10, 'learning_rate': 0.04774640388872188, 'lambda': 0.05262524770824057, 'alpha': 0.1726562872642191, 'subsample': 0.8086889037706028}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:53,309] Trial 703 finished with value: 0.10393739615670122 and parameters: {'depth': 10, 'learning_rate': 0.04892957455612767, 'lambda': 0.3069641350747794, 'alpha': 0.055140436004444404, 'subsample': 0.9894637515518258}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:56,028] Trial 704 finished with value: 0.11184859220789274 and parameters: {'depth': 9, 'learning_rate': 0.03068706066131423, 'lambda': 0.41521195102190245, 'alpha': 0.4185515407505586, 'subsample': 0.9762867760832582}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:19:59,964] Trial 705 finished with value: 0.14910701677503438 and parameters: {'depth': 10, 'learning_rate': 0.019440911370240135, 'lambda': 0.08719892735004835, 'alpha': 0.44188190074944234, 'subsample': 0.9522404566110863}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:03,691] Trial 706 finished with value: 0.10515697985847228 and parameters: {'depth': 10, 'learning_rate': 0.04092604576871342, 'lambda': 0.018805155498374512, 'alpha': 0.2450200782242096, 'subsample': 0.6229525886582814}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:07,136] Trial 707 finished with value: 0.10425373387573303 and parameters: {'depth': 10, 'learning_rate': 0.0490242939473738, 'lambda': 0.665300462310929, 'alpha': 0.19121763831692845, 'subsample': 0.7781752350728012}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:10,703] Trial 708 finished with value: 0.10424735870699336 and parameters: {'depth': 10, 'learning_rate': 0.049995056728797414, 'lambda': 0.7880288303253986, 'alpha': 0.3682379780507556, 'subsample': 0.7407334940101596}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:14,354] Trial 709 finished with value: 0.21109895388689498 and parameters: {'depth': 10, 'learning_rate': 0.015049490526856552, 'lambda': 0.6097572832642679, 'alpha': 0.16658005330030384, 'subsample': 0.5029204768249991}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:18,062] Trial 710 finished with value: 0.10363196181713856 and parameters: {'depth': 10, 'learning_rate': 0.0474549856109941, 'lambda': 0.05134250505417873, 'alpha': 0.20078493106029868, 'subsample': 0.939777130346381}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:21,746] Trial 711 finished with value: 0.10467043726013843 and parameters: {'depth': 10, 'learning_rate': 0.039274611458111466, 'lambda': 0.10278377794956112, 'alpha': 0.46339253447184425, 'subsample': 0.7354802550912771}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:25,383] Trial 712 finished with value: 0.10492839303340921 and parameters: {'depth': 10, 'learning_rate': 0.04046488788412439, 'lambda': 0.3318743397480086, 'alpha': 0.4001563233578658, 'subsample': 0.7005582787614866}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:29,296] Trial 713 finished with value: 0.28070838628725836 and parameters: {'depth': 10, 'learning_rate': 0.012122245000004642, 'lambda': 0.07244273383933834, 'alpha': 0.3557775981866888, 'subsample': 0.9240339790641383}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:31,861] Trial 714 finished with value: 0.11027387054651927 and parameters: {'depth': 9, 'learning_rate': 0.048326378497218964, 'lambda': 0.7277776115703394, 'alpha': 0.01365935586434619, 'subsample': 0.9999817305713211}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:33,352] Trial 715 finished with value: 0.13068223794934097 and parameters: {'depth': 6, 'learning_rate': 0.04894110287550215, 'lambda': 0.8191792505603616, 'alpha': 0.42924862667488434, 'subsample': 0.619526949942135}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:34,449] Trial 716 finished with value: 0.1788106102953849 and parameters: {'depth': 3, 'learning_rate': 0.04282106944341071, 'lambda': 0.13419411311264884, 'alpha': 0.15948781839490866, 'subsample': 0.958844454578217}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:38,378] Trial 717 finished with value: 0.10546954761811712 and parameters: {'depth': 10, 'learning_rate': 0.03428373334960225, 'lambda': 0.6379275420676701, 'alpha': 0.3880390374300169, 'subsample': 0.9820796323621084}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:42,517] Trial 718 finished with value: 0.12050649506409708 and parameters: {'depth': 10, 'learning_rate': 0.02384174939300657, 'lambda': 0.6976436226650775, 'alpha': 0.5206759173391257, 'subsample': 0.9076986349707594}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:46,632] Trial 719 finished with value: 0.1036493893737142 and parameters: {'depth': 10, 'learning_rate': 0.045427650342236045, 'lambda': 0.03537972030793517, 'alpha': 0.45071056269321175, 'subsample': 0.9722024275361747}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:50,716] Trial 720 finished with value: 0.223611179731667 and parameters: {'depth': 10, 'learning_rate': 0.014432107666742796, 'lambda': 0.0629250128689643, 'alpha': 0.4150177162707255, 'subsample': 0.9333314083112313}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:54,802] Trial 721 finished with value: 0.11141485095880531 and parameters: {'depth': 10, 'learning_rate': 0.027423977027236885, 'lambda': 0.020413790697397086, 'alpha': 0.7008226611853574, 'subsample': 0.6282225200845426}. Best is trial 548 with value: 0.10313543781773155.\n",
      "[I 2023-08-29 15:20:59,012] Trial 722 finished with value: 0.47648821803130437 and parameters: {'depth': 10, 'learning_rate': 0.007069199833949172, 'lambda': 0.0827359275613712, 'alpha': 0.3723261392344912, 'subsample': 0.9192044982861489}. Best is trial 548 with value: 0.10313543781773155.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(xgb_objective_reg, n_trials=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6c00db0-001e-47f3-a7f1-c2d634a32773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:51:05,268] A new study created in memory with name: no-name-df856eb8-61e1-445b-b49a-5f4190127cfc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.620550915538727, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.620550915538727\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1776731469289237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1776731469289237\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1014644031286385, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1014644031286385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23925531425840824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23925531425840824\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.620550915538727, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.620550915538727\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1776731469289237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1776731469289237\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1014644031286385, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1014644031286385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23925531425840824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23925531425840824\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011079 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.002512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.19 MB) transferred to GPU in 0.001819 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.002181 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.016078 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.016182 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.014041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.018183 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.013320 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.020651 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.19 MB) transferred to GPU in 0.013358 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.014771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.013314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.20 MB) transferred to GPU in 0.014408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.620550915538727, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.620550915538727\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1776731469289237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1776731469289237\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1014644031286385, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1014644031286385\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23925531425840824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23925531425840824\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:51:27,558] Trial 0 finished with value: 0.5600493199912698 and parameters: {'lambda_l1': 0.1776731469289237, 'lambda_l2': 0.1014644031286385, 'num_leaves': 208, 'feature_fraction': 0.620550915538727, 'bagging_fraction': 0.23925531425840824, 'bagging_freq': 8, 'min_child_samples': 61, 'depth': 2, 'learning_rate': 0.008183169973273409}. Best is trial 0 with value: 0.5600493199912698.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2208147007977972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2208147007977972\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2561583468367563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2561583468367563\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38689707246889843, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38689707246889843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6519906999440717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6519906999440717\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2208147007977972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2208147007977972\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2561583468367563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2561583468367563\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38689707246889843, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38689707246889843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6519906999440717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6519906999440717\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.26 MB) transferred to GPU in 0.004902 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.26 MB) transferred to GPU in 0.007888 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.27 MB) transferred to GPU in 0.006197 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.26 MB) transferred to GPU in 0.005251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.26 MB) transferred to GPU in 0.004687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.27 MB) transferred to GPU in 0.047329 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.26 MB) transferred to GPU in 0.050927 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.27 MB) transferred to GPU in 0.005860 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2208147007977972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2208147007977972\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2561583468367563, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2561583468367563\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38689707246889843, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38689707246889843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6519906999440717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6519906999440717\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:51:35,424] Trial 1 finished with value: 0.5023248044433551 and parameters: {'lambda_l1': 0.2561583468367563, 'lambda_l2': 0.38689707246889843, 'num_leaves': 234, 'feature_fraction': 0.2208147007977972, 'bagging_fraction': 0.6519906999440717, 'bagging_freq': 14, 'min_child_samples': 1, 'depth': 5, 'learning_rate': 0.009491265323998415}. Best is trial 1 with value: 0.5023248044433551.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3591561737156401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3591561737156401\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8456098523961818, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8456098523961818\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10986235673580917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10986235673580917\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657113718561807, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657113718561807\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3591561737156401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3591561737156401\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8456098523961818, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8456098523961818\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10986235673580917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10986235673580917\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657113718561807, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657113718561807\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.005356 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.005984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.34 MB) transferred to GPU in 0.005036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.005019 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.006742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.004540 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.006663 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.34 MB) transferred to GPU in 0.006372 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.008547 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.004749 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.34 MB) transferred to GPU in 0.006615 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.041334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.029188 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.056514 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.34 MB) transferred to GPU in 0.043206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.039772 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.055418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.34 MB) transferred to GPU in 0.048297 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.33 MB) transferred to GPU in 0.005328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.34 MB) transferred to GPU in 0.006125 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:51:42,374] Trial 2 finished with value: 0.30081949082060205 and parameters: {'lambda_l1': 0.8456098523961818, 'lambda_l2': 0.10986235673580917, 'num_leaves': 423, 'feature_fraction': 0.3591561737156401, 'bagging_fraction': 0.6657113718561807, 'bagging_freq': 5, 'min_child_samples': 99, 'depth': 4, 'learning_rate': 0.018466731404698147}. Best is trial 2 with value: 0.30081949082060205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3591561737156401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3591561737156401\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8456098523961818, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8456098523961818\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.10986235673580917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10986235673580917\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6657113718561807, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6657113718561807\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5736476380426557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5736476380426557\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.46236880209591374, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.46236880209591374\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15800150239143737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15800150239143737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3715843354988789, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3715843354988789\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5736476380426557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5736476380426557\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.46236880209591374, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.46236880209591374\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15800150239143737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15800150239143737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3715843354988789, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3715843354988789\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.013544 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:51:43,598] Trial 3 finished with value: 0.554330694173789 and parameters: {'lambda_l1': 0.46236880209591374, 'lambda_l2': 0.15800150239143737, 'num_leaves': 31, 'feature_fraction': 0.5736476380426557, 'bagging_fraction': 0.3715843354988789, 'bagging_freq': 0, 'min_child_samples': 25, 'depth': 2, 'learning_rate': 0.008835193842477477}. Best is trial 2 with value: 0.30081949082060205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5736476380426557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5736476380426557\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.46236880209591374, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.46236880209591374\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.15800150239143737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.15800150239143737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3715843354988789, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3715843354988789\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879817986371911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879817986371911\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16133215837625361, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16133215837625361\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7660028000800924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7660028000800924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9702548544737815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9702548544737815\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.879817986371911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879817986371911\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16133215837625361, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16133215837625361\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7660028000800924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7660028000800924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9702548544737815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9702548544737815\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007829 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.007367 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.067106 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.055804 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.064629 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.056604 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.059701 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.059929 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.056181 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.006968 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.86 MB) transferred to GPU in 0.007107 secs. 1 sparse feature groups\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:51:49,378] Trial 4 finished with value: 0.29276308501538845 and parameters: {'lambda_l1': 0.16133215837625361, 'lambda_l2': 0.7660028000800924, 'num_leaves': 143, 'feature_fraction': 0.879817986371911, 'bagging_fraction': 0.9702548544737815, 'bagging_freq': 10, 'min_child_samples': 95, 'depth': 2, 'learning_rate': 0.029298153732611427}. Best is trial 4 with value: 0.29276308501538845.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.879817986371911, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.879817986371911\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16133215837625361, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16133215837625361\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7660028000800924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7660028000800924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9702548544737815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9702548544737815\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5627419272817765, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5627419272817765\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27830967044497373, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27830967044497373\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1512176118268605, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1512176118268605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5315869173693528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5315869173693528\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5627419272817765, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5627419272817765\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27830967044497373, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27830967044497373\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1512176118268605, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1512176118268605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5315869173693528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5315869173693528\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011941 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:51:50,742] Trial 5 finished with value: 0.28499016072166306 and parameters: {'lambda_l1': 0.27830967044497373, 'lambda_l2': 0.1512176118268605, 'num_leaves': 361, 'feature_fraction': 0.5627419272817765, 'bagging_fraction': 0.5315869173693528, 'bagging_freq': 1, 'min_child_samples': 62, 'depth': 2, 'learning_rate': 0.031567429271452264}. Best is trial 5 with value: 0.28499016072166306.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5627419272817765, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5627419272817765\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.27830967044497373, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.27830967044497373\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1512176118268605, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1512176118268605\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5315869173693528, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5315869173693528\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9700309294617072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9700309294617072\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.39243731087020767, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.39243731087020767\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7928434133626452, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7928434133626452\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5481108487832344, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5481108487832344\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9700309294617072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9700309294617072\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.39243731087020767, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.39243731087020767\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7928434133626452, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7928434133626452\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5481108487832344, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5481108487832344\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.087015 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.75 MB) transferred to GPU in 0.045643 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.74 MB) transferred to GPU in 0.043802 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.75 MB) transferred to GPU in 0.004681 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.74 MB) transferred to GPU in 0.004742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.74 MB) transferred to GPU in 0.004831 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.75 MB) transferred to GPU in 0.033448 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.74 MB) transferred to GPU in 0.045888 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.75 MB) transferred to GPU in 0.004614 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.74 MB) transferred to GPU in 0.005734 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.74 MB) transferred to GPU in 0.005087 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9700309294617072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9700309294617072\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.39243731087020767, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.39243731087020767\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7928434133626452, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7928434133626452\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5481108487832344, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5481108487832344\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:52:04,287] Trial 6 finished with value: 0.1329429194488744 and parameters: {'lambda_l1': 0.39243731087020767, 'lambda_l2': 0.7928434133626452, 'num_leaves': 183, 'feature_fraction': 0.9700309294617072, 'bagging_fraction': 0.5481108487832344, 'bagging_freq': 10, 'min_child_samples': 76, 'depth': 7, 'learning_rate': 0.043527270806703294}. Best is trial 6 with value: 0.1329429194488744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.37718500078942974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37718500078942974\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5448446660869835, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5448446660869835\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1126146565275935, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1126146565275935\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3161789232707758, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3161789232707758\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.37718500078942974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37718500078942974\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5448446660869835, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5448446660869835\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1126146565275935, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1126146565275935\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3161789232707758, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3161789232707758\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008934 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.003056 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.003321 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.002924 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.002980 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.002789 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.003200 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.002606 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.003261 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.002568 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.003193 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.002375 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.002485 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.002577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.002234 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.002091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.150992 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.037772 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.024369 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.019307 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.026126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.025458 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.023029 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.024508 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.019562 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.025059 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.020178 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.023590 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.018433 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.020020 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.57 MB) transferred to GPU in 0.020606 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.022082 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.044526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.003950 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.011076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.003796 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.009512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.005033 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.003600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.002875 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.003730 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.004372 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.004107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.003458 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.003672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.007812 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.006577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.007609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.004957 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.59 MB) transferred to GPU in 0.002947 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.58 MB) transferred to GPU in 0.003103 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.37718500078942974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.37718500078942974\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5448446660869835, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5448446660869835\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1126146565275935, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1126146565275935\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3161789232707758, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3161789232707758\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:52:11,038] Trial 7 finished with value: 0.20692732641010203 and parameters: {'lambda_l1': 0.5448446660869835, 'lambda_l2': 0.1126146565275935, 'num_leaves': 323, 'feature_fraction': 0.37718500078942974, 'bagging_fraction': 0.3161789232707758, 'bagging_freq': 2, 'min_child_samples': 65, 'depth': 3, 'learning_rate': 0.04734736095603375}. Best is trial 6 with value: 0.1329429194488744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9378451321915027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9378451321915027\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5279558127428792, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5279558127428792\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2865361205910457, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2865361205910457\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3052618336999326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3052618336999326\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9378451321915027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9378451321915027\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5279558127428792, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5279558127428792\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2865361205910457, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2865361205910457\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3052618336999326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3052618336999326\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007844 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.53 MB) transferred to GPU in 0.010190 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.53 MB) transferred to GPU in 0.002229 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.53 MB) transferred to GPU in 0.003190 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.53 MB) transferred to GPU in 0.003248 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.53 MB) transferred to GPU in 0.010298 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.54 MB) transferred to GPU in 0.003552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.53 MB) transferred to GPU in 0.003494 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.53 MB) transferred to GPU in 0.003578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.53 MB) transferred to GPU in 0.002684 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.52 MB) transferred to GPU in 0.002927 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9378451321915027, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9378451321915027\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5279558127428792, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5279558127428792\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2865361205910457, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2865361205910457\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3052618336999326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3052618336999326\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:52:12,603] Trial 8 finished with value: 0.30046536710162147 and parameters: {'lambda_l1': 0.5279558127428792, 'lambda_l2': 0.2865361205910457, 'num_leaves': 489, 'feature_fraction': 0.9378451321915027, 'bagging_fraction': 0.3052618336999326, 'bagging_freq': 10, 'min_child_samples': 38, 'depth': 2, 'learning_rate': 0.02852915215318766}. Best is trial 6 with value: 0.1329429194488744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6461993765844894, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6461993765844894\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13029391856326222, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13029391856326222\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11498088982909643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11498088982909643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3418290726548179, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3418290726548179\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6461993765844894, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6461993765844894\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13029391856326222, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13029391856326222\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11498088982909643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11498088982909643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3418290726548179, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3418290726548179\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009756 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.71 MB) transferred to GPU in 0.011212 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.71 MB) transferred to GPU in 0.002866 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.71 MB) transferred to GPU in 0.002243 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.71 MB) transferred to GPU in 0.002978 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.71 MB) transferred to GPU in 0.025463 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.72 MB) transferred to GPU in 0.002541 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (1.71 MB) transferred to GPU in 0.002556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6461993765844894, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6461993765844894\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13029391856326222, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13029391856326222\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.11498088982909643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11498088982909643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3418290726548179, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3418290726548179\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:52:28,760] Trial 9 finished with value: 0.8204821761609239 and parameters: {'lambda_l1': 0.13029391856326222, 'lambda_l2': 0.11498088982909643, 'num_leaves': 422, 'feature_fraction': 0.6461993765844894, 'bagging_fraction': 0.3418290726548179, 'bagging_freq': 15, 'min_child_samples': 81, 'depth': 8, 'learning_rate': 0.00038750245635716437}. Best is trial 6 with value: 0.1329429194488744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9910868940417391, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9910868940417391\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3498187062828753, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3498187062828753\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9672978679625529, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9672978679625529\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11476351298869403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11476351298869403\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9910868940417391, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9910868940417391\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3498187062828753, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3498187062828753\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9672978679625529, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9672978679625529\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11476351298869403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11476351298869403\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.021669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.58 MB) transferred to GPU in 0.010911 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.57 MB) transferred to GPU in 0.012065 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.57 MB) transferred to GPU in 0.001473 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.57 MB) transferred to GPU in 0.001502 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.58 MB) transferred to GPU in 0.001921 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.58 MB) transferred to GPU in 0.001411 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.57 MB) transferred to GPU in 0.001332 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.58 MB) transferred to GPU in 0.001303 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.57 MB) transferred to GPU in 0.009761 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9910868940417391, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9910868940417391\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3498187062828753, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3498187062828753\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9672978679625529, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9672978679625529\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.11476351298869403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.11476351298869403\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:52:40,897] Trial 10 finished with value: 0.13380564349767357 and parameters: {'lambda_l1': 0.3498187062828753, 'lambda_l2': 0.9672978679625529, 'num_leaves': 95, 'feature_fraction': 0.9910868940417391, 'bagging_fraction': 0.11476351298869403, 'bagging_freq': 12, 'min_child_samples': 80, 'depth': 10, 'learning_rate': 0.04992064863857302}. Best is trial 6 with value: 0.1329429194488744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9491406222489294, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9491406222489294\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.36270863118722696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.36270863118722696\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9656984544327064, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9656984544327064\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1012662155285201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1012662155285201\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9491406222489294, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9491406222489294\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.36270863118722696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.36270863118722696\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9656984544327064, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9656984544327064\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1012662155285201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1012662155285201\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011239 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.51 MB) transferred to GPU in 0.002049 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.51 MB) transferred to GPU in 0.001669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.51 MB) transferred to GPU in 0.001379 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.51 MB) transferred to GPU in 0.001362 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.51 MB) transferred to GPU in 0.001294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.51 MB) transferred to GPU in 0.001745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.51 MB) transferred to GPU in 0.015568 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.51 MB) transferred to GPU in 0.007450 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.51 MB) transferred to GPU in 0.001796 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9491406222489294, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9491406222489294\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.36270863118722696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.36270863118722696\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9656984544327064, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9656984544327064\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1012662155285201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1012662155285201\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:52:50,691] Trial 11 finished with value: 0.13342409746010903 and parameters: {'lambda_l1': 0.36270863118722696, 'lambda_l2': 0.9656984544327064, 'num_leaves': 83, 'feature_fraction': 0.9491406222489294, 'bagging_fraction': 0.1012662155285201, 'bagging_freq': 12, 'min_child_samples': 79, 'depth': 10, 'learning_rate': 0.04890418454992904}. Best is trial 6 with value: 0.1329429194488744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8603739838067639, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8603739838067639\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3578377978305625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3578377978305625\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.693608779205162, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.693608779205162\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309077137776613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.14309077137776613\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8603739838067639, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8603739838067639\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3578377978305625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3578377978305625\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.693608779205162, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.693608779205162\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309077137776613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.14309077137776613\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008855 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001947 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001811 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001446 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001304 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001440 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001841 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001726 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001992 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.71 MB) transferred to GPU in 0.001514 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001645 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.71 MB) transferred to GPU in 0.001709 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.71 MB) transferred to GPU in 0.001638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.72 MB) transferred to GPU in 0.001852 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8603739838067639, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8603739838067639\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3578377978305625, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3578377978305625\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.693608779205162, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.693608779205162\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.14309077137776613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.14309077137776613\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:52:51,604] Trial 12 finished with value: 0.2768856223859527 and parameters: {'lambda_l1': 0.3578377978305625, 'lambda_l2': 0.693608779205162, 'num_leaves': 3, 'feature_fraction': 0.8603739838067639, 'bagging_fraction': 0.14309077137776613, 'bagging_freq': 7, 'min_child_samples': 82, 'depth': 7, 'learning_rate': 0.041046593135202675}. Best is trial 6 with value: 0.1329429194488744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7870888416306085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870888416306085\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22067542476954166, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22067542476954166\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5992857964123589, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5992857964123589\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.489765148542039, subsample=1.0 will be ignored. Current value: bagging_fraction=0.489765148542039\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870888416306085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870888416306085\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22067542476954166, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22067542476954166\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5992857964123589, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5992857964123589\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.489765148542039, subsample=1.0 will be ignored. Current value: bagging_fraction=0.489765148542039\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.45 MB) transferred to GPU in 0.003720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.45 MB) transferred to GPU in 0.004146 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.46 MB) transferred to GPU in 0.004538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.45 MB) transferred to GPU in 0.003783 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.45 MB) transferred to GPU in 0.003983 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.45 MB) transferred to GPU in 0.031593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.45 MB) transferred to GPU in 0.003553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.46 MB) transferred to GPU in 0.005359 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.46 MB) transferred to GPU in 0.004159 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7870888416306085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7870888416306085\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22067542476954166, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22067542476954166\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5992857964123589, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5992857964123589\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.489765148542039, subsample=1.0 will be ignored. Current value: bagging_fraction=0.489765148542039\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:53:08,728] Trial 13 finished with value: 0.12686082290424067 and parameters: {'lambda_l1': 0.22067542476954166, 'lambda_l2': 0.5992857964123589, 'num_leaves': 148, 'feature_fraction': 0.7870888416306085, 'bagging_fraction': 0.489765148542039, 'bagging_freq': 12, 'min_child_samples': 48, 'depth': 10, 'learning_rate': 0.03999511502042928}. Best is trial 13 with value: 0.12686082290424067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7933721304995583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7933721304995583\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24636377404726553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24636377404726553\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5229373155364893, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5229373155364893\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4979804157184808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4979804157184808\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7933721304995583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7933721304995583\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24636377404726553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24636377404726553\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5229373155364893, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5229373155364893\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4979804157184808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4979804157184808\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.49 MB) transferred to GPU in 0.003815 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.49 MB) transferred to GPU in 0.005753 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.50 MB) transferred to GPU in 0.004822 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.49 MB) transferred to GPU in 0.003846 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.49 MB) transferred to GPU in 0.004519 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.50 MB) transferred to GPU in 0.005556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.49 MB) transferred to GPU in 0.004286 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.50 MB) transferred to GPU in 0.004751 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.50 MB) transferred to GPU in 0.005346 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7933721304995583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7933721304995583\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24636377404726553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24636377404726553\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5229373155364893, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5229373155364893\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4979804157184808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4979804157184808\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:53:24,773] Trial 14 finished with value: 0.12789019183910608 and parameters: {'lambda_l1': 0.24636377404726553, 'lambda_l2': 0.5229373155364893, 'num_leaves': 181, 'feature_fraction': 0.7933721304995583, 'bagging_fraction': 0.4979804157184808, 'bagging_freq': 12, 'min_child_samples': 44, 'depth': 8, 'learning_rate': 0.03830148223135381}. Best is trial 13 with value: 0.12686082290424067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.768105500409044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.768105500409044\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2181388733460887, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2181388733460887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5282890290177876, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5282890290177876\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46896605308013445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46896605308013445\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.768105500409044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.768105500409044\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2181388733460887, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2181388733460887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5282890290177876, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5282890290177876\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46896605308013445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46896605308013445\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007572 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.35 MB) transferred to GPU in 0.003391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.34 MB) transferred to GPU in 0.003718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.35 MB) transferred to GPU in 0.004349 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.35 MB) transferred to GPU in 0.025789 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.34 MB) transferred to GPU in 0.003399 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.35 MB) transferred to GPU in 0.004473 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.35 MB) transferred to GPU in 0.026974 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.35 MB) transferred to GPU in 0.004631 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.768105500409044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.768105500409044\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2181388733460887, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2181388733460887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5282890290177876, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5282890290177876\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.46896605308013445, subsample=1.0 will be ignored. Current value: bagging_fraction=0.46896605308013445\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:53:47,887] Trial 15 finished with value: 0.12610463524428905 and parameters: {'lambda_l1': 0.2181388733460887, 'lambda_l2': 0.5282890290177876, 'num_leaves': 254, 'feature_fraction': 0.768105500409044, 'bagging_fraction': 0.46896605308013445, 'bagging_freq': 13, 'min_child_samples': 39, 'depth': 9, 'learning_rate': 0.03728867132280462}. Best is trial 15 with value: 0.12610463524428905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.74836600379435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74836600379435\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19943691517123002, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19943691517123002\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5213820448790496, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5213820448790496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42676541826480285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42676541826480285\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.74836600379435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74836600379435\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19943691517123002, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19943691517123002\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5213820448790496, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5213820448790496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42676541826480285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42676541826480285\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.071487 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.14 MB) transferred to GPU in 0.024588 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.13 MB) transferred to GPU in 0.003283 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.14 MB) transferred to GPU in 0.027984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.14 MB) transferred to GPU in 0.003624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.13 MB) transferred to GPU in 0.003680 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.14 MB) transferred to GPU in 0.003543 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.13 MB) transferred to GPU in 0.003445 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (2.14 MB) transferred to GPU in 0.003277 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.74836600379435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.74836600379435\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19943691517123002, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19943691517123002\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5213820448790496, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5213820448790496\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42676541826480285, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42676541826480285\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:54:11,052] Trial 16 finished with value: 0.1276264767061773 and parameters: {'lambda_l1': 0.19943691517123002, 'lambda_l2': 0.5213820448790496, 'num_leaves': 283, 'feature_fraction': 0.74836600379435, 'bagging_fraction': 0.42676541826480285, 'bagging_freq': 14, 'min_child_samples': 27, 'depth': 9, 'learning_rate': 0.03539568737625507}. Best is trial 15 with value: 0.12610463524428905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7339327637432266, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7339327637432266\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10463680754654693, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10463680754654693\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.32771463177659427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.32771463177659427\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6390269093443113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6390269093443113\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7339327637432266, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7339327637432266\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10463680754654693, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10463680754654693\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.32771463177659427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.32771463177659427\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6390269093443113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6390269093443113\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.082983 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.046342 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.035992 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.21 MB) transferred to GPU in 0.006076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.004227 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.005820 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.038783 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.038566 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.21 MB) transferred to GPU in 0.005308 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.005272 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.004880 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.21 MB) transferred to GPU in 0.004081 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.19 MB) transferred to GPU in 0.041592 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.009976 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.005114 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.004444 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.004645 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.005174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.004780 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.005171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.21 MB) transferred to GPU in 0.048055 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.042320 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.004674 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.007303 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.004950 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.20 MB) transferred to GPU in 0.009583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7339327637432266, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7339327637432266\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10463680754654693, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10463680754654693\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.32771463177659427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.32771463177659427\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6390269093443113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6390269093443113\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:54:43,497] Trial 17 finished with value: 0.12257219835230039 and parameters: {'lambda_l1': 0.10463680754654693, 'lambda_l2': 0.32771463177659427, 'num_leaves': 300, 'feature_fraction': 0.7339327637432266, 'bagging_fraction': 0.6390269093443113, 'bagging_freq': 4, 'min_child_samples': 15, 'depth': 9, 'learning_rate': 0.03752241970409452}. Best is trial 17 with value: 0.12257219835230039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7125343972785855, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7125343972785855\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111604447977059, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111604447977059\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3332912721863411, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3332912721863411\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6569017445846973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6569017445846973\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7125343972785855, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7125343972785855\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111604447977059, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111604447977059\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3332912721863411, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3332912721863411\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6569017445846973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6569017445846973\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.008512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.006607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.30 MB) transferred to GPU in 0.007523 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.006118 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.28 MB) transferred to GPU in 0.007144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.004940 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.004755 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.004450 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.005387 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.004112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.30 MB) transferred to GPU in 0.036384 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.28 MB) transferred to GPU in 0.052785 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.044561 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.034622 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.30 MB) transferred to GPU in 0.035931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.006403 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.004984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.30 MB) transferred to GPU in 0.005437 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.004898 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.004390 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.007324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.006699 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.008286 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.29 MB) transferred to GPU in 0.010351 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.30 MB) transferred to GPU in 0.461288 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7125343972785855, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7125343972785855\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.111604447977059, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.111604447977059\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3332912721863411, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3332912721863411\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6569017445846973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6569017445846973\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:54:59,598] Trial 18 finished with value: 0.18880702709350936 and parameters: {'lambda_l1': 0.111604447977059, 'lambda_l2': 0.3332912721863411, 'num_leaves': 285, 'feature_fraction': 0.7125343972785855, 'bagging_fraction': 0.6569017445846973, 'bagging_freq': 4, 'min_child_samples': 9, 'depth': 6, 'learning_rate': 0.02286828895689122}. Best is trial 17 with value: 0.12257219835230039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6839099349405731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6839099349405731\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10386419705912786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10386419705912786\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24782043023998956, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24782043023998956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7768864322134532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7768864322134532\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6839099349405731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6839099349405731\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10386419705912786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10386419705912786\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24782043023998956, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24782043023998956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7768864322134532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7768864322134532\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.016070 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.009706 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.010920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.90 MB) transferred to GPU in 0.008423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.008036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.88 MB) transferred to GPU in 0.014112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.007736 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.007555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.008268 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.040926 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.052329 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.008138 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.010209 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.008018 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.008705 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.90 MB) transferred to GPU in 0.052394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.90 MB) transferred to GPU in 0.057925 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.009271 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.009261 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.009949 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.90 MB) transferred to GPU in 0.008991 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.005536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.041400 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.053525 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.89 MB) transferred to GPU in 0.007481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.90 MB) transferred to GPU in 0.005744 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6839099349405731, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6839099349405731\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10386419705912786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10386419705912786\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24782043023998956, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24782043023998956\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7768864322134532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7768864322134532\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:55:32,859] Trial 19 finished with value: 0.1246908089653234 and parameters: {'lambda_l1': 0.10386419705912786, 'lambda_l2': 0.24782043023998956, 'num_leaves': 366, 'feature_fraction': 0.6839099349405731, 'bagging_fraction': 0.7768864322134532, 'bagging_freq': 4, 'min_child_samples': 22, 'depth': 9, 'learning_rate': 0.03501991129712767}. Best is trial 17 with value: 0.12257219835230039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6786344140877923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6786344140877923\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10420113820254444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10420113820254444\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23318223251733888, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23318223251733888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8007542323845799, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8007542323845799\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6786344140877923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6786344140877923\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10420113820254444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10420113820254444\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23318223251733888, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23318223251733888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8007542323845799, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8007542323845799\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.006380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.047139 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.059890 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.006436 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.00 MB) transferred to GPU in 0.006359 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.008660 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.005786 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.005130 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.007521 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.049184 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.039894 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.005630 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.008474 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.006764 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.02 MB) transferred to GPU in 0.005820 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.004821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.005579 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.054283 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.054790 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.02 MB) transferred to GPU in 0.016878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.008656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.007208 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.007796 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.006334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.01 MB) transferred to GPU in 0.004794 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6786344140877923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6786344140877923\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10420113820254444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10420113820254444\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23318223251733888, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23318223251733888\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8007542323845799, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8007542323845799\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:55:56,589] Trial 20 finished with value: 0.13385642254293853 and parameters: {'lambda_l1': 0.10420113820254444, 'lambda_l2': 0.23318223251733888, 'num_leaves': 370, 'feature_fraction': 0.6786344140877923, 'bagging_fraction': 0.8007542323845799, 'bagging_freq': 4, 'min_child_samples': 18, 'depth': 8, 'learning_rate': 0.03348860937333099}. Best is trial 17 with value: 0.12257219835230039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.713313567749277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.713313567749277\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14557452834314263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14557452834314263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.429872551217872, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.429872551217872\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7620840698534543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7620840698534543\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.713313567749277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.713313567749277\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14557452834314263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14557452834314263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.429872551217872, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.429872551217872\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7620840698534543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7620840698534543\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.071785 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.043751 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.008618 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.005543 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.049846 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.81 MB) transferred to GPU in 0.005799 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.005979 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.81 MB) transferred to GPU in 0.055540 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.008842 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.81 MB) transferred to GPU in 0.007492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.005908 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.054401 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.006350 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.006661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.056159 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.010279 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.005947 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.82 MB) transferred to GPU in 0.005681 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.713313567749277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.713313567749277\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14557452834314263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14557452834314263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.429872551217872, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.429872551217872\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7620840698534543, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7620840698534543\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:56:29,334] Trial 21 finished with value: 0.12302619549428571 and parameters: {'lambda_l1': 0.14557452834314263, 'lambda_l2': 0.429872551217872, 'num_leaves': 333, 'feature_fraction': 0.713313567749277, 'bagging_fraction': 0.7620840698534543, 'bagging_freq': 6, 'min_child_samples': 35, 'depth': 9, 'learning_rate': 0.03712791618405506}. Best is trial 17 with value: 0.12257219835230039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4908155202922744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4908155202922744\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13579324265436535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13579324265436535\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4067756880530618, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4067756880530618\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7888422430658019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7888422430658019\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4908155202922744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4908155202922744\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13579324265436535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13579324265436535\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4067756880530618, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4067756880530618\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7888422430658019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7888422430658019\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.082278 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.042453 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.005110 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.005552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.060640 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.006235 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.006488 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.004680 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.056318 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.005914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.006117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.005672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.056967 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.005990 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.007246 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.96 MB) transferred to GPU in 0.006916 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.005985 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.064659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4908155202922744, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4908155202922744\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13579324265436535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13579324265436535\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4067756880530618, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4067756880530618\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7888422430658019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7888422430658019\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:57:02,851] Trial 22 finished with value: 0.12383391166171884 and parameters: {'lambda_l1': 0.13579324265436535, 'lambda_l2': 0.4067756880530618, 'num_leaves': 340, 'feature_fraction': 0.4908155202922744, 'bagging_fraction': 0.7888422430658019, 'bagging_freq': 6, 'min_child_samples': 28, 'depth': 9, 'learning_rate': 0.042304871652934374}. Best is trial 17 with value: 0.12257219835230039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.48886511505317287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48886511505317287\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13960987737639666, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13960987737639666\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.41110235798828754, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.41110235798828754\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.787115015860563, subsample=1.0 will be ignored. Current value: bagging_fraction=0.787115015860563\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48886511505317287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48886511505317287\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13960987737639666, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13960987737639666\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.41110235798828754, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.41110235798828754\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.787115015860563, subsample=1.0 will be ignored. Current value: bagging_fraction=0.787115015860563\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010179 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.006452 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.005224 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.005599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.006056 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.93 MB) transferred to GPU in 0.047850 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.047069 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.006926 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.005940 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.006933 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.007567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.005389 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.004912 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.006595 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.056674 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.051655 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.95 MB) transferred to GPU in 0.006287 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.94 MB) transferred to GPU in 0.006807 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48886511505317287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48886511505317287\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13960987737639666, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13960987737639666\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.41110235798828754, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.41110235798828754\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.787115015860563, subsample=1.0 will be ignored. Current value: bagging_fraction=0.787115015860563\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:57:17,246] Trial 23 finished with value: 0.13433071385449524 and parameters: {'lambda_l1': 0.13960987737639666, 'lambda_l2': 0.41110235798828754, 'num_leaves': 320, 'feature_fraction': 0.48886511505317287, 'bagging_fraction': 0.787115015860563, 'bagging_freq': 6, 'min_child_samples': 32, 'depth': 7, 'learning_rate': 0.04369874882728539}. Best is trial 17 with value: 0.12257219835230039.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4902516635318902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4902516635318902\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1420121816283706, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1420121816283706\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.40762700971325133, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.40762700971325133\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8813546751107926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8813546751107926\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4902516635318902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4902516635318902\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1420121816283706, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1420121816283706\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.40762700971325133, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.40762700971325133\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8813546751107926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8813546751107926\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006928 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.006420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.352015 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.011286 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.009299 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.007893 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.138002 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.008672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.009916 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.014087 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.008219 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.013912 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.009350 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.41 MB) transferred to GPU in 0.008416 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4902516635318902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4902516635318902\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1420121816283706, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1420121816283706\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.40762700971325133, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.40762700971325133\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8813546751107926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8813546751107926\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:58:19,861] Trial 24 finished with value: 0.12133192483365905 and parameters: {'lambda_l1': 0.1420121816283706, 'lambda_l2': 0.40762700971325133, 'num_leaves': 425, 'feature_fraction': 0.4902516635318902, 'bagging_fraction': 0.8813546751107926, 'bagging_freq': 8, 'min_child_samples': 14, 'depth': 9, 'learning_rate': 0.04420285686654737}. Best is trial 24 with value: 0.12133192483365905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6125698665959853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6125698665959853\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1594601772340237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1594601772340237\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3399710805636841, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3399710805636841\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9372562332567882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9372562332567882\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6125698665959853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6125698665959853\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1594601772340237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1594601772340237\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3399710805636841, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3399710805636841\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9372562332567882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9372562332567882\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.020484 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.009693 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.007195 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.010538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.096738 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.009284 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.007153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.010364 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.010964 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.011480 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.010187 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.010765 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.010619 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.011397 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6125698665959853, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6125698665959853\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1594601772340237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1594601772340237\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3399710805636841, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3399710805636841\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9372562332567882, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9372562332567882\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:58:36,308] Trial 25 finished with value: 0.13485627701843672 and parameters: {'lambda_l1': 0.1594601772340237, 'lambda_l2': 0.3399710805636841, 'num_leaves': 430, 'feature_fraction': 0.6125698665959853, 'bagging_fraction': 0.9372562332567882, 'bagging_freq': 8, 'min_child_samples': 15, 'depth': 6, 'learning_rate': 0.0452156938712613}. Best is trial 24 with value: 0.12133192483365905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7183298190474418, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7183298190474418\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11944335075513389, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11944335075513389\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.44155252592341265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.44155252592341265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8829506341429493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8829506341429493\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7183298190474418, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7183298190474418\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11944335075513389, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11944335075513389\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.44155252592341265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.44155252592341265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8829506341429493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8829506341429493\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.012967 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.012882 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.009212 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.013185 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.009827 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.007314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.007175 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.009905 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.010969 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.009262 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.008961 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.105540 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.007133 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.008508 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.008824 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.008691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.010127 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.008565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.008878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.014672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.011022 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.010532 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.012679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.005433 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.004364 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.059538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.057930 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.047872 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.009758 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.009053 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.007225 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.006641 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.006118 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.008150 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.007306 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7183298190474418, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7183298190474418\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11944335075513389, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11944335075513389\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.44155252592341265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.44155252592341265\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8829506341429493, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8829506341429493\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:59:07,575] Trial 26 finished with value: 0.12441901050584774 and parameters: {'lambda_l1': 0.11944335075513389, 'lambda_l2': 0.44155252592341265, 'num_leaves': 478, 'feature_fraction': 0.7183298190474418, 'bagging_fraction': 0.8829506341429493, 'bagging_freq': 3, 'min_child_samples': 9, 'depth': 8, 'learning_rate': 0.039556616431746947}. Best is trial 24 with value: 0.12133192483365905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.851221058423507, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.851221058423507\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.100471004863325, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.100471004863325\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29257820185671485, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29257820185671485\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.874096556357059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.874096556357059\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.851221058423507, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.851221058423507\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.100471004863325, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.100471004863325\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29257820185671485, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29257820185671485\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.874096556357059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.874096556357059\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.075758 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.049258 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.008051 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.009815 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.008637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006754 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.008044 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.050720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.008670 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.008599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006776 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.851221058423507, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.851221058423507\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.100471004863325, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.100471004863325\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29257820185671485, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29257820185671485\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.874096556357059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.874096556357059\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 16:59:47,354] Trial 27 finished with value: 0.1158233756219235 and parameters: {'lambda_l1': 0.100471004863325, 'lambda_l2': 0.29257820185671485, 'num_leaves': 398, 'feature_fraction': 0.851221058423507, 'bagging_fraction': 0.874096556357059, 'bagging_freq': 9, 'min_child_samples': 3, 'depth': 10, 'learning_rate': 0.046244807856712346}. Best is trial 27 with value: 0.1158233756219235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8506598087389519, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8506598087389519\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1027168430323423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1027168430323423\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2813098822006244, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2813098822006244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9892912243760825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9892912243760825\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8506598087389519, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8506598087389519\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1027168430323423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1027168430323423\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2813098822006244, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2813098822006244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9892912243760825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9892912243760825\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007722 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.96 MB) transferred to GPU in 0.007405 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.007260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.96 MB) transferred to GPU in 0.007024 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.96 MB) transferred to GPU in 0.057501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.007010 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.007670 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.96 MB) transferred to GPU in 0.008109 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.007675 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.056229 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.006952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.96 MB) transferred to GPU in 0.006821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.96 MB) transferred to GPU in 0.055994 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8506598087389519, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8506598087389519\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1027168430323423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1027168430323423\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2813098822006244, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2813098822006244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9892912243760825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9892912243760825\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:00:25,478] Trial 28 finished with value: 0.11343129973389852 and parameters: {'lambda_l1': 0.1027168430323423, 'lambda_l2': 0.2813098822006244, 'num_leaves': 452, 'feature_fraction': 0.8506598087389519, 'bagging_fraction': 0.9892912243760825, 'bagging_freq': 9, 'min_child_samples': 2, 'depth': 10, 'learning_rate': 0.046549918619471074}. Best is trial 28 with value: 0.11343129973389852.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8493054575333774, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8493054575333774\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17478000881653685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17478000881653685\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2663489641040155, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2663489641040155\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9242919831734736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9242919831734736\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8493054575333774, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8493054575333774\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17478000881653685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17478000881653685\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2663489641040155, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2663489641040155\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9242919831734736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9242919831734736\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.006318 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007219 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.006894 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.006895 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.010221 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.006610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007768 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008133 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007971 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008770 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.009953 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.012145 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8493054575333774, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8493054575333774\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17478000881653685, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17478000881653685\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2663489641040155, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2663489641040155\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9242919831734736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9242919831734736\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:01:14,436] Trial 29 finished with value: 0.11496790295293194 and parameters: {'lambda_l1': 0.17478000881653685, 'lambda_l2': 0.2663489641040155, 'num_leaves': 450, 'feature_fraction': 0.8493054575333774, 'bagging_fraction': 0.9242919831734736, 'bagging_freq': 9, 'min_child_samples': 1, 'depth': 10, 'learning_rate': 0.04600029450249378}. Best is trial 28 with value: 0.11343129973389852.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.860731904837994, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.860731904837994\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.182486541998572, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.182486541998572\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.253027447075799, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.253027447075799\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9942454909559719, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9942454909559719\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.860731904837994, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.860731904837994\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.182486541998572, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.182486541998572\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.253027447075799, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.253027447075799\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9942454909559719, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9942454909559719\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010690 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.009849 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.010401 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.091573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.013594 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.064981 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.012092 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.014809 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.012952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.014372 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.008084 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.009645 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.015825 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.860731904837994, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.860731904837994\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.182486541998572, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.182486541998572\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.253027447075799, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.253027447075799\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9942454909559719, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9942454909559719\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:02:17,110] Trial 30 finished with value: 0.11334655533109637 and parameters: {'lambda_l1': 0.182486541998572, 'lambda_l2': 0.253027447075799, 'num_leaves': 470, 'feature_fraction': 0.860731904837994, 'bagging_fraction': 0.9942454909559719, 'bagging_freq': 9, 'min_child_samples': 1, 'depth': 10, 'learning_rate': 0.04658152369503388}. Best is trial 30 with value: 0.11334655533109637.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8625433386276691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8625433386276691\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17793795097663173, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17793795097663173\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2634497195340113, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2634497195340113\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9884569129762387, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9884569129762387\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8625433386276691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8625433386276691\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17793795097663173, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17793795097663173\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2634497195340113, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2634497195340113\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9884569129762387, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9884569129762387\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010923 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.009128 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.065822 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.009880 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.009323 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.007250 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.008477 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.061913 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.007069 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.007437 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.067858 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.007937 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.95 MB) transferred to GPU in 0.008058 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8625433386276691, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8625433386276691\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17793795097663173, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17793795097663173\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2634497195340113, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2634497195340113\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9884569129762387, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9884569129762387\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:03:11,037] Trial 31 finished with value: 0.11133381906751748 and parameters: {'lambda_l1': 0.17793795097663173, 'lambda_l2': 0.2634497195340113, 'num_leaves': 511, 'feature_fraction': 0.8625433386276691, 'bagging_fraction': 0.9884569129762387, 'bagging_freq': 9, 'min_child_samples': 4, 'depth': 10, 'learning_rate': 0.04688726854454414}. Best is trial 31 with value: 0.11133381906751748.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8943692260733905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8943692260733905\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17129394578874127, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17129394578874127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2379852373231178, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2379852373231178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9657694621042426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9657694621042426\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8943692260733905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8943692260733905\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17129394578874127, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17129394578874127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2379852373231178, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2379852373231178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9657694621042426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9657694621042426\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007046 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.009592 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.079709 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.009054 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.009549 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.073953 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008930 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.010593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.067924 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.005786 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8943692260733905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8943692260733905\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17129394578874127, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17129394578874127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2379852373231178, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2379852373231178\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9657694621042426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9657694621042426\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:04:01,900] Trial 32 finished with value: 0.11230699559640281 and parameters: {'lambda_l1': 0.17129394578874127, 'lambda_l2': 0.2379852373231178, 'num_leaves': 465, 'feature_fraction': 0.8943692260733905, 'bagging_fraction': 0.9657694621042426, 'bagging_freq': 9, 'min_child_samples': 3, 'depth': 10, 'learning_rate': 0.0493485151154623}. Best is trial 31 with value: 0.11133381906751748.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9056310335387008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9056310335387008\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.194714278354781, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.194714278354781\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21876741829864643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21876741829864643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9814843293659323, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9814843293659323\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9056310335387008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9056310335387008\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.194714278354781, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.194714278354781\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21876741829864643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21876741829864643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9814843293659323, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9814843293659323\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.072474 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.055054 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.008701 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.007529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.055129 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.007620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.024102 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.068297 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.007397 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.012980 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.008642 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.007794 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.008845 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9056310335387008, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9056310335387008\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.194714278354781, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.194714278354781\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21876741829864643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21876741829864643\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9814843293659323, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9814843293659323\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:04:58,793] Trial 33 finished with value: 0.10984358228392692 and parameters: {'lambda_l1': 0.194714278354781, 'lambda_l2': 0.21876741829864643, 'num_leaves': 501, 'feature_fraction': 0.9056310335387008, 'bagging_fraction': 0.9814843293659323, 'bagging_freq': 9, 'min_child_samples': 7, 'depth': 10, 'learning_rate': 0.04964870129175945}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9241276613479837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9241276613479837\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18699077734199301, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18699077734199301\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23456306494871765, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23456306494871765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9981720139550795, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9981720139550795\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9241276613479837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9241276613479837\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18699077734199301, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18699077734199301\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23456306494871765, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23456306494871765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9981720139550795, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9981720139550795\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.068953 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.053539 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008344 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010979 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008860 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009335 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008052 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.006844 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.063028 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.063237 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9241276613479837, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9241276613479837\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18699077734199301, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18699077734199301\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23456306494871765, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23456306494871765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9981720139550795, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9981720139550795\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:05:10,241] Trial 34 finished with value: 0.14562455205416494 and parameters: {'lambda_l1': 0.18699077734199301, 'lambda_l2': 0.23456306494871765, 'num_leaves': 512, 'feature_fraction': 0.9241276613479837, 'bagging_fraction': 0.9981720139550795, 'bagging_freq': 11, 'min_child_samples': 9, 'depth': 5, 'learning_rate': 0.0498264366564357}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9118093204281397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9118093204281397\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17535032859423036, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17535032859423036\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2054329139449679, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2054329139449679\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9981379981835601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9981379981835601\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9118093204281397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9118093204281397\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17535032859423036, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17535032859423036\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2054329139449679, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2054329139449679\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9981379981835601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9981379981835601\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007054 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007913 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007393 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.076752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.011294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.058367 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009291 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.059963 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007731 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.063324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.015166 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.098870 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010712 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010640 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9118093204281397, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9118093204281397\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17535032859423036, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17535032859423036\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2054329139449679, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2054329139449679\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9981379981835601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9981379981835601\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:06:13,095] Trial 35 finished with value: 0.10987842171120163 and parameters: {'lambda_l1': 0.17535032859423036, 'lambda_l2': 0.2054329139449679, 'num_leaves': 509, 'feature_fraction': 0.9118093204281397, 'bagging_fraction': 0.9981379981835601, 'bagging_freq': 7, 'min_child_samples': 6, 'depth': 10, 'learning_rate': 0.049769229269166625}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9986468718994942, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9986468718994942\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16226474471834873, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16226474471834873\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20688338166087203, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20688338166087203\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9172361081457157, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9172361081457157\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9986468718994942, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9986468718994942\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16226474471834873, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16226474471834873\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20688338166087203, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20688338166087203\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9172361081457157, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9172361081457157\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.018182 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.011328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.057320 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.006505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.014835 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.011999 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.009239 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.013509 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.010874 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.013104 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.055305 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.60 MB) transferred to GPU in 0.011432 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.012647 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.60 MB) transferred to GPU in 0.006747 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.006303 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.60 MB) transferred to GPU in 0.008158 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9986468718994942, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9986468718994942\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16226474471834873, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16226474471834873\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20688338166087203, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20688338166087203\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9172361081457157, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9172361081457157\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:07:31,586] Trial 36 finished with value: 0.11267954378732743 and parameters: {'lambda_l1': 0.16226474471834873, 'lambda_l2': 0.20688338166087203, 'num_leaves': 506, 'feature_fraction': 0.9986468718994942, 'bagging_fraction': 0.9172361081457157, 'bagging_freq': 7, 'min_child_samples': 8, 'depth': 10, 'learning_rate': 0.04249712942301086}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9256698262410935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9256698262410935\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26928682689434463, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26928682689434463\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1923030247445297, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1923030247445297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9494582351109301, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9494582351109301\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9256698262410935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9256698262410935\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26928682689434463, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26928682689434463\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1923030247445297, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1923030247445297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9494582351109301, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9494582351109301\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009940 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.006307 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.083025 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007120 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.009943 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.010616 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.012466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009861 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008259 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.006022 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007963 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008189 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.010143 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009650 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9256698262410935, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9256698262410935\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26928682689434463, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26928682689434463\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1923030247445297, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1923030247445297\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9494582351109301, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9494582351109301\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:07:46,462] Trial 37 finished with value: 0.12003234215196022 and parameters: {'lambda_l1': 0.26928682689434463, 'lambda_l2': 0.1923030247445297, 'num_leaves': 464, 'feature_fraction': 0.9256698262410935, 'bagging_fraction': 0.9494582351109301, 'bagging_freq': 7, 'min_child_samples': 19, 'depth': 8, 'learning_rate': 0.04950142738051741}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9000441495764204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000441495764204\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20577900366008223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20577900366008223\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19284158575005111, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19284158575005111\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455560512713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455560512713879\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000441495764204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000441495764204\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20577900366008223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20577900366008223\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19284158575005111, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19284158575005111\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455560512713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455560512713879\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008256 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.005535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.23 MB) transferred to GPU in 0.005149 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.007989 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.007303 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.23 MB) transferred to GPU in 0.008016 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.007117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.23 MB) transferred to GPU in 0.008898 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.005686 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.23 MB) transferred to GPU in 0.005719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.006848 secs. 1 sparse feature groups\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:07:49,373] Trial 38 finished with value: 0.16431583489889595 and parameters: {'lambda_l1': 0.20577900366008223, 'lambda_l2': 0.19284158575005111, 'num_leaves': 493, 'feature_fraction': 0.9000441495764204, 'bagging_fraction': 0.8455560512713879, 'bagging_freq': 11, 'min_child_samples': 57, 'depth': 4, 'learning_rate': 0.04258298311770813}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9000441495764204, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9000441495764204\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20577900366008223, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20577900366008223\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19284158575005111, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19284158575005111\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455560512713879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455560512713879\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8047866152444432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8047866152444432\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2380829983533822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2380829983533822\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16288721159599862, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16288721159599862\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9558393362437607, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9558393362437607\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8047866152444432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8047866152444432\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2380829983533822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2380829983533822\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16288721159599862, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16288721159599862\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9558393362437607, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9558393362437607\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007224 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.008901 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.009147 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.009560 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.007202 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.008117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.007992 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.008482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.006640 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.008970 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.005752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8047866152444432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8047866152444432\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2380829983533822, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2380829983533822\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16288721159599862, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16288721159599862\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9558393362437607, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9558393362437607\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:08:08,994] Trial 39 finished with value: 0.11341631484995959 and parameters: {'lambda_l1': 0.2380829983533822, 'lambda_l2': 0.16288721159599862, 'num_leaves': 404, 'feature_fraction': 0.8047866152444432, 'bagging_fraction': 0.9558393362437607, 'bagging_freq': 10, 'min_child_samples': 7, 'depth': 9, 'learning_rate': 0.048248228913566324}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9045848609628673, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045848609628673\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2913655415848521, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2913655415848521\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21637801226894257, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21637801226894257\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111943987353369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111943987353369\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045848609628673, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045848609628673\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2913655415848521, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2913655415848521\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21637801226894257, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21637801226894257\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111943987353369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111943987353369\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008768 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.008331 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007276 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.006830 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007779 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007349 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.005491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.008726 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.009153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.008075 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.008045 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.006079 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.006809 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9045848609628673, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9045848609628673\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2913655415848521, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2913655415848521\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21637801226894257, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21637801226894257\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9111943987353369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9111943987353369\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:08:30,730] Trial 40 finished with value: 0.1114672998248005 and parameters: {'lambda_l1': 0.2913655415848521, 'lambda_l2': 0.21637801226894257, 'num_leaves': 512, 'feature_fraction': 0.9045848609628673, 'bagging_fraction': 0.9111943987353369, 'bagging_freq': 8, 'min_child_samples': 24, 'depth': 10, 'learning_rate': 0.044399804399442855}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9089411711479388, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9089411711479388\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.30283670041595906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.30283670041595906\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21707931084763069, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21707931084763069\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9550808788992358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9550808788992358\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9089411711479388, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9089411711479388\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.30283670041595906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.30283670041595906\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21707931084763069, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21707931084763069\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9550808788992358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9550808788992358\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011088 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.008662 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.010277 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.007093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.010318 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.007211 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.007751 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.007343 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.005784 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.007220 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.006798 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.007841 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.007209 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.007612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9089411711479388, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9089411711479388\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.30283670041595906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.30283670041595906\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21707931084763069, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21707931084763069\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9550808788992358, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9550808788992358\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:08:56,924] Trial 41 finished with value: 0.1108648305363016 and parameters: {'lambda_l1': 0.30283670041595906, 'lambda_l2': 0.21707931084763069, 'num_leaves': 512, 'feature_fraction': 0.9089411711479388, 'bagging_fraction': 0.9550808788992358, 'bagging_freq': 8, 'min_child_samples': 13, 'depth': 10, 'learning_rate': 0.04482927606392068}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9614023709325161, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9614023709325161\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2990474060147193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2990474060147193\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20644829652175242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20644829652175242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9113759487531349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9113759487531349\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9614023709325161, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9614023709325161\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2990474060147193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2990474060147193\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20644829652175242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20644829652175242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9113759487531349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9113759487531349\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008078 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.005036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.006909 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.006147 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.006657 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.007933 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.004702 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.009682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.008164 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.006947 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.006066 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.008399 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9614023709325161, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9614023709325161\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2990474060147193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2990474060147193\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20644829652175242, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20644829652175242\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9113759487531349, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9113759487531349\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:09:18,604] Trial 42 finished with value: 0.11168461022588858 and parameters: {'lambda_l1': 0.2990474060147193, 'lambda_l2': 0.20644829652175242, 'num_leaves': 509, 'feature_fraction': 0.9614023709325161, 'bagging_fraction': 0.9113759487531349, 'bagging_freq': 8, 'min_child_samples': 23, 'depth': 10, 'learning_rate': 0.04442212648622031}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9120274690689805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9120274690689805\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29356982743163695, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29356982743163695\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17853186173119556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17853186173119556\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9933189094120453, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9933189094120453\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9120274690689805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9120274690689805\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29356982743163695, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29356982743163695\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17853186173119556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17853186173119556\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9933189094120453, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9933189094120453\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007270 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.010760 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.97 MB) transferred to GPU in 0.006193 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.97 MB) transferred to GPU in 0.007330 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.008960 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.97 MB) transferred to GPU in 0.007107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.97 MB) transferred to GPU in 0.008121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.009826 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.97 MB) transferred to GPU in 0.008654 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.97 MB) transferred to GPU in 0.008505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.006309 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.011455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.008074 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.007784 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.008141 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.97 MB) transferred to GPU in 0.008052 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.007604 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.98 MB) transferred to GPU in 0.006527 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9120274690689805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9120274690689805\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.29356982743163695, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.29356982743163695\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17853186173119556, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17853186173119556\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9933189094120453, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9933189094120453\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:09:38,896] Trial 43 finished with value: 0.11718998932826655 and parameters: {'lambda_l1': 0.29356982743163695, 'lambda_l2': 0.17853186173119556, 'num_leaves': 485, 'feature_fraction': 0.9120274690689805, 'bagging_fraction': 0.9933189094120453, 'bagging_freq': 6, 'min_child_samples': 13, 'depth': 9, 'learning_rate': 0.04050460797819107}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9713302224901369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9713302224901369\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24782830550344107, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24782830550344107\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21932315031406296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21932315031406296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9440792462584249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9440792462584249\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9713302224901369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9713302224901369\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24782830550344107, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24782830550344107\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21932315031406296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21932315031406296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9440792462584249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9440792462584249\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007572 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.007891 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.006681 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.007636 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.009916 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.008479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.008222 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.009244 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.007707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.007227 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.010126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.009730 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.008514 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.008235 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.005970 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.73 MB) transferred to GPU in 0.008250 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9713302224901369, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9713302224901369\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24782830550344107, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24782830550344107\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21932315031406296, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21932315031406296\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9440792462584249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9440792462584249\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:10:02,185] Trial 44 finished with value: 0.11153079013438051 and parameters: {'lambda_l1': 0.24782830550344107, 'lambda_l2': 0.21932315031406296, 'num_leaves': 445, 'feature_fraction': 0.9713302224901369, 'bagging_fraction': 0.9440792462584249, 'bagging_freq': 7, 'min_child_samples': 21, 'depth': 10, 'learning_rate': 0.047260876320412946}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9453172761837718, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9453172761837718\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.31922014286233996, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31922014286233996\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1508301626385734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1508301626385734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8468251033256903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8468251033256903\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9453172761837718, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9453172761837718\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.31922014286233996, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31922014286233996\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1508301626385734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1508301626385734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8468251033256903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8468251033256903\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.008218 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.008880 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.005481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.008597 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.23 MB) transferred to GPU in 0.005278 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.006707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.006972 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.008679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.006653 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.006789 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.009325 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.009484 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.007255 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.005971 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.008383 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.007604 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.007194 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.007238 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.005873 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.24 MB) transferred to GPU in 0.005238 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9453172761837718, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9453172761837718\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.31922014286233996, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.31922014286233996\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1508301626385734, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1508301626385734\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8468251033256903, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8468251033256903\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:10:25,554] Trial 45 finished with value: 0.1118940824934037 and parameters: {'lambda_l1': 0.31922014286233996, 'lambda_l2': 0.1508301626385734, 'num_leaves': 486, 'feature_fraction': 0.9453172761837718, 'bagging_fraction': 0.8468251033256903, 'bagging_freq': 5, 'min_child_samples': 12, 'depth': 10, 'learning_rate': 0.04456413858642627}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8062772080382477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8062772080382477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22164243302572706, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22164243302572706\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2697705324650778, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2697705324650778\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9072337241381923, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9072337241381923\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8062772080382477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8062772080382477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22164243302572706, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22164243302572706\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2697705324650778, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2697705324650778\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9072337241381923, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9072337241381923\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008832 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.55 MB) transferred to GPU in 0.007749 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.55 MB) transferred to GPU in 0.008424 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.012340 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.011661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007542 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.008371 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.009503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.55 MB) transferred to GPU in 0.006633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.008237 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007588 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8062772080382477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8062772080382477\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22164243302572706, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22164243302572706\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2697705324650778, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2697705324650778\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9072337241381923, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9072337241381923\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:10:37,535] Trial 46 finished with value: 0.1189537014551409 and parameters: {'lambda_l1': 0.22164243302572706, 'lambda_l2': 0.2697705324650778, 'num_leaves': 395, 'feature_fraction': 0.8062772080382477, 'bagging_fraction': 0.9072337241381923, 'bagging_freq': 8, 'min_child_samples': 6, 'depth': 8, 'learning_rate': 0.04739918434129187}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.824068914598424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.824068914598424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2728105567004984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2728105567004984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17330939577299448, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17330939577299448\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499634842698063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499634842698063\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.824068914598424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.824068914598424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2728105567004984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2728105567004984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17330939577299448, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17330939577299448\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499634842698063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499634842698063\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007236 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008822 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007897 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007846 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.005762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006863 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006714 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.010238 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.005912 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008021 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007699 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.824068914598424, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.824068914598424\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2728105567004984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2728105567004984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.17330939577299448, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.17330939577299448\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9499634842698063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9499634842698063\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:10:54,613] Trial 47 finished with value: 0.11740048058112801 and parameters: {'lambda_l1': 0.2728105567004984, 'lambda_l2': 0.17330939577299448, 'num_leaves': 510, 'feature_fraction': 0.824068914598424, 'bagging_fraction': 0.9499634842698063, 'bagging_freq': 11, 'min_child_samples': 29, 'depth': 9, 'learning_rate': 0.04189231067426758}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8850744928547541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8850744928547541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23245806772348138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23245806772348138\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21808122636923583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21808122636923583\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9955951288786087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9955951288786087\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8850744928547541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8850744928547541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23245806772348138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23245806772348138\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21808122636923583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21808122636923583\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9955951288786087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9955951288786087\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009072 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.010665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.009421 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.007676 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.009046 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.007818 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.008832 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.007460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.009041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.010147 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.99 MB) transferred to GPU in 0.007178 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8850744928547541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8850744928547541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23245806772348138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23245806772348138\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21808122636923583, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21808122636923583\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9955951288786087, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9955951288786087\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:11:19,893] Trial 48 finished with value: 0.11447972325763961 and parameters: {'lambda_l1': 0.23245806772348138, 'lambda_l2': 0.21808122636923583, 'num_leaves': 434, 'feature_fraction': 0.8850744928547541, 'bagging_fraction': 0.9955951288786087, 'bagging_freq': 10, 'min_child_samples': 17, 'depth': 10, 'learning_rate': 0.04032229539587452}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9733883104878072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9733883104878072\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20230574249553573, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20230574249553573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1381088630484784, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1381088630484784\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8281824574406469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8281824574406469\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9733883104878072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9733883104878072\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20230574249553573, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20230574249553573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1381088630484784, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1381088630484784\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8281824574406469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8281824574406469\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006006 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.005361 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.006752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.006313 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.006068 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.14 MB) transferred to GPU in 0.004733 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.008605 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.007449 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.005530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.14 MB) transferred to GPU in 0.005598 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.008727 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.007566 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.008718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.005668 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.007078 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.007011 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.006743 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.005864 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.005246 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.007586 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.15 MB) transferred to GPU in 0.006500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9733883104878072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9733883104878072\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20230574249553573, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20230574249553573\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1381088630484784, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1381088630484784\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8281824574406469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8281824574406469\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:11:32,503] Trial 49 finished with value: 0.11841437829377015 and parameters: {'lambda_l1': 0.20230574249553573, 'lambda_l2': 0.1381088630484784, 'num_leaves': 224, 'feature_fraction': 0.9733883104878072, 'bagging_fraction': 0.8281824574406469, 'bagging_freq': 5, 'min_child_samples': 71, 'depth': 9, 'learning_rate': 0.04762482252397041}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7650887717084403, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7650887717084403\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41438860791428944, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41438860791428944\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28875430297004184, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28875430297004184\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8927572253602287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8927572253602287\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7650887717084403, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7650887717084403\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41438860791428944, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41438860791428944\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28875430297004184, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28875430297004184\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8927572253602287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8927572253602287\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007941 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:11:34,095] Trial 50 finished with value: 0.18804785907980448 and parameters: {'lambda_l1': 0.41438860791428944, 'lambda_l2': 0.28875430297004184, 'num_leaves': 479, 'feature_fraction': 0.7650887717084403, 'bagging_fraction': 0.8927572253602287, 'bagging_freq': 0, 'min_child_samples': 11, 'depth': 3, 'learning_rate': 0.04512188600060873}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7650887717084403, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7650887717084403\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41438860791428944, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41438860791428944\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28875430297004184, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28875430297004184\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8927572253602287, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8927572253602287\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9819308450227902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9819308450227902\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2510204012350511, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2510204012350511\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21926005246506167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21926005246506167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9483343942332458, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9483343942332458\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9819308450227902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9819308450227902\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2510204012350511, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2510204012350511\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21926005246506167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21926005246506167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9483343942332458, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9483343942332458\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007787 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.008204 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.005583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.006160 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007711 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007747 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.006240 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.006817 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.006788 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007136 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007062 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.006622 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.014534 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.015305 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.012695 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.022325 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9819308450227902, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9819308450227902\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2510204012350511, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2510204012350511\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21926005246506167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21926005246506167\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9483343942332458, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9483343942332458\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:11:55,365] Trial 51 finished with value: 0.11090851992270763 and parameters: {'lambda_l1': 0.2510204012350511, 'lambda_l2': 0.21926005246506167, 'num_leaves': 448, 'feature_fraction': 0.9819308450227902, 'bagging_fraction': 0.9483343942332458, 'bagging_freq': 7, 'min_child_samples': 20, 'depth': 10, 'learning_rate': 0.049952329799463034}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8997261014550337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8997261014550337\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.25549460231198, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25549460231198\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19094339993294274, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19094339993294274\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9534049100772786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9534049100772786\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8997261014550337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8997261014550337\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.25549460231198, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25549460231198\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19094339993294274, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19094339993294274\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9534049100772786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9534049100772786\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.017139 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.015813 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.014679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.017280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.015476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.015052 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.015635 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.015593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.015459 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.018208 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.015179 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.012700 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.015442 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.018229 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.015419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.015752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8997261014550337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8997261014550337\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.25549460231198, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25549460231198\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19094339993294274, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19094339993294274\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9534049100772786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9534049100772786\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:12:16,200] Trial 52 finished with value: 0.1127959274248909 and parameters: {'lambda_l1': 0.25549460231198, 'lambda_l2': 0.19094339993294274, 'num_leaves': 455, 'feature_fraction': 0.8997261014550337, 'bagging_fraction': 0.9534049100772786, 'bagging_freq': 7, 'min_child_samples': 90, 'depth': 10, 'learning_rate': 0.0495323015500859}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9396964996523612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9396964996523612\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3188411724411366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3188411724411366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2202816908735528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2202816908735528\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9166356785391786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9166356785391786\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9396964996523612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9396964996523612\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3188411724411366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3188411724411366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2202816908735528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2202816908735528\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9166356785391786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9166356785391786\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.015687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.015014 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.017010 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.014888 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.014724 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.014560 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.016505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.007742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.006724 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.006380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.006027 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.007764 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.006431 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.005844 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9396964996523612, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9396964996523612\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3188411724411366, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3188411724411366\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2202816908735528, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2202816908735528\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9166356785391786, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9166356785391786\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:12:37,870] Trial 53 finished with value: 0.11027879173264177 and parameters: {'lambda_l1': 0.3188411724411366, 'lambda_l2': 0.2202816908735528, 'num_leaves': 492, 'feature_fraction': 0.9396964996523612, 'bagging_fraction': 0.9166356785391786, 'bagging_freq': 8, 'min_child_samples': 25, 'depth': 10, 'learning_rate': 0.049982076354978915}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9975772080495484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975772080495484\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3229636531683363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3229636531683363\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2553407878038255, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2553407878038255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9734372142506476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9734372142506476\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975772080495484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975772080495484\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3229636531683363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3229636531683363\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2553407878038255, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2553407878038255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9734372142506476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9734372142506476\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007586 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.006424 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.87 MB) transferred to GPU in 0.008406 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007688 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008136 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.87 MB) transferred to GPU in 0.006141 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007029 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.006283 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.87 MB) transferred to GPU in 0.006168 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.87 MB) transferred to GPU in 0.006442 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007150 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.006897 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9975772080495484, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9975772080495484\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3229636531683363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3229636531683363\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2553407878038255, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2553407878038255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9734372142506476, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9734372142506476\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:12:53,844] Trial 54 finished with value: 0.11435226815902289 and parameters: {'lambda_l1': 0.3229636531683363, 'lambda_l2': 0.2553407878038255, 'num_leaves': 489, 'feature_fraction': 0.9975772080495484, 'bagging_fraction': 0.9734372142506476, 'bagging_freq': 9, 'min_child_samples': 5, 'depth': 9, 'learning_rate': 0.0474633006673223}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9363750597672126, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9363750597672126\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19421438081895342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19421438081895342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23352048404073963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23352048404073963\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9300565664741899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9300565664741899\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9363750597672126, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9363750597672126\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19421438081895342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19421438081895342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23352048404073963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23352048404073963\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9300565664741899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9300565664741899\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007888 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.005969 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.005321 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006963 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006302 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006284 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006047 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006141 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006249 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.007343 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006273 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.005643 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006549 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.009081 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.007995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006484 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9363750597672126, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9363750597672126\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19421438081895342, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19421438081895342\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23352048404073963, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23352048404073963\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9300565664741899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9300565664741899\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:13:11,333] Trial 55 finished with value: 0.11071584378084427 and parameters: {'lambda_l1': 0.19421438081895342, 'lambda_l2': 0.23352048404073963, 'num_leaves': 409, 'feature_fraction': 0.9363750597672126, 'bagging_fraction': 0.9300565664741899, 'bagging_freq': 6, 'min_child_samples': 19, 'depth': 10, 'learning_rate': 0.04972816400649852}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9513841657657347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9513841657657347\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26438186271098196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26438186271098196\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2269860343367036, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2269860343367036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85918491478847, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85918491478847\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9513841657657347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9513841657657347\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26438186271098196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26438186271098196\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2269860343367036, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2269860343367036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85918491478847, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85918491478847\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007058 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.007063 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.007433 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.31 MB) transferred to GPU in 0.005125 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.009313 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.005559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.006080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.006744 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.006291 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.009391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.007984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.008277 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.008268 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.005689 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.31 MB) transferred to GPU in 0.005362 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.31 MB) transferred to GPU in 0.008805 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.31 MB) transferred to GPU in 0.009170 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.30 MB) transferred to GPU in 0.006007 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9513841657657347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9513841657657347\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26438186271098196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26438186271098196\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2269860343367036, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2269860343367036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85918491478847, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85918491478847\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:13:17,780] Trial 56 finished with value: 0.1274187685170654 and parameters: {'lambda_l1': 0.26438186271098196, 'lambda_l2': 0.2269860343367036, 'num_leaves': 376, 'feature_fraction': 0.9513841657657347, 'bagging_fraction': 0.85918491478847, 'bagging_freq': 6, 'min_child_samples': 44, 'depth': 7, 'learning_rate': 0.04859556331675389}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9347383874602463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9347383874602463\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1971708918425897, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1971708918425897\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19833976330635059, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19833976330635059\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.92656348506968, subsample=1.0 will be ignored. Current value: bagging_fraction=0.92656348506968\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9347383874602463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9347383874602463\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1971708918425897, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1971708918425897\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19833976330635059, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19833976330635059\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.92656348506968, subsample=1.0 will be ignored. Current value: bagging_fraction=0.92656348506968\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008694 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.009296 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.006140 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.005968 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.005773 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.010387 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.005846 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.007828 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.007570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.005573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.009625 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.006328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.008128 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.005577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.007153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.007255 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.010070 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.008806 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.011760 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.011763 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.010377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9347383874602463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9347383874602463\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1971708918425897, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1971708918425897\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19833976330635059, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19833976330635059\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.92656348506968, subsample=1.0 will be ignored. Current value: bagging_fraction=0.92656348506968\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:13:30,429] Trial 57 finished with value: 0.11458733126254622 and parameters: {'lambda_l1': 0.1971708918425897, 'lambda_l2': 0.19833976330635059, 'num_leaves': 413, 'feature_fraction': 0.9347383874602463, 'bagging_fraction': 0.92656348506968, 'bagging_freq': 5, 'min_child_samples': 31, 'depth': 9, 'learning_rate': 0.049994744205669316}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9981290897665159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9981290897665159\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22394253240502526, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22394253240502526\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18066395387800582, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18066395387800582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7380353604868419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7380353604868419\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9981290897665159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9981290897665159\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22394253240502526, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22394253240502526\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18066395387800582, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18066395387800582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7380353604868419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7380353604868419\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.006531 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.009775 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.007761 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.009018 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.69 MB) transferred to GPU in 0.009699 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.008358 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.69 MB) transferred to GPU in 0.008959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.008636 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.69 MB) transferred to GPU in 0.006973 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.008220 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.006507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.69 MB) transferred to GPU in 0.006594 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.004910 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.008637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (3.70 MB) transferred to GPU in 0.007047 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9981290897665159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9981290897665159\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22394253240502526, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22394253240502526\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18066395387800582, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18066395387800582\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7380353604868419, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7380353604868419\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:13:53,410] Trial 58 finished with value: 0.11417122760543465 and parameters: {'lambda_l1': 0.22394253240502526, 'lambda_l2': 0.18066395387800582, 'num_leaves': 433, 'feature_fraction': 0.9981290897665159, 'bagging_fraction': 0.7380353604868419, 'bagging_freq': 7, 'min_child_samples': 19, 'depth': 10, 'learning_rate': 0.043439171593264145}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8247682582282236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8247682582282236\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24300913823633513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24300913823633513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23563855692087912, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23563855692087912\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8260665913429263, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8260665913429263\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8247682582282236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8247682582282236\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24300913823633513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24300913823633513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23563855692087912, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23563855692087912\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8260665913429263, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8260665913429263\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006464 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.14 MB) transferred to GPU in 0.005533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.13 MB) transferred to GPU in 0.005737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.14 MB) transferred to GPU in 0.007251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.14 MB) transferred to GPU in 0.006327 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.13 MB) transferred to GPU in 0.007032 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.14 MB) transferred to GPU in 0.006745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.14 MB) transferred to GPU in 0.006552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.14 MB) transferred to GPU in 0.007300 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.13 MB) transferred to GPU in 0.006489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.14 MB) transferred to GPU in 0.007530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8247682582282236, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8247682582282236\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.24300913823633513, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.24300913823633513\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23563855692087912, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23563855692087912\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8260665913429263, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8260665913429263\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:14:06,832] Trial 59 finished with value: 0.11544159983210608 and parameters: {'lambda_l1': 0.24300913823633513, 'lambda_l2': 0.23563855692087912, 'num_leaves': 385, 'feature_fraction': 0.8247682582282236, 'bagging_fraction': 0.8260665913429263, 'bagging_freq': 10, 'min_child_samples': 36, 'depth': 9, 'learning_rate': 0.048037924304124846}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9551150084632848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9551150084632848\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20982730330610913, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20982730330610913\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2104956684315709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2104956684315709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8787597152444198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8787597152444198\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9551150084632848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9551150084632848\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20982730330610913, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20982730330610913\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2104956684315709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2104956684315709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8787597152444198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8787597152444198\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007575 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.009830 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.009261 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.008189 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.007048 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.008014 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.011955 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.008748 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.008807 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.009745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.008205 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.010477 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.008646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.009145 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.007036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.007102 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.010611 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.007544 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.008412 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.010171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.40 MB) transferred to GPU in 0.007353 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9551150084632848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9551150084632848\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20982730330610913, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20982730330610913\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2104956684315709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2104956684315709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8787597152444198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8787597152444198\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:14:26,402] Trial 60 finished with value: 0.11177918461948043 and parameters: {'lambda_l1': 0.20982730330610913, 'lambda_l2': 0.2104956684315709, 'num_leaves': 470, 'feature_fraction': 0.9551150084632848, 'bagging_fraction': 0.8787597152444198, 'bagging_freq': 5, 'min_child_samples': 25, 'depth': 10, 'learning_rate': 0.04528890997232675}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.886770479174207, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.886770479174207\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15211030282574403, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15211030282574403\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.259351987483056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.259351987483056\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9652324238398347, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9652324238398347\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.886770479174207, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.886770479174207\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15211030282574403, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15211030282574403\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.259351987483056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.259351987483056\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9652324238398347, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9652324238398347\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008834 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.008242 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.011205 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.010634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.009872 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.010200 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007641 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008000 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.009307 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.011285 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.012875 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.008123 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.009867 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.886770479174207, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.886770479174207\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15211030282574403, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15211030282574403\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.259351987483056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.259351987483056\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9652324238398347, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9652324238398347\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:14:51,072] Trial 61 finished with value: 0.11042031299401082 and parameters: {'lambda_l1': 0.15211030282574403, 'lambda_l2': 0.259351987483056, 'num_leaves': 492, 'feature_fraction': 0.886770479174207, 'bagging_fraction': 0.9652324238398347, 'bagging_freq': 8, 'min_child_samples': 11, 'depth': 10, 'learning_rate': 0.04634687555998679}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9344971417077869, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9344971417077869\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1573222134707758, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1573222134707758\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30027534577032194, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30027534577032194\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9619144027114847, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9619144027114847\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9344971417077869, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9344971417077869\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1573222134707758, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1573222134707758\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30027534577032194, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30027534577032194\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9619144027114847, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9619144027114847\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010604 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007629 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008230 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009816 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.012314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.019683 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.016633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.020129 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.012698 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.016469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.015309 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.011421 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008836 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9344971417077869, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9344971417077869\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1573222134707758, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1573222134707758\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30027534577032194, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30027534577032194\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9619144027114847, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9619144027114847\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:15:21,192] Trial 62 finished with value: 0.11021167680271374 and parameters: {'lambda_l1': 0.1573222134707758, 'lambda_l2': 0.30027534577032194, 'num_leaves': 493, 'feature_fraction': 0.9344971417077869, 'bagging_fraction': 0.9619144027114847, 'bagging_freq': 8, 'min_child_samples': 16, 'depth': 10, 'learning_rate': 0.04794032406744977}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8760546057672823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8760546057672823\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15434374513373533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15434374513373533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.31359683020167484, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.31359683020167484\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985816486532352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985816486532352\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8760546057672823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8760546057672823\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15434374513373533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15434374513373533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.31359683020167484, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.31359683020167484\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985816486532352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985816486532352\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006658 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.007213 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.007092 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.009051 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.009661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.008357 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.008526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.008935 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.008577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.012111 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.008655 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.009495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.007593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.006749 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8760546057672823, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8760546057672823\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15434374513373533, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15434374513373533\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.31359683020167484, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.31359683020167484\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8985816486532352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8985816486532352\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:15:44,115] Trial 63 finished with value: 0.11064564305218366 and parameters: {'lambda_l1': 0.15434374513373533, 'lambda_l2': 0.31359683020167484, 'num_leaves': 494, 'feature_fraction': 0.8760546057672823, 'bagging_fraction': 0.8985816486532352, 'bagging_freq': 8, 'min_child_samples': 16, 'depth': 10, 'learning_rate': 0.04579317696035792}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8714027219599717, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8714027219599717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1561805365517698, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1561805365517698\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3084085326514541, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3084085326514541\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8901446979544909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8901446979544909\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8714027219599717, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8714027219599717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1561805365517698, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1561805365517698\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3084085326514541, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3084085326514541\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8901446979544909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8901446979544909\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.007576 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.45 MB) transferred to GPU in 0.010023 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.008354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.009238 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.007793 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.008752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.009793 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.009330 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.008993 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.009373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.008398 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.008556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.008073 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8714027219599717, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8714027219599717\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1561805365517698, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1561805365517698\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3084085326514541, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3084085326514541\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8901446979544909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8901446979544909\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:16:01,300] Trial 64 finished with value: 0.11657720510166553 and parameters: {'lambda_l1': 0.1561805365517698, 'lambda_l2': 0.3084085326514541, 'num_leaves': 495, 'feature_fraction': 0.8714027219599717, 'bagging_fraction': 0.8901446979544909, 'bagging_freq': 8, 'min_child_samples': 16, 'depth': 9, 'learning_rate': 0.0417159085823772}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9358833782818313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9358833782818313\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12747917119508284, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12747917119508284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3553989131254929, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3553989131254929\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9228593675942449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9228593675942449\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9358833782818313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9358833782818313\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12747917119508284, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12747917119508284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3553989131254929, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3553989131254929\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9228593675942449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9228593675942449\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006617 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.007038 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.010621 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.007778 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.007887 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.007827 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.007238 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.008198 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.006791 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.007958 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.008549 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.006934 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.023205 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.007803 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.008261 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.008282 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007005 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.009368 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9358833782818313, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9358833782818313\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12747917119508284, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12747917119508284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3553989131254929, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3553989131254929\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9228593675942449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9228593675942449\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:16:22,398] Trial 65 finished with value: 0.11049417327786587 and parameters: {'lambda_l1': 0.12747917119508284, 'lambda_l2': 0.3553989131254929, 'num_leaves': 468, 'feature_fraction': 0.9358833782818313, 'bagging_fraction': 0.9228593675942449, 'bagging_freq': 6, 'min_child_samples': 12, 'depth': 10, 'learning_rate': 0.04828157698487144}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8831942804290941, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8831942804290941\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12845738957900935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12845738957900935\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.36715505631450446, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.36715505631450446\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8657245949417958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8657245949417958\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8831942804290941, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8831942804290941\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12845738957900935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12845738957900935\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.36715505631450446, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.36715505631450446\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8657245949417958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8657245949417958\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007799 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.006224 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.007902 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.007542 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.007931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.006713 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.008085 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.008798 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.007762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.007148 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.008368 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8831942804290941, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8831942804290941\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12845738957900935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12845738957900935\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.36715505631450446, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.36715505631450446\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8657245949417958, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8657245949417958\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:16:36,954] Trial 66 finished with value: 0.11430153071109961 and parameters: {'lambda_l1': 0.12845738957900935, 'lambda_l2': 0.36715505631450446, 'num_leaves': 469, 'feature_fraction': 0.8831942804290941, 'bagging_fraction': 0.8657245949417958, 'bagging_freq': 10, 'min_child_samples': 11, 'depth': 9, 'learning_rate': 0.04592126430229952}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8384516925670452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8384516925670452\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15150893326045875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15150893326045875\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.31487105081855654, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.31487105081855654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9070605357526835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9070605357526835\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8384516925670452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8384516925670452\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15150893326045875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15150893326045875\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.31487105081855654, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.31487105081855654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9070605357526835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9070605357526835\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008613 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007774 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007977 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007833 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007863 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.008537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.006476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.008563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007965 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007706 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.006914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.009361 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007791 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8384516925670452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8384516925670452\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15150893326045875, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15150893326045875\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.31487105081855654, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.31487105081855654\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9070605357526835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9070605357526835\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:16:46,874] Trial 67 finished with value: 0.12132717090393119 and parameters: {'lambda_l1': 0.15150893326045875, 'lambda_l2': 0.31487105081855654, 'num_leaves': 488, 'feature_fraction': 0.8384516925670452, 'bagging_fraction': 0.9070605357526835, 'bagging_freq': 8, 'min_child_samples': 16, 'depth': 8, 'learning_rate': 0.043019353379437596}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7916561775571846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7916561775571846\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1443230873376357, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1443230873376357\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.36115622334632186, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.36115622334632186\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9748402875983139, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9748402875983139\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7916561775571846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7916561775571846\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1443230873376357, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1443230873376357\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.36115622334632186, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.36115622334632186\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9748402875983139, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9748402875983139\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007202 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.006767 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008581 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007337 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.011173 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009347 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007689 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.006782 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008838 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008413 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008767 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009347 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.016256 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.015232 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.014343 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.015280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7916561775571846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7916561775571846\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1443230873376357, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1443230873376357\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.36115622334632186, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.36115622334632186\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9748402875983139, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9748402875983139\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:17:13,016] Trial 68 finished with value: 0.11170068915287895 and parameters: {'lambda_l1': 0.1443230873376357, 'lambda_l2': 0.36115622334632186, 'num_leaves': 442, 'feature_fraction': 0.7916561775571846, 'bagging_fraction': 0.9748402875983139, 'bagging_freq': 6, 'min_child_samples': 6, 'depth': 10, 'learning_rate': 0.0480761444480766}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8740700302998534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8740700302998534\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12295710998479209, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12295710998479209\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3010861129494269, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3010861129494269\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9736198589208198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9736198589208198\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8740700302998534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8740700302998534\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12295710998479209, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12295710998479209\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3010861129494269, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3010861129494269\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9736198589208198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9736198589208198\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010582 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.010418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.87 MB) transferred to GPU in 0.009748 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.010804 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009947 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.87 MB) transferred to GPU in 0.007941 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.012346 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009390 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008309 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009273 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009268 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009151 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009845 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.012455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8740700302998534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8740700302998534\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12295710998479209, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12295710998479209\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3010861129494269, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3010861129494269\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9736198589208198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9736198589208198\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:17:23,398] Trial 69 finished with value: 0.13374775677732073 and parameters: {'lambda_l1': 0.12295710998479209, 'lambda_l2': 0.3010861129494269, 'num_leaves': 125, 'feature_fraction': 0.8740700302998534, 'bagging_fraction': 0.9736198589208198, 'bagging_freq': 7, 'min_child_samples': 26, 'depth': 9, 'learning_rate': 0.03844265131215768}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9253800749288611, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9253800749288611\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16171104062763844, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16171104062763844\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2782415370668179, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2782415370668179\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8100261561989136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8100261561989136\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9253800749288611, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9253800749288611\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16171104062763844, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16171104062763844\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2782415370668179, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2782415370668179\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8100261561989136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8100261561989136\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.06 MB) transferred to GPU in 0.006851 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.06 MB) transferred to GPU in 0.009794 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.06 MB) transferred to GPU in 0.007530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.06 MB) transferred to GPU in 0.006930 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.05 MB) transferred to GPU in 0.005346 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.06 MB) transferred to GPU in 0.006157 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.05 MB) transferred to GPU in 0.005865 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.06 MB) transferred to GPU in 0.006579 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.05 MB) transferred to GPU in 0.007018 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.06 MB) transferred to GPU in 0.007462 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.06 MB) transferred to GPU in 0.008337 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.06 MB) transferred to GPU in 0.006110 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9253800749288611, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9253800749288611\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16171104062763844, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16171104062763844\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2782415370668179, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2782415370668179\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8100261561989136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8100261561989136\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:17:47,473] Trial 70 finished with value: 0.11218485144487896 and parameters: {'lambda_l1': 0.16171104062763844, 'lambda_l2': 0.2782415370668179, 'num_leaves': 461, 'feature_fraction': 0.9253800749288611, 'bagging_fraction': 0.8100261561989136, 'bagging_freq': 9, 'min_child_samples': 9, 'depth': 10, 'learning_rate': 0.04572962284536935}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9307075305510442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9307075305510442\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1660508015967943, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1660508015967943\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24716277103875364, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24716277103875364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9307915584440744, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9307915584440744\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9307075305510442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9307075305510442\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1660508015967943, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1660508015967943\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24716277103875364, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24716277103875364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9307915584440744, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9307915584440744\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006362 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.007763 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.007184 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.008358 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.007360 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.007881 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.008005 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.009456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.008019 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.008466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.007656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.009312 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.008293 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.008662 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.006375 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.007564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.008105 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9307075305510442, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9307075305510442\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1660508015967943, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1660508015967943\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24716277103875364, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24716277103875364\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9307915584440744, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9307915584440744\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:18:04,969] Trial 71 finished with value: 0.11148889102294142 and parameters: {'lambda_l1': 0.1660508015967943, 'lambda_l2': 0.24716277103875364, 'num_leaves': 417, 'feature_fraction': 0.9307075305510442, 'bagging_fraction': 0.9307915584440744, 'bagging_freq': 6, 'min_child_samples': 22, 'depth': 10, 'learning_rate': 0.04816578769866273}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9573781087797235, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9573781087797235\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13322340082670497, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13322340082670497\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.320837911135776, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.320837911135776\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9249684585083794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9249684585083794\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9573781087797235, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9573781087797235\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13322340082670497, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13322340082670497\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.320837911135776, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.320837911135776\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9249684585083794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9249684585083794\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008944 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.009001 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.010677 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008374 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008697 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008186 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008203 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.006671 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007543 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.009156 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.006785 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008368 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.010539 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.006656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9573781087797235, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9573781087797235\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13322340082670497, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13322340082670497\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.320837911135776, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.320837911135776\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9249684585083794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9249684585083794\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:18:23,667] Trial 72 finished with value: 0.11111196060029045 and parameters: {'lambda_l1': 0.13322340082670497, 'lambda_l2': 0.320837911135776, 'num_leaves': 474, 'feature_fraction': 0.9573781087797235, 'bagging_fraction': 0.9249684585083794, 'bagging_freq': 7, 'min_child_samples': 15, 'depth': 10, 'learning_rate': 0.04687092729015791}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8314334881035227, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8314334881035227\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1481571936612346, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1481571936612346\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2653943812666829, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2653943812666829\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8960794826390975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8960794826390975\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8314334881035227, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8314334881035227\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1481571936612346, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1481571936612346\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2653943812666829, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2653943812666829\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8960794826390975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8960794826390975\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007732 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.006947 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.48 MB) transferred to GPU in 0.007713 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.009211 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008057 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008137 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008203 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008235 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007227 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.006574 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007101 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007462 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007726 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008092 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.006481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007785 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008258 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.48 MB) transferred to GPU in 0.006451 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007157 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.48 MB) transferred to GPU in 0.007588 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007882 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.009165 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.48 MB) transferred to GPU in 0.008090 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.006565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.006460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.009894 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.010102 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007960 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.006643 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007730 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8314334881035227, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8314334881035227\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1481571936612346, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1481571936612346\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2653943812666829, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2653943812666829\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8960794826390975, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8960794826390975\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:18:42,557] Trial 73 finished with value: 0.1098902698423549 and parameters: {'lambda_l1': 0.1481571936612346, 'lambda_l2': 0.2653943812666829, 'num_leaves': 495, 'feature_fraction': 0.8314334881035227, 'bagging_fraction': 0.8960794826390975, 'bagging_freq': 3, 'min_child_samples': 12, 'depth': 10, 'learning_rate': 0.04848610067334851}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8800077219595561, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8800077219595561\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14718283058180887, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14718283058180887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2751648107008722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2751648107008722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.895368302395692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.895368302395692\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8800077219595561, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8800077219595561\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14718283058180887, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14718283058180887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2751648107008722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2751648107008722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.895368302395692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.895368302395692\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006432 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8800077219595561, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8800077219595561\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14718283058180887, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14718283058180887\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2751648107008722, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2751648107008722\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.895368302395692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.895368302395692\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:19:03,967] Trial 74 finished with value: 0.11189725153257021 and parameters: {'lambda_l1': 0.14718283058180887, 'lambda_l2': 0.2751648107008722, 'num_leaves': 499, 'feature_fraction': 0.8800077219595561, 'bagging_fraction': 0.895368302395692, 'bagging_freq': 1, 'min_child_samples': 10, 'depth': 10, 'learning_rate': 0.04335068352038223}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8326067104283856, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8326067104283856\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11622193147248504, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11622193147248504\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29544046817275477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29544046817275477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8519712773233781, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8519712773233781\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8326067104283856, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8326067104283856\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11622193147248504, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11622193147248504\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29544046817275477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29544046817275477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8519712773233781, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8519712773233781\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007902 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006125 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.26 MB) transferred to GPU in 0.008830 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.005990 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.005677 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.26 MB) transferred to GPU in 0.007473 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006065 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.008878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007291 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006092 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006379 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006014 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.005028 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.005974 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007397 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007084 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007021 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007271 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006012 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.008758 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.008212 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.26 MB) transferred to GPU in 0.007959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.26 MB) transferred to GPU in 0.009117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.26 MB) transferred to GPU in 0.005973 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.004909 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006677 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007429 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007971 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.26 MB) transferred to GPU in 0.007792 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007658 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007277 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.006399 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8326067104283856, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8326067104283856\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11622193147248504, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11622193147248504\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29544046817275477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29544046817275477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8519712773233781, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8519712773233781\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:19:07,911] Trial 75 finished with value: 0.1432133076476192 and parameters: {'lambda_l1': 0.11622193147248504, 'lambda_l2': 0.29544046817275477, 'num_leaves': 497, 'feature_fraction': 0.8326067104283856, 'bagging_fraction': 0.8519712773233781, 'bagging_freq': 3, 'min_child_samples': 6, 'depth': 5, 'learning_rate': 0.04846272560804647}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8523790090507106, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8523790090507106\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13658671564991942, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13658671564991942\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34376878952531115, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.34376878952531115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9736989776692555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9736989776692555\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8523790090507106, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8523790090507106\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13658671564991942, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13658671564991942\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34376878952531115, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.34376878952531115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9736989776692555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9736989776692555\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007994 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.006815 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007580 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.006779 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008344 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008416 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007944 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007177 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008966 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009104 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.006954 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.011028 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007301 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007527 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008615 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008960 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009728 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007178 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009511 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009088 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007050 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008622 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007272 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.010166 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008982 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008997 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008993 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009516 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007045 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008750 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.005887 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008546 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.006581 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.87 MB) transferred to GPU in 0.008906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009283 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009250 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008211 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.008918 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.007213 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.87 MB) transferred to GPU in 0.007250 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8523790090507106, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8523790090507106\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13658671564991942, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13658671564991942\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34376878952531115, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.34376878952531115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9736989776692555, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9736989776692555\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:19:22,799] Trial 76 finished with value: 0.11386911931063406 and parameters: {'lambda_l1': 0.13658671564991942, 'lambda_l2': 0.34376878952531115, 'num_leaves': 481, 'feature_fraction': 0.8523790090507106, 'bagging_fraction': 0.9736989776692555, 'bagging_freq': 2, 'min_child_samples': 13, 'depth': 9, 'learning_rate': 0.046319763300600614}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9138180839759401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9138180839759401\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17049999125998352, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17049999125998352\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25531931396337787, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25531931396337787\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8725234647646841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8725234647646841\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9138180839759401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9138180839759401\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17049999125998352, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17049999125998352\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25531931396337787, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25531931396337787\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8725234647646841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8725234647646841\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006349 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006471 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007840 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.36 MB) transferred to GPU in 0.007926 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.008389 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.009928 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.008082 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.009056 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006513 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006594 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.008213 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007955 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006724 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007010 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007716 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007497 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006973 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007182 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007311 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.005344 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007518 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006953 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007362 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007352 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006463 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007905 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007045 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.008399 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007880 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.008345 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9138180839759401, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9138180839759401\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17049999125998352, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17049999125998352\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25531931396337787, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25531931396337787\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8725234647646841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8725234647646841\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:19:45,801] Trial 77 finished with value: 0.11293956141992033 and parameters: {'lambda_l1': 0.17049999125998352, 'lambda_l2': 0.25531931396337787, 'num_leaves': 462, 'feature_fraction': 0.9138180839759401, 'bagging_fraction': 0.8725234647646841, 'bagging_freq': 3, 'min_child_samples': 1, 'depth': 10, 'learning_rate': 0.04854066555519593}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9735109196712695, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9735109196712695\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15365150781239428, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15365150781239428\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3082302784506387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3082302784506387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9992992989289357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9992992989289357\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9735109196712695, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9735109196712695\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15365150781239428, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15365150781239428\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3082302784506387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3082302784506387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9992992989289357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9992992989289357\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010625 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007797 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009704 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007250 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007800 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008836 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008922 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007474 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9735109196712695, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9735109196712695\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15365150781239428, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15365150781239428\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3082302784506387, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3082302784506387\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9992992989289357, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9992992989289357\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:20:08,008] Trial 78 finished with value: 0.11117547254468048 and parameters: {'lambda_l1': 0.15365150781239428, 'lambda_l2': 0.3082302784506387, 'num_leaves': 497, 'feature_fraction': 0.9735109196712695, 'bagging_fraction': 0.9992992989289357, 'bagging_freq': 9, 'min_child_samples': 17, 'depth': 10, 'learning_rate': 0.04603533760895652}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7742341471018123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7742341471018123\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18488651239243473, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18488651239243473\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26751403994994255, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26751403994994255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9657060716494228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9657060716494228\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7742341471018123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7742341471018123\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18488651239243473, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18488651239243473\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26751403994994255, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26751403994994255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9657060716494228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9657060716494228\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006531 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006421 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.006723 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008436 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.006867 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007099 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007968 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.83 MB) transferred to GPU in 0.006744 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007747 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.010576 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007773 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7742341471018123, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7742341471018123\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18488651239243473, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18488651239243473\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26751403994994255, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26751403994994255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9657060716494228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9657060716494228\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:20:12,444] Trial 79 finished with value: 0.1580555371739363 and parameters: {'lambda_l1': 0.18488651239243473, 'lambda_l2': 0.26751403994994255, 'num_leaves': 41, 'feature_fraction': 0.7742341471018123, 'bagging_fraction': 0.9657060716494228, 'bagging_freq': 8, 'min_child_samples': 9, 'depth': 9, 'learning_rate': 0.04146447054017112}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8922974284630952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8922974284630952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11088356766422758, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11088356766422758\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2456659630537954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2456659630537954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.905842318285223, subsample=1.0 will be ignored. Current value: bagging_fraction=0.905842318285223\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8922974284630952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8922974284630952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11088356766422758, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11088356766422758\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2456659630537954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2456659630537954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.905842318285223, subsample=1.0 will be ignored. Current value: bagging_fraction=0.905842318285223\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006790 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8922974284630952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8922974284630952\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.11088356766422758, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.11088356766422758\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2456659630537954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2456659630537954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.905842318285223, subsample=1.0 will be ignored. Current value: bagging_fraction=0.905842318285223\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:20:29,689] Trial 80 finished with value: 0.11580090225398923 and parameters: {'lambda_l1': 0.11088356766422758, 'lambda_l2': 0.2456659630537954, 'num_leaves': 349, 'feature_fraction': 0.8922974284630952, 'bagging_fraction': 0.905842318285223, 'bagging_freq': 1, 'min_child_samples': 12, 'depth': 10, 'learning_rate': 0.04346012628361293}. Best is trial 33 with value: 0.10984358228392692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9368874604754511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9368874604754511\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18974952002541362, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18974952002541362\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23639363358602442, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23639363358602442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9320851863559099, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9320851863559099\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9368874604754511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9368874604754511\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18974952002541362, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18974952002541362\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23639363358602442, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23639363358602442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9320851863559099, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9320851863559099\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.007811 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.008563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.010472 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.009559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.008454 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.006808 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.006783 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.008121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.006992 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.008781 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.009171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.007615 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.006862 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9368874604754511, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9368874604754511\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18974952002541362, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18974952002541362\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23639363358602442, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23639363358602442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9320851863559099, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9320851863559099\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:20:50,233] Trial 81 finished with value: 0.1097630301462204 and parameters: {'lambda_l1': 0.18974952002541362, 'lambda_l2': 0.23639363358602442, 'num_leaves': 478, 'feature_fraction': 0.9368874604754511, 'bagging_fraction': 0.9320851863559099, 'bagging_freq': 8, 'min_child_samples': 19, 'depth': 10, 'learning_rate': 0.04983855621121318}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9404904008186035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9404904008186035\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1710358892119648, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1710358892119648\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2808503631146158, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2808503631146158\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9337890729069379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9337890729069379\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9404904008186035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9404904008186035\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1710358892119648, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1710358892119648\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2808503631146158, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2808503631146158\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9337890729069379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9337890729069379\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006690 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007428 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.008314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.009147 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007149 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007882 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.008713 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.009024 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.007021 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.008106 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006738 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9404904008186035, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9404904008186035\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1710358892119648, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1710358892119648\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2808503631146158, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2808503631146158\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9337890729069379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9337890729069379\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:21:09,409] Trial 82 finished with value: 0.11174284564955211 and parameters: {'lambda_l1': 0.1710358892119648, 'lambda_l2': 0.2808503631146158, 'num_leaves': 473, 'feature_fraction': 0.9404904008186035, 'bagging_fraction': 0.9337890729069379, 'bagging_freq': 8, 'min_child_samples': 4, 'depth': 10, 'learning_rate': 0.048729533250120645}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8670958983326871, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8670958983326871\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12470342172224946, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12470342172224946\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24189804837835321, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24189804837835321\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9680726867487535, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9680726867487535\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8670958983326871, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8670958983326871\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12470342172224946, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12470342172224946\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24189804837835321, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24189804837835321\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9680726867487535, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9680726867487535\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.007057 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.008710 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.008013 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.007609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.007403 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.007541 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.008051 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.008059 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.007999 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.008662 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.007389 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.85 MB) transferred to GPU in 0.008514 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8670958983326871, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8670958983326871\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12470342172224946, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12470342172224946\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24189804837835321, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24189804837835321\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9680726867487535, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9680726867487535\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:21:28,334] Trial 83 finished with value: 0.11072750806940615 and parameters: {'lambda_l1': 0.12470342172224946, 'lambda_l2': 0.24189804837835321, 'num_leaves': 442, 'feature_fraction': 0.8670958983326871, 'bagging_fraction': 0.9680726867487535, 'bagging_freq': 9, 'min_child_samples': 22, 'depth': 10, 'learning_rate': 0.04719619704485679}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9111347965967933, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9111347965967933\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14116976923773514, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14116976923773514\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3279194046204737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3279194046204737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8895219715150542, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8895219715150542\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9111347965967933, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9111347965967933\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14116976923773514, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14116976923773514\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3279194046204737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3279194046204737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8895219715150542, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8895219715150542\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008046 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.45 MB) transferred to GPU in 0.006005 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.45 MB) transferred to GPU in 0.007842 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.007914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.006836 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.45 MB) transferred to GPU in 0.007980 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.007176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.007228 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.45 MB) transferred to GPU in 0.005573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.45 MB) transferred to GPU in 0.007251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.45 MB) transferred to GPU in 0.007026 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.006707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.45 MB) transferred to GPU in 0.009329 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.46 MB) transferred to GPU in 0.006545 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9111347965967933, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9111347965967933\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14116976923773514, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14116976923773514\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3279194046204737, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3279194046204737\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8895219715150542, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8895219715150542\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:21:44,499] Trial 84 finished with value: 0.11229236902705578 and parameters: {'lambda_l1': 0.14116976923773514, 'lambda_l2': 0.3279194046204737, 'num_leaves': 500, 'feature_fraction': 0.9111347965967933, 'bagging_fraction': 0.8895219715150542, 'bagging_freq': 8, 'min_child_samples': 52, 'depth': 10, 'learning_rate': 0.04517312068814763}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8216173021015166, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8216173021015166\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15462209545932026, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15462209545932026\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2940964168835226, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2940964168835226\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9351533785634134, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9351533785634134\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8216173021015166, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8216173021015166\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15462209545932026, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15462209545932026\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2940964168835226, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2940964168835226\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9351533785634134, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9351533785634134\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010451 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.009480 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.010866 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006916 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.008766 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.009344 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007715 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007175 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.009477 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006796 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.69 MB) transferred to GPU in 0.008719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8216173021015166, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8216173021015166\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15462209545932026, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15462209545932026\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2940964168835226, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2940964168835226\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9351533785634134, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9351533785634134\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:22:05,095] Trial 85 finished with value: 0.11030283947942705 and parameters: {'lambda_l1': 0.15462209545932026, 'lambda_l2': 0.2940964168835226, 'num_leaves': 455, 'feature_fraction': 0.8216173021015166, 'bagging_fraction': 0.9351533785634134, 'bagging_freq': 9, 'min_child_samples': 18, 'depth': 10, 'learning_rate': 0.04878243802301463}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9708775046256086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9708775046256086\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18844831430201855, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18844831430201855\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2603936339130533, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2603936339130533\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9469649949822585, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9469649949822585\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9708775046256086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9708775046256086\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18844831430201855, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18844831430201855\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2603936339130533, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2603936339130533\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9469649949822585, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9469649949822585\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.007798 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.008857 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.007757 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.007121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.009089 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.008160 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.008287 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.008112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.008869 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.74 MB) transferred to GPU in 0.007889 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9708775046256086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9708775046256086\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18844831430201855, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18844831430201855\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2603936339130533, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2603936339130533\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9469649949822585, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9469649949822585\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:22:18,889] Trial 86 finished with value: 0.11508579146616742 and parameters: {'lambda_l1': 0.18844831430201855, 'lambda_l2': 0.2603936339130533, 'num_leaves': 458, 'feature_fraction': 0.9708775046256086, 'bagging_fraction': 0.9469649949822585, 'bagging_freq': 11, 'min_child_samples': 28, 'depth': 9, 'learning_rate': 0.049934163782642774}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.821418888235284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.821418888235284\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17499047958232233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17499047958232233\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2880035429066311, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2880035429066311\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9987755515222837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9987755515222837\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.821418888235284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.821418888235284\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17499047958232233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17499047958232233\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2880035429066311, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2880035429066311\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9987755515222837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9987755515222837\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006777 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010293 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007467 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007425 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007209 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010498 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009033 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007169 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008662 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008401 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.821418888235284, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.821418888235284\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17499047958232233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17499047958232233\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2880035429066311, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2880035429066311\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9987755515222837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9987755515222837\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:22:40,409] Trial 87 finished with value: 0.11159406129493854 and parameters: {'lambda_l1': 0.17499047958232233, 'lambda_l2': 0.2880035429066311, 'num_leaves': 427, 'feature_fraction': 0.821418888235284, 'bagging_fraction': 0.9987755515222837, 'bagging_freq': 10, 'min_child_samples': 7, 'depth': 10, 'learning_rate': 0.04876601527080394}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8449995406987999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8449995406987999\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13232789820359703, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13232789820359703\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22634484044579453, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22634484044579453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9236861911830409, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9236861911830409\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8449995406987999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8449995406987999\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13232789820359703, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13232789820359703\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22634484044579453, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22634484044579453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9236861911830409, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9236861911830409\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009943 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007454 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.006884 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007860 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008803 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008140 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007365 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.008447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.007869 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.006251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.008039 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.63 MB) transferred to GPU in 0.004951 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.62 MB) transferred to GPU in 0.006394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8449995406987999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8449995406987999\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13232789820359703, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13232789820359703\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22634484044579453, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22634484044579453\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9236861911830409, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9236861911830409\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:22:43,255] Trial 88 finished with value: 0.16098279232893556 and parameters: {'lambda_l1': 0.13232789820359703, 'lambda_l2': 0.22634484044579453, 'num_leaves': 481, 'feature_fraction': 0.8449995406987999, 'bagging_fraction': 0.9236861911830409, 'bagging_freq': 9, 'min_child_samples': 14, 'depth': 4, 'learning_rate': 0.04701709996602359}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8995944422836353, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8995944422836353\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1619661072749096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1619661072749096\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2052290929043714, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2052290929043714\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9783774531096785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9783774531096785\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8995944422836353, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8995944422836353\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1619661072749096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1619661072749096\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2052290929043714, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2052290929043714\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9783774531096785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9783774531096785\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008463 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008635 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007226 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.006826 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.010456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008966 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007042 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.011066 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8995944422836353, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8995944422836353\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1619661072749096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1619661072749096\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2052290929043714, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2052290929043714\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9783774531096785, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9783774531096785\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:22:55,872] Trial 89 finished with value: 0.11756223381836063 and parameters: {'lambda_l1': 0.1619661072749096, 'lambda_l2': 0.2052290929043714, 'num_leaves': 258, 'feature_fraction': 0.8995944422836353, 'bagging_fraction': 0.9783774531096785, 'bagging_freq': 10, 'min_child_samples': 33, 'depth': 9, 'learning_rate': 0.04398736253099808}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9256813835722636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9256813835722636\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14904989953879083, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14904989953879083\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2688361860712854, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2688361860712854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9421062322641204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9421062322641204\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9256813835722636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9256813835722636\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14904989953879083, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14904989953879083\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2688361860712854, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2688361860712854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9421062322641204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9421062322641204\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008877 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.011224 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.007480 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.007084 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.007794 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.009632 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008400 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.010230 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.010819 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008485 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008376 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008291 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.007136 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.007453 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9256813835722636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9256813835722636\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14904989953879083, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14904989953879083\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2688361860712854, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2688361860712854\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9421062322641204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9421062322641204\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:23:14,337] Trial 90 finished with value: 0.11082262469466064 and parameters: {'lambda_l1': 0.14904989953879083, 'lambda_l2': 0.2688361860712854, 'num_leaves': 454, 'feature_fraction': 0.9256813835722636, 'bagging_fraction': 0.9421062322641204, 'bagging_freq': 7, 'min_child_samples': 18, 'depth': 10, 'learning_rate': 0.04757156990560794}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8063800215020732, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8063800215020732\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15619388329415662, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15619388329415662\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34277646164146514, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.34277646164146514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9061308776397715, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9061308776397715\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8063800215020732, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8063800215020732\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15619388329415662, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15619388329415662\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34277646164146514, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.34277646164146514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9061308776397715, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9061308776397715\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008965 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.009986 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.008344 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.008225 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.009083 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007115 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.008753 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.008035 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.006476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.006742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.006821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.010235 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.007850 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8063800215020732, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8063800215020732\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15619388329415662, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15619388329415662\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.34277646164146514, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.34277646164146514\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9061308776397715, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9061308776397715\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:23:33,988] Trial 91 finished with value: 0.11028863974449547 and parameters: {'lambda_l1': 0.15619388329415662, 'lambda_l2': 0.34277646164146514, 'num_leaves': 487, 'feature_fraction': 0.8063800215020732, 'bagging_fraction': 0.9061308776397715, 'bagging_freq': 8, 'min_child_samples': 15, 'depth': 10, 'learning_rate': 0.04619978666407184}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8145080571533114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8145080571533114\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17535794993202308, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17535794993202308\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38779115664014846, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38779115664014846\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9612670565700245, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9612670565700245\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8145080571533114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8145080571533114\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17535794993202308, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17535794993202308\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38779115664014846, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38779115664014846\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9612670565700245, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9612670565700245\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.005417 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.008496 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.007955 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.009172 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008549 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.008547 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009653 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.007921 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.008296 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010934 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.009364 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8145080571533114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8145080571533114\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17535794993202308, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17535794993202308\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38779115664014846, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38779115664014846\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9612670565700245, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9612670565700245\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:23:56,045] Trial 92 finished with value: 0.11038909537150575 and parameters: {'lambda_l1': 0.17535794993202308, 'lambda_l2': 0.38779115664014846, 'num_leaves': 483, 'feature_fraction': 0.8145080571533114, 'bagging_fraction': 0.9612670565700245, 'bagging_freq': 9, 'min_child_samples': 11, 'depth': 10, 'learning_rate': 0.04864873780624509}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.810146164978272, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.810146164978272\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1802700545739605, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1802700545739605\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38213803855064343, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38213803855064343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9609968698604372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9609968698604372\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.810146164978272, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.810146164978272\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1802700545739605, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1802700545739605\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38213803855064343, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38213803855064343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9609968698604372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9609968698604372\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008532 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.008247 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.010616 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.006901 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.007703 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.007177 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.007559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.009320 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.810146164978272, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.810146164978272\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1802700545739605, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1802700545739605\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38213803855064343, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38213803855064343\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9609968698604372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9609968698604372\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:24:07,816] Trial 93 finished with value: 0.12056884633534519 and parameters: {'lambda_l1': 0.1802700545739605, 'lambda_l2': 0.38213803855064343, 'num_leaves': 192, 'feature_fraction': 0.810146164978272, 'bagging_fraction': 0.9609968698604372, 'bagging_freq': 15, 'min_child_samples': 24, 'depth': 10, 'learning_rate': 0.04879851813347937}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7887574668124826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7887574668124826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16684099004714692, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16684099004714692\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3360069362881992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3360069362881992\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8723475540082748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8723475540082748\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7887574668124826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7887574668124826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16684099004714692, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16684099004714692\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3360069362881992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3360069362881992\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8723475540082748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8723475540082748\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006459 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006282 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007957 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006967 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007592 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.36 MB) transferred to GPU in 0.007613 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006197 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007999 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007291 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006696 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.010138 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.009587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.011260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7887574668124826, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7887574668124826\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16684099004714692, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16684099004714692\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3360069362881992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3360069362881992\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8723475540082748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8723475540082748\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:24:13,392] Trial 94 finished with value: 0.1328308673185857 and parameters: {'lambda_l1': 0.16684099004714692, 'lambda_l2': 0.3360069362881992, 'num_leaves': 484, 'feature_fraction': 0.7887574668124826, 'bagging_fraction': 0.8723475540082748, 'bagging_freq': 9, 'min_child_samples': 4, 'depth': 6, 'learning_rate': 0.0499707633628913}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7514813935611707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7514813935611707\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21083054946911703, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21083054946911703\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2526019113720477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2526019113720477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9522318041123098, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9522318041123098\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7514813935611707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7514813935611707\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21083054946911703, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21083054946911703\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2526019113720477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2526019113720477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9522318041123098, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9522318041123098\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010814 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.011682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.010870 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.013794 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.009076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.008254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.007818 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.009392 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.007801 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.007254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.77 MB) transferred to GPU in 0.007095 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7514813935611707, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7514813935611707\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21083054946911703, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21083054946911703\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2526019113720477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2526019113720477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9522318041123098, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9522318041123098\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:24:37,280] Trial 95 finished with value: 0.11042273994987475 and parameters: {'lambda_l1': 0.21083054946911703, 'lambda_l2': 0.2526019113720477, 'num_leaves': 501, 'feature_fraction': 0.7514813935611707, 'bagging_fraction': 0.9522318041123098, 'bagging_freq': 10, 'min_child_samples': 20, 'depth': 10, 'learning_rate': 0.046793340363514825}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.846118382618687, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.846118382618687\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1784436096669892, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1784436096669892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29413128271996053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29413128271996053\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.910151499418421, subsample=1.0 will be ignored. Current value: bagging_fraction=0.910151499418421\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.846118382618687, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.846118382618687\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1784436096669892, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1784436096669892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29413128271996053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29413128271996053\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.910151499418421, subsample=1.0 will be ignored. Current value: bagging_fraction=0.910151499418421\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006889 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007271 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007118 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.006589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.006954 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.010086 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007929 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.006923 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.006749 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.006522 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.56 MB) transferred to GPU in 0.007848 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.846118382618687, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.846118382618687\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1784436096669892, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1784436096669892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.29413128271996053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.29413128271996053\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.910151499418421, subsample=1.0 will be ignored. Current value: bagging_fraction=0.910151499418421\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:24:59,784] Trial 96 finished with value: 0.11182140316969096 and parameters: {'lambda_l1': 0.1784436096669892, 'lambda_l2': 0.29413128271996053, 'num_leaves': 476, 'feature_fraction': 0.846118382618687, 'bagging_fraction': 0.910151499418421, 'bagging_freq': 9, 'min_child_samples': 10, 'depth': 10, 'learning_rate': 0.04464848727302631}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8188449087036906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8188449087036906\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19164318951381137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19164318951381137\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22558471192905336, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22558471192905336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9394066163106896, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9394066163106896\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8188449087036906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8188449087036906\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19164318951381137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19164318951381137\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22558471192905336, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22558471192905336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9394066163106896, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9394066163106896\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008108 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.006291 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.008535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.71 MB) transferred to GPU in 0.007072 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.008718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.008273 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.71 MB) transferred to GPU in 0.009667 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.71 MB) transferred to GPU in 0.010758 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.71 MB) transferred to GPU in 0.012234 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.011665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.007653 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.71 MB) transferred to GPU in 0.009062 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.008809 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.71 MB) transferred to GPU in 0.007064 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8188449087036906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8188449087036906\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19164318951381137, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19164318951381137\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22558471192905336, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22558471192905336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9394066163106896, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9394066163106896\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:25:14,466] Trial 97 finished with value: 0.1135945650349565 and parameters: {'lambda_l1': 0.19164318951381137, 'lambda_l2': 0.22558471192905336, 'num_leaves': 444, 'feature_fraction': 0.8188449087036906, 'bagging_fraction': 0.9394066163106896, 'bagging_freq': 8, 'min_child_samples': 14, 'depth': 9, 'learning_rate': 0.04895603699579922}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8653732838593757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8653732838593757\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14151138670200247, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14151138670200247\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23863238435941939, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23863238435941939\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9807249575842332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9807249575842332\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8653732838593757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8653732838593757\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14151138670200247, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14151138670200247\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23863238435941939, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23863238435941939\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9807249575842332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9807249575842332\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006893 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.008686 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.008902 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.007755 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.008470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.010678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.009004 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.011393 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.007192 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8653732838593757, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8653732838593757\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14151138670200247, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14151138670200247\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23863238435941939, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23863238435941939\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9807249575842332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9807249575842332\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:25:35,057] Trial 98 finished with value: 0.11047256531292612 and parameters: {'lambda_l1': 0.14151138670200247, 'lambda_l2': 0.23863238435941939, 'num_leaves': 512, 'feature_fraction': 0.8653732838593757, 'bagging_fraction': 0.9807249575842332, 'bagging_freq': 13, 'min_child_samples': 7, 'depth': 10, 'learning_rate': 0.0463531317213469}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.808578165182756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.808578165182756\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.157650002208628, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.157650002208628\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26194056646469427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26194056646469427\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994147045360647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994147045360647\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.808578165182756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.808578165182756\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.157650002208628, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.157650002208628\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26194056646469427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26194056646469427\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994147045360647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994147045360647\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009156 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009772 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010843 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008739 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008743 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009927 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009348 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.808578165182756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.808578165182756\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.157650002208628, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.157650002208628\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26194056646469427, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26194056646469427\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994147045360647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994147045360647\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:25:49,315] Trial 99 finished with value: 0.1140397796315471 and parameters: {'lambda_l1': 0.157650002208628, 'lambda_l2': 0.26194056646469427, 'num_leaves': 487, 'feature_fraction': 0.808578165182756, 'bagging_fraction': 0.9994147045360647, 'bagging_freq': 9, 'min_child_samples': 18, 'depth': 9, 'learning_rate': 0.04754820915846848}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8912093440367348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8912093440367348\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2003109037025495, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2003109037025495\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38901608010726985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38901608010726985\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8404073895905757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8404073895905757\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8912093440367348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8912093440367348\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2003109037025495, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2003109037025495\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38901608010726985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38901608010726985\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8404073895905757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8404073895905757\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008704 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.006112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.007975 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.006495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.007672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.006510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.006032 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.006215 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.006515 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.008369 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.006609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.007087 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.007887 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.007895 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.007496 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.21 MB) transferred to GPU in 0.007406 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8912093440367348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8912093440367348\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2003109037025495, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2003109037025495\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.38901608010726985, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.38901608010726985\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8404073895905757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8404073895905757\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:26:09,588] Trial 100 finished with value: 0.11328291728368912 and parameters: {'lambda_l1': 0.2003109037025495, 'lambda_l2': 0.38901608010726985, 'num_leaves': 502, 'feature_fraction': 0.8912093440367348, 'bagging_fraction': 0.8404073895905757, 'bagging_freq': 7, 'min_child_samples': 3, 'depth': 10, 'learning_rate': 0.044612746054830975}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7511855700278095, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7511855700278095\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1647426075720851, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1647426075720851\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24722915086205274, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24722915086205274\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9608837226808845, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9608837226808845\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7511855700278095, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7511855700278095\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1647426075720851, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1647426075720851\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24722915086205274, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24722915086205274\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9608837226808845, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9608837226808845\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.007195 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.008314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.010672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.010516 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.008877 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.011117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.011100 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.008040 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.007890 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.81 MB) transferred to GPU in 0.011085 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7511855700278095, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7511855700278095\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1647426075720851, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1647426075720851\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24722915086205274, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24722915086205274\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9608837226808845, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9608837226808845\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:26:28,854] Trial 101 finished with value: 0.11083401418836095 and parameters: {'lambda_l1': 0.1647426075720851, 'lambda_l2': 0.24722915086205274, 'num_leaves': 499, 'feature_fraction': 0.7511855700278095, 'bagging_fraction': 0.9608837226808845, 'bagging_freq': 11, 'min_child_samples': 21, 'depth': 10, 'learning_rate': 0.04684918190715699}. Best is trial 81 with value: 0.1097630301462204.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7743017161323531, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7743017161323531\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18750138036088035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18750138036088035\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2771748292858018, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2771748292858018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.948940356092234, subsample=1.0 will be ignored. Current value: bagging_fraction=0.948940356092234\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7743017161323531, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7743017161323531\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18750138036088035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18750138036088035\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2771748292858018, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2771748292858018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.948940356092234, subsample=1.0 will be ignored. Current value: bagging_fraction=0.948940356092234\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.013387 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.015572 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.016942 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.024137 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.009188 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.009199 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.009130 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.008060 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007335 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007141 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7743017161323531, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7743017161323531\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18750138036088035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18750138036088035\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2771748292858018, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2771748292858018\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.948940356092234, subsample=1.0 will be ignored. Current value: bagging_fraction=0.948940356092234\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:26:55,018] Trial 102 finished with value: 0.10959249481298065 and parameters: {'lambda_l1': 0.18750138036088035, 'lambda_l2': 0.2771748292858018, 'num_leaves': 491, 'feature_fraction': 0.7743017161323531, 'bagging_fraction': 0.948940356092234, 'bagging_freq': 10, 'min_child_samples': 20, 'depth': 10, 'learning_rate': 0.04922362502420004}. Best is trial 102 with value: 0.10959249481298065.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.775150906035067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775150906035067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1873614189651116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1873614189651116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30002810690969617, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30002810690969617\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9126199831365078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9126199831365078\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.775150906035067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775150906035067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1873614189651116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1873614189651116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30002810690969617, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30002810690969617\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9126199831365078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9126199831365078\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006416 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.007157 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.007759 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.006563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.007093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.006769 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.007810 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.008034 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.008691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.006616 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.006586 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.007758 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.010611 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.010493 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.775150906035067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775150906035067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1873614189651116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1873614189651116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30002810690969617, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30002810690969617\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9126199831365078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9126199831365078\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:27:12,917] Trial 103 finished with value: 0.10955033538215246 and parameters: {'lambda_l1': 0.1873614189651116, 'lambda_l2': 0.30002810690969617, 'num_leaves': 462, 'feature_fraction': 0.775150906035067, 'bagging_fraction': 0.9126199831365078, 'bagging_freq': 8, 'min_child_samples': 15, 'depth': 10, 'learning_rate': 0.04885918962472099}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.72493981962925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72493981962925\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19098558118615014, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19098558118615014\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3306052765440424, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3306052765440424\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8839063804028735, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8839063804028735\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.72493981962925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72493981962925\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19098558118615014, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19098558118615014\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3306052765440424, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3306052765440424\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8839063804028735, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8839063804028735\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008753 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.007287 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.006980 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.008248 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.007512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.007347 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.006282 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.006431 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.008414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.006634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.007612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.43 MB) transferred to GPU in 0.007690 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.42 MB) transferred to GPU in 0.008422 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.72493981962925, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72493981962925\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19098558118615014, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19098558118615014\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3306052765440424, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3306052765440424\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8839063804028735, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8839063804028735\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:27:29,838] Trial 104 finished with value: 0.11096701627663418 and parameters: {'lambda_l1': 0.19098558118615014, 'lambda_l2': 0.3306052765440424, 'num_leaves': 459, 'feature_fraction': 0.72493981962925, 'bagging_fraction': 0.8839063804028735, 'bagging_freq': 9, 'min_child_samples': 24, 'depth': 10, 'learning_rate': 0.0490997042434749}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8294544391313368, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8294544391313368\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1813015343812331, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1813015343812331\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3054435137548704, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3054435137548704\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9173698799740205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9173698799740205\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8294544391313368, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8294544391313368\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1813015343812331, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1813015343812331\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3054435137548704, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3054435137548704\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9173698799740205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9173698799740205\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010869 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.008031 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.006535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.60 MB) transferred to GPU in 0.007721 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.60 MB) transferred to GPU in 0.008267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.006377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.60 MB) transferred to GPU in 0.006477 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.008095 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.009972 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.008264 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.008488 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:27:31,980] Trial 105 finished with value: 0.1823413104715845 and parameters: {'lambda_l1': 0.1813015343812331, 'lambda_l2': 0.3054435137548704, 'num_leaves': 477, 'feature_fraction': 0.8294544391313368, 'bagging_fraction': 0.9173698799740205, 'bagging_freq': 10, 'min_child_samples': 15, 'depth': 3, 'learning_rate': 0.04796152950960564}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8294544391313368, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8294544391313368\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1813015343812331, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1813015343812331\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3054435137548704, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3054435137548704\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9173698799740205, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9173698799740205\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818067847003046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818067847003046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17319114800452431, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17319114800452431\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2919799402705568, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2919799402705568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8964734124927766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8964734124927766\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818067847003046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818067847003046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17319114800452431, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17319114800452431\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2919799402705568, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2919799402705568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8964734124927766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8964734124927766\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007017 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008735 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008310 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.006888 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.008053 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.006548 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.010317 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007816 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007004 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007496 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.49 MB) transferred to GPU in 0.007846 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818067847003046, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818067847003046\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17319114800452431, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17319114800452431\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2919799402705568, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2919799402705568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8964734124927766, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8964734124927766\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:27:49,711] Trial 106 finished with value: 0.11109710343577511 and parameters: {'lambda_l1': 0.17319114800452431, 'lambda_l2': 0.2919799402705568, 'num_leaves': 440, 'feature_fraction': 0.7818067847003046, 'bagging_fraction': 0.8964734124927766, 'bagging_freq': 9, 'min_child_samples': 8, 'depth': 10, 'learning_rate': 0.049947754060051246}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7705954070907984, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7705954070907984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21407311473313814, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21407311473313814\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27315452293827036, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.27315452293827036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9814545823154394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9814545823154394\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7705954070907984, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7705954070907984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21407311473313814, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21407311473313814\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27315452293827036, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.27315452293827036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9814545823154394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9814545823154394\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008315 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.008025 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.008305 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.008091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.008770 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.91 MB) transferred to GPU in 0.009186 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.008379 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.008310 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.007238 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.007060 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.007194 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7705954070907984, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7705954070907984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21407311473313814, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21407311473313814\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27315452293827036, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.27315452293827036\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9814545823154394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9814545823154394\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:28:06,553] Trial 107 finished with value: 0.11087664586014476 and parameters: {'lambda_l1': 0.21407311473313814, 'lambda_l2': 0.27315452293827036, 'num_leaves': 452, 'feature_fraction': 0.7705954070907984, 'bagging_fraction': 0.9814545823154394, 'bagging_freq': 10, 'min_child_samples': 18, 'depth': 10, 'learning_rate': 0.04895368224112243}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7959392424878117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7959392424878117\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2033676940191453, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2033676940191453\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2806107130526709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2806107130526709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8623416272572856, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8623416272572856\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7959392424878117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7959392424878117\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2033676940191453, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2033676940191453\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2806107130526709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2806107130526709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8623416272572856, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8623416272572856\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006639 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.005718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.007505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.006202 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.007388 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.31 MB) transferred to GPU in 0.007519 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.005870 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.006144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.007226 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.006372 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.006211 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.006246 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.006790 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.32 MB) transferred to GPU in 0.006587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7959392424878117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7959392424878117\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2033676940191453, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2033676940191453\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2806107130526709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2806107130526709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8623416272572856, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8623416272572856\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:28:23,162] Trial 108 finished with value: 0.11131063786725923 and parameters: {'lambda_l1': 0.2033676940191453, 'lambda_l2': 0.2806107130526709, 'num_leaves': 468, 'feature_fraction': 0.7959392424878117, 'bagging_fraction': 0.8623416272572856, 'bagging_freq': 8, 'min_child_samples': 30, 'depth': 10, 'learning_rate': 0.0456618934083483}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8542861137539092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8542861137539092\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19459627311499733, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19459627311499733\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3131853624063885, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3131853624063885\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9423512073100987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423512073100987\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8542861137539092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8542861137539092\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19459627311499733, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19459627311499733\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3131853624063885, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3131853624063885\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9423512073100987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423512073100987\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.006090 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.007324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.006346 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008876 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008335 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.009465 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.007420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008210 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008226 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.007226 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.007735 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.008155 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.72 MB) transferred to GPU in 0.006968 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8542861137539092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8542861137539092\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19459627311499733, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19459627311499733\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3131853624063885, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3131853624063885\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9423512073100987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423512073100987\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:28:35,301] Trial 109 finished with value: 0.11679891971511686 and parameters: {'lambda_l1': 0.19459627311499733, 'lambda_l2': 0.3131853624063885, 'num_leaves': 486, 'feature_fraction': 0.8542861137539092, 'bagging_fraction': 0.9423512073100987, 'bagging_freq': 8, 'min_child_samples': 65, 'depth': 9, 'learning_rate': 0.04749154674319378}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6875931520441239, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6875931520441239\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18451581985130558, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18451581985130558\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3509604360790602, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3509604360790602\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9168879619974095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9168879619974095\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6875931520441239, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6875931520441239\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18451581985130558, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18451581985130558\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3509604360790602, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3509604360790602\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9168879619974095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9168879619974095\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.007122 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.009594 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.007910 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.008579 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.010449 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.008422 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.006906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.005607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.009912 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.59 MB) transferred to GPU in 0.008009 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6875931520441239, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6875931520441239\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18451581985130558, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18451581985130558\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.3509604360790602, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3509604360790602\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9168879619974095, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9168879619974095\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:28:49,350] Trial 110 finished with value: 0.11508236901013719 and parameters: {'lambda_l1': 0.18451581985130558, 'lambda_l2': 0.3509604360790602, 'num_leaves': 420, 'feature_fraction': 0.6875931520441239, 'bagging_fraction': 0.9168879619974095, 'bagging_freq': 11, 'min_child_samples': 27, 'depth': 9, 'learning_rate': 0.049059324666076515}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9105347314478636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9105347314478636\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15084208112073624, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15084208112073624\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22636098173396393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22636098173396393\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9550036950135392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9550036950135392\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9105347314478636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9105347314478636\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15084208112073624, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15084208112073624\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22636098173396393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22636098173396393\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9550036950135392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9550036950135392\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008918 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.007566 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.009535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.010962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.009613 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.009102 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.009460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.009513 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.008505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.007343 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.010574 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.008828 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.006615 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.007021 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9105347314478636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9105347314478636\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15084208112073624, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15084208112073624\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22636098173396393, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22636098173396393\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9550036950135392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9550036950135392\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:29:12,781] Trial 111 finished with value: 0.11035272152227793 and parameters: {'lambda_l1': 0.15084208112073624, 'lambda_l2': 0.22636098173396393, 'num_leaves': 488, 'feature_fraction': 0.9105347314478636, 'bagging_fraction': 0.9550036950135392, 'bagging_freq': 8, 'min_child_samples': 13, 'depth': 10, 'learning_rate': 0.04625075219112061}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7400149472673297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7400149472673297\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15870414479642284, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15870414479642284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20892332673242262, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20892332673242262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9344456239596565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9344456239596565\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7400149472673297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7400149472673297\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15870414479642284, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15870414479642284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20892332673242262, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20892332673242262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9344456239596565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9344456239596565\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008824 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006027 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.009107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007490 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007841 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006843 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007735 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.008511 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.009066 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.008708 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007729 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.008528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.008409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.009455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.009603 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006896 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7400149472673297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7400149472673297\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15870414479642284, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15870414479642284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20892332673242262, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20892332673242262\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9344456239596565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9344456239596565\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:29:35,748] Trial 112 finished with value: 0.10993689152267659 and parameters: {'lambda_l1': 0.15870414479642284, 'lambda_l2': 0.20892332673242262, 'num_leaves': 508, 'feature_fraction': 0.7400149472673297, 'bagging_fraction': 0.9344456239596565, 'bagging_freq': 7, 'min_child_samples': 13, 'depth': 10, 'learning_rate': 0.047842049494505476}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9528173211858508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9528173211858508\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14572232319168132, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14572232319168132\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20087007736558254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20087007736558254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345885676704885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9345885676704885\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9528173211858508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9528173211858508\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14572232319168132, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14572232319168132\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20087007736558254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20087007736558254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345885676704885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9345885676704885\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007013 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007876 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006965 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.007259 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.009922 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.006938 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.023450 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.011146 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.013720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.012415 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.011782 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.011967 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.012113 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.68 MB) transferred to GPU in 0.013103 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9528173211858508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9528173211858508\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14572232319168132, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14572232319168132\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20087007736558254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20087007736558254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9345885676704885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9345885676704885\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:29:59,095] Trial 113 finished with value: 0.11109342413570947 and parameters: {'lambda_l1': 0.14572232319168132, 'lambda_l2': 0.20087007736558254, 'num_leaves': 512, 'feature_fraction': 0.9528173211858508, 'bagging_fraction': 0.9345885676704885, 'bagging_freq': 7, 'min_child_samples': 20, 'depth': 10, 'learning_rate': 0.0454704923408829}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7365892331524929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7365892331524929\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15820439367293218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15820439367293218\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22853500034460655, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22853500034460655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994764340359533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994764340359533\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7365892331524929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7365892331524929\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15820439367293218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15820439367293218\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22853500034460655, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22853500034460655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994764340359533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994764340359533\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011118 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.51 MB) transferred to GPU in 0.009975 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.011691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.51 MB) transferred to GPU in 0.012122 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.51 MB) transferred to GPU in 0.009870 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.007734 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.51 MB) transferred to GPU in 0.006281 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.51 MB) transferred to GPU in 0.008410 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.007811 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.007861 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.009001 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.51 MB) transferred to GPU in 0.007752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.50 MB) transferred to GPU in 0.010011 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.51 MB) transferred to GPU in 0.007679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.51 MB) transferred to GPU in 0.008997 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.51 MB) transferred to GPU in 0.008226 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7365892331524929, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7365892331524929\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15820439367293218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15820439367293218\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22853500034460655, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22853500034460655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8994764340359533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8994764340359533\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:30:23,214] Trial 114 finished with value: 0.11052003055584973 and parameters: {'lambda_l1': 0.15820439367293218, 'lambda_l2': 0.22853500034460655, 'num_leaves': 503, 'feature_fraction': 0.7365892331524929, 'bagging_fraction': 0.8994764340359533, 'bagging_freq': 7, 'min_child_samples': 14, 'depth': 10, 'learning_rate': 0.04786182060900689}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9866755813546315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9866755813546315\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13811243319503108, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13811243319503108\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23755678005329567, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23755678005329567\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9824573579485526, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9824573579485526\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9866755813546315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9866755813546315\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13811243319503108, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13811243319503108\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23755678005329567, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23755678005329567\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9824573579485526, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9824573579485526\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006913 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.006827 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.023995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.011027 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.010844 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.011041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.008210 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.007040 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.022078 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.011559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.009273 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.007771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.010179 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.92 MB) transferred to GPU in 0.010357 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9866755813546315, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9866755813546315\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13811243319503108, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13811243319503108\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23755678005329567, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23755678005329567\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9824573579485526, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9824573579485526\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:30:49,104] Trial 115 finished with value: 0.11141088468864352 and parameters: {'lambda_l1': 0.13811243319503108, 'lambda_l2': 0.23755678005329567, 'num_leaves': 492, 'feature_fraction': 0.9866755813546315, 'bagging_fraction': 0.9824573579485526, 'bagging_freq': 8, 'min_child_samples': 16, 'depth': 10, 'learning_rate': 0.04431151645667479}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9156463294944973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9156463294944973\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15307898442797596, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15307898442797596\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2120266805113468, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2120266805113468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8739349090101524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8739349090101524\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9156463294944973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9156463294944973\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15307898442797596, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15307898442797596\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2120266805113468, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2120266805113468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8739349090101524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8739349090101524\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007034 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.005840 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.006257 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006969 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.010197 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.37 MB) transferred to GPU in 0.007545 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.013252 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.007567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006216 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006683 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006389 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006422 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.006983 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.38 MB) transferred to GPU in 0.009553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9156463294944973, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9156463294944973\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15307898442797596, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15307898442797596\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2120266805113468, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2120266805113468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8739349090101524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8739349090101524\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:31:08,356] Trial 116 finished with value: 0.11267781582011345 and parameters: {'lambda_l1': 0.15307898442797596, 'lambda_l2': 0.2120266805113468, 'num_leaves': 464, 'feature_fraction': 0.9156463294944973, 'bagging_fraction': 0.8739349090101524, 'bagging_freq': 8, 'min_child_samples': 22, 'depth': 10, 'learning_rate': 0.04269316470623851}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8347816122365692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8347816122365692\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1666691622564275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1666691622564275\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21458624923574046, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21458624923574046\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9390380773901286, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9390380773901286\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8347816122365692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8347816122365692\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1666691622564275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1666691622564275\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21458624923574046, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21458624923574046\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9390380773901286, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9390380773901286\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.008001 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.007794 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.010154 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.006764 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.007596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.009093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.007925 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.007953 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.008142 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.006711 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.71 MB) transferred to GPU in 0.006608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.008464 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.71 MB) transferred to GPU in 0.008219 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.007706 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.70 MB) transferred to GPU in 0.007502 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8347816122365692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8347816122365692\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1666691622564275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1666691622564275\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21458624923574046, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21458624923574046\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9390380773901286, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9390380773901286\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:31:14,610] Trial 117 finished with value: 0.12730202470322052 and parameters: {'lambda_l1': 0.1666691622564275, 'lambda_l2': 0.21458624923574046, 'num_leaves': 475, 'feature_fraction': 0.8347816122365692, 'bagging_fraction': 0.9390380773901286, 'bagging_freq': 7, 'min_child_samples': 98, 'depth': 7, 'learning_rate': 0.0499497968416789}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7576083325089366, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7576083325089366\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1482320584535211, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1482320584535211\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1995450417547119, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1995450417547119\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9134218111611629, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9134218111611629\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7576083325089366, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7576083325089366\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1482320584535211, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1482320584535211\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1995450417547119, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1995450417547119\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9134218111611629, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9134218111611629\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.58 MB) transferred to GPU in 0.007151 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.007985 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.58 MB) transferred to GPU in 0.007958 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.58 MB) transferred to GPU in 0.007688 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.008049 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.58 MB) transferred to GPU in 0.009184 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.58 MB) transferred to GPU in 0.010027 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.013772 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.021419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.024177 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.58 MB) transferred to GPU in 0.012216 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.57 MB) transferred to GPU in 0.013519 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.58 MB) transferred to GPU in 0.014470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.58 MB) transferred to GPU in 0.016150 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.58 MB) transferred to GPU in 0.028189 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7576083325089366, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7576083325089366\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1482320584535211, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1482320584535211\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1995450417547119, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1995450417547119\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9134218111611629, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9134218111611629\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:31:47,187] Trial 118 finished with value: 0.11099415632123362 and parameters: {'lambda_l1': 0.1482320584535211, 'lambda_l2': 0.1995450417547119, 'num_leaves': 491, 'feature_fraction': 0.7576083325089366, 'bagging_fraction': 0.9134218111611629, 'bagging_freq': 7, 'min_child_samples': 10, 'depth': 10, 'learning_rate': 0.04647793952170331}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7843535391733699, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843535391733699\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.159158569291867, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.159158569291867\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18697374074359788, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18697374074359788\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8388899166038011, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8388899166038011\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843535391733699, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843535391733699\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.159158569291867, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.159158569291867\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18697374074359788, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18697374074359788\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8388899166038011, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8388899166038011\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.012195 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.010962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.012196 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.014143 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.012400 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.19 MB) transferred to GPU in 0.011738 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.009802 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.013839 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.014324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.012933 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.009371 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.007838 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.008001 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.20 MB) transferred to GPU in 0.007498 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7843535391733699, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7843535391733699\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.159158569291867, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.159158569291867\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18697374074359788, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18697374074359788\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8388899166038011, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8388899166038011\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:32:14,679] Trial 119 finished with value: 0.1144526852838348 and parameters: {'lambda_l1': 0.159158569291867, 'lambda_l2': 0.18697374074359788, 'num_leaves': 310, 'feature_fraction': 0.7843535391733699, 'bagging_fraction': 0.8388899166038011, 'bagging_freq': 8, 'min_child_samples': 40, 'depth': 10, 'learning_rate': 0.04769232185625559}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8634140872080417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8634140872080417\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22840382037815982, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22840382037815982\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22573590187200462, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22573590187200462\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8865941374995446, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8865941374995446\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8634140872080417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8634140872080417\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22840382037815982, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22840382037815982\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22573590187200462, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22573590187200462\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8865941374995446, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8865941374995446\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.007166 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.008144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.007385 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.007035 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.007263 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.007448 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.007785 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.007373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.007844 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.008401 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.006561 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.44 MB) transferred to GPU in 0.008633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8634140872080417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8634140872080417\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22840382037815982, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22840382037815982\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.22573590187200462, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.22573590187200462\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8865941374995446, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8865941374995446\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:32:34,880] Trial 120 finished with value: 0.11093894137466384 and parameters: {'lambda_l1': 0.22840382037815982, 'lambda_l2': 0.22573590187200462, 'num_leaves': 507, 'feature_fraction': 0.8634140872080417, 'bagging_fraction': 0.8865941374995446, 'bagging_freq': 9, 'min_child_samples': 13, 'depth': 10, 'learning_rate': 0.045590288291410166}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8156838373753761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8156838373753761\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17356903378771718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17356903378771718\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21113296644961096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21113296644961096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9557732179280831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9557732179280831\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8156838373753761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8156838373753761\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17356903378771718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17356903378771718\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21113296644961096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21113296644961096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9557732179280831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9557732179280831\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011954 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.019878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.021487 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.015034 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.017010 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.018878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.019560 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.030196 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.017761 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.029892 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.78 MB) transferred to GPU in 0.024524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.016760 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.017003 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8156838373753761, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8156838373753761\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17356903378771718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17356903378771718\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21113296644961096, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21113296644961096\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9557732179280831, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9557732179280831\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:33:20,611] Trial 121 finished with value: 0.11014012831171725 and parameters: {'lambda_l1': 0.17356903378771718, 'lambda_l2': 0.21113296644961096, 'num_leaves': 480, 'feature_fraction': 0.8156838373753761, 'bagging_fraction': 0.9557732179280831, 'bagging_freq': 9, 'min_child_samples': 12, 'depth': 10, 'learning_rate': 0.04872508986801844}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7674075079661742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7674075079661742\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16708845228722977, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16708845228722977\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20752722009842384, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20752722009842384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.956290171416013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.956290171416013\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7674075079661742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7674075079661742\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16708845228722977, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16708845228722977\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20752722009842384, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20752722009842384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.956290171416013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.956290171416013\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.013169 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.011563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.010736 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.013480 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.014800 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.013204 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.029093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.012549 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.008778 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.013282 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.010650 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.009041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.008555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.79 MB) transferred to GPU in 0.017728 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7674075079661742, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7674075079661742\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16708845228722977, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16708845228722977\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.20752722009842384, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.20752722009842384\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.956290171416013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.956290171416013\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:33:52,486] Trial 122 finished with value: 0.1103517395156314 and parameters: {'lambda_l1': 0.16708845228722977, 'lambda_l2': 0.20752722009842384, 'num_leaves': 471, 'feature_fraction': 0.7674075079661742, 'bagging_fraction': 0.956290171416013, 'bagging_freq': 8, 'min_child_samples': 16, 'depth': 10, 'learning_rate': 0.049247479322494264}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7660253980226541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7660253980226541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16794914729909735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16794914729909735\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2064179077487254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2064179077487254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9317524521004374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9317524521004374\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7660253980226541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7660253980226541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16794914729909735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16794914729909735\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2064179077487254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2064179077487254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9317524521004374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9317524521004374\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.015548 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.014266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.014025 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.015536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.008951 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.009655 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.011503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.007471 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.008439 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.67 MB) transferred to GPU in 0.007252 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.66 MB) transferred to GPU in 0.009506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7660253980226541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7660253980226541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16794914729909735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16794914729909735\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2064179077487254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2064179077487254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9317524521004374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9317524521004374\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:34:16,858] Trial 123 finished with value: 0.1119743384593142 and parameters: {'lambda_l1': 0.16794914729909735, 'lambda_l2': 0.2064179077487254, 'num_leaves': 433, 'feature_fraction': 0.7660253980226541, 'bagging_fraction': 0.9317524521004374, 'bagging_freq': 10, 'min_child_samples': 17, 'depth': 10, 'learning_rate': 0.04913141543933596}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7415027593475974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415027593475974\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1811819625055913, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1811819625055913\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19603686242144333, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19603686242144333\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9737581468912677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9737581468912677\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415027593475974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415027593475974\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1811819625055913, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1811819625055913\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19603686242144333, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19603686242144333\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9737581468912677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9737581468912677\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.009920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.013845 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.019308 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.024221 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.025821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.017672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.031162 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.010327 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.011512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.010267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.015609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.88 MB) transferred to GPU in 0.011610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415027593475974, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415027593475974\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1811819625055913, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1811819625055913\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19603686242144333, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19603686242144333\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9737581468912677, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9737581468912677\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:34:51,651] Trial 124 finished with value: 0.11103149195895927 and parameters: {'lambda_l1': 0.1811819625055913, 'lambda_l2': 0.19603686242144333, 'num_leaves': 466, 'feature_fraction': 0.7415027593475974, 'bagging_fraction': 0.9737581468912677, 'bagging_freq': 9, 'min_child_samples': 8, 'depth': 10, 'learning_rate': 0.04803228251595986}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7128416553677014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7128416553677014\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19640433590693748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19640433590693748\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19125505337577564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19125505337577564\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850046787052394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850046787052394\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7128416553677014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7128416553677014\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19640433590693748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19640433590693748\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19125505337577564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19125505337577564\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850046787052394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850046787052394\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008700 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7128416553677014, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7128416553677014\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19640433590693748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19640433590693748\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.19125505337577564, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19125505337577564\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850046787052394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850046787052394\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:35:09,577] Trial 125 finished with value: 0.11353807346293446 and parameters: {'lambda_l1': 0.19640433590693748, 'lambda_l2': 0.19125505337577564, 'num_leaves': 476, 'feature_fraction': 0.7128416553677014, 'bagging_fraction': 0.9850046787052394, 'bagging_freq': 0, 'min_child_samples': 16, 'depth': 9, 'learning_rate': 0.049991861372500564}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7939505113850618, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7939505113850618\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21396263407430127, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21396263407430127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21344192965214306, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21344192965214306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9053100965681604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9053100965681604\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7939505113850618, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7939505113850618\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21396263407430127, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21396263407430127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21344192965214306, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21344192965214306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9053100965681604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9053100965681604\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.007878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.008528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.010161 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.007481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.009281 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.009613 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.011776 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.013423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.011437 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.012460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.54 MB) transferred to GPU in 0.009322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.009077 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.53 MB) transferred to GPU in 0.009756 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7939505113850618, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7939505113850618\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21396263407430127, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21396263407430127\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21344192965214306, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21344192965214306\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9053100965681604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9053100965681604\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:35:33,578] Trial 126 finished with value: 0.110692737773613 and parameters: {'lambda_l1': 0.21396263407430127, 'lambda_l2': 0.21344192965214306, 'num_leaves': 455, 'feature_fraction': 0.7939505113850618, 'bagging_fraction': 0.9053100965681604, 'bagging_freq': 8, 'min_child_samples': 19, 'depth': 10, 'learning_rate': 0.04697521031318035}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8083896861617191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8083896861617191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1723191631768601, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1723191631768601\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25178478203870136, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25178478203870136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8544673314947622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8544673314947622\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8083896861617191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8083896861617191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1723191631768601, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1723191631768601\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25178478203870136, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25178478203870136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8544673314947622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8544673314947622\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010345 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007767 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007268 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.010548 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007282 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008098 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006825 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.010112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.010147 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008082 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006907 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008363 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007343 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007338 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007255 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007978 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006217 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006286 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.011086 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007363 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.009999 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007572 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007686 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.008350 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007755 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.009795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007685 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.010770 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.008268 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007592 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008008 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.009820 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008677 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.009938 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007128 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.27 MB) transferred to GPU in 0.007545 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.009061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.009582 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.010221 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007370 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008773 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.010549 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8083896861617191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8083896861617191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1723191631768601, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1723191631768601\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25178478203870136, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25178478203870136\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8544673314947622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8544673314947622\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:35:54,620] Trial 127 finished with value: 0.11008929108677101 and parameters: {'lambda_l1': 0.1723191631768601, 'lambda_l2': 0.25178478203870136, 'num_leaves': 501, 'feature_fraction': 0.8083896861617191, 'bagging_fraction': 0.8544673314947622, 'bagging_freq': 2, 'min_child_samples': 26, 'depth': 10, 'learning_rate': 0.048875625434805926}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8035058001713953, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8035058001713953\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18545114382685524, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18545114382685524\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24560568092857932, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24560568092857932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8651285095276559, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8651285095276559\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8035058001713953, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8035058001713953\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18545114382685524, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18545114382685524\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24560568092857932, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24560568092857932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8651285095276559, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8651285095276559\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007806 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.006084 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.008074 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.008267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.007360 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.010381 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.011301 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.008781 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.009291 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.008746 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.009786 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.009855 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.011877 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.007959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.006602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.007844 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.007355 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.006324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.006682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.006800 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.34 MB) transferred to GPU in 0.007737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.009174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.006386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.009112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.007533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.33 MB) transferred to GPU in 0.007617 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8035058001713953, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8035058001713953\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18545114382685524, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18545114382685524\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24560568092857932, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24560568092857932\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8651285095276559, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8651285095276559\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:36:15,319] Trial 128 finished with value: 0.11036824392338195 and parameters: {'lambda_l1': 0.18545114382685524, 'lambda_l2': 0.24560568092857932, 'num_leaves': 500, 'feature_fraction': 0.8035058001713953, 'bagging_fraction': 0.8651285095276559, 'bagging_freq': 4, 'min_child_samples': 26, 'depth': 10, 'learning_rate': 0.04853893111354561}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8449823895837473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8449823895837473\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17551267764977158, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17551267764977158\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26012962966691966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26012962966691966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9286429372988151, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9286429372988151\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8449823895837473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8449823895837473\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17551267764977158, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17551267764977158\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26012962966691966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26012962966691966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9286429372988151, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9286429372988151\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009022 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007736 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.010033 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008993 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008327 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.009346 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007004 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.009167 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.010711 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007132 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008985 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.009101 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008575 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008437 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008518 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008910 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.009061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.011070 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.009149 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.006790 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007498 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007549 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.006729 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.006687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.006762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007330 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007330 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008193 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008429 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007897 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007830 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007887 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.006824 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008664 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.009007 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007785 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008842 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.64 MB) transferred to GPU in 0.007468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.007931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.006752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008721 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.006952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.006524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.65 MB) transferred to GPU in 0.008931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8449823895837473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8449823895837473\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.17551267764977158, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.17551267764977158\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26012962966691966, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26012962966691966\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9286429372988151, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9286429372988151\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:36:30,847] Trial 129 finished with value: 0.11442070430988384 and parameters: {'lambda_l1': 0.17551267764977158, 'lambda_l2': 0.26012962966691966, 'num_leaves': 505, 'feature_fraction': 0.8449823895837473, 'bagging_fraction': 0.9286429372988151, 'bagging_freq': 2, 'min_child_samples': 24, 'depth': 9, 'learning_rate': 0.0476793261695658}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.829464761173043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.829464761173043\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15955477001159138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15955477001159138\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28631339275957474, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28631339275957474\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8557170746451426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8557170746451426\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.829464761173043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.829464761173043\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15955477001159138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15955477001159138\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28631339275957474, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28631339275957474\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8557170746451426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8557170746451426\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006078 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.008985 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006971 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006548 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006836 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006005 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006826 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.007602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007125 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006498 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.009367 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.007282 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.005125 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.007473 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.008144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006066 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.007488 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.007438 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.009776 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006819 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006382 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006508 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006918 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006183 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.28 MB) transferred to GPU in 0.006140 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006838 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.006235 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.29 MB) transferred to GPU in 0.007151 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.829464761173043, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.829464761173043\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15955477001159138, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15955477001159138\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.28631339275957474, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.28631339275957474\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8557170746451426, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8557170746451426\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:36:53,792] Trial 130 finished with value: 0.1277804216039192 and parameters: {'lambda_l1': 0.15955477001159138, 'lambda_l2': 0.28631339275957474, 'num_leaves': 493, 'feature_fraction': 0.829464761173043, 'bagging_fraction': 0.8557170746451426, 'bagging_freq': 3, 'min_child_samples': 21, 'depth': 10, 'learning_rate': 0.03045075935006311}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7785938996494481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7785938996494481\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1684200054696256, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1684200054696256\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2073639267436653, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2073639267436653\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9666779911964094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9666779911964094\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7785938996494481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7785938996494481\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1684200054696256, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1684200054696256\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2073639267436653, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2073639267436653\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9666779911964094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9666779911964094\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006764 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008201 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007889 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007202 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007138 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008159 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007315 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.009423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007929 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007916 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007935 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007066 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008375 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008325 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008832 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.009154 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007017 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007071 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008168 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007561 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008090 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007032 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007867 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006888 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008016 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006522 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007531 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008088 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006913 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007547 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007561 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006910 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008027 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.006778 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.010308 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007431 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.007849 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.84 MB) transferred to GPU in 0.008126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7785938996494481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7785938996494481\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1684200054696256, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1684200054696256\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2073639267436653, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2073639267436653\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9666779911964094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9666779911964094\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:37:12,706] Trial 131 finished with value: 0.11005674866865818 and parameters: {'lambda_l1': 0.1684200054696256, 'lambda_l2': 0.2073639267436653, 'num_leaves': 473, 'feature_fraction': 0.7785938996494481, 'bagging_fraction': 0.9666779911964094, 'bagging_freq': 2, 'min_child_samples': 12, 'depth': 10, 'learning_rate': 0.049136333056698255}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7789758473954297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7789758473954297\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20172003065192107, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20172003065192107\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23768159670577751, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23768159670577751\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.950582741578763, subsample=1.0 will be ignored. Current value: bagging_fraction=0.950582741578763\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7789758473954297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7789758473954297\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20172003065192107, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20172003065192107\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23768159670577751, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23768159670577751\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.950582741578763, subsample=1.0 will be ignored. Current value: bagging_fraction=0.950582741578763\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006321 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006213 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008428 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008050 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006684 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006701 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006942 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006760 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006853 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008890 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007139 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007944 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006648 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007838 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007207 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007588 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006811 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006789 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007872 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006838 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006754 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008935 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008985 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.015221 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.014992 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.013180 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.022126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.026048 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.017225 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.029153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.014527 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.032295 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.018529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.015193 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.014024 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008824 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008215 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008975 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008873 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009601 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008283 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009049 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009010 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008969 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7789758473954297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7789758473954297\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20172003065192107, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20172003065192107\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23768159670577751, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23768159670577751\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.950582741578763, subsample=1.0 will be ignored. Current value: bagging_fraction=0.950582741578763\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:37:40,646] Trial 132 finished with value: 0.10991458163480246 and parameters: {'lambda_l1': 0.20172003065192107, 'lambda_l2': 0.23768159670577751, 'num_leaves': 484, 'feature_fraction': 0.7789758473954297, 'bagging_fraction': 0.950582741578763, 'bagging_freq': 2, 'min_child_samples': 11, 'depth': 10, 'learning_rate': 0.048424053969933746}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7294242107554592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7294242107554592\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2060710227734603, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2060710227734603\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23291521098074647, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23291521098074647\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9624772341720846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9624772341720846\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7294242107554592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7294242107554592\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2060710227734603, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2060710227734603\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23291521098074647, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23291521098074647\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9624772341720846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9624772341720846\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007841 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.006694 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.006675 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.006881 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008765 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.006952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009084 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009217 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010835 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007024 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.011741 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.011711 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.015495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.012977 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.015914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.013381 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008056 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009255 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008283 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009697 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008998 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007243 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009037 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008668 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008102 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009403 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009124 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009142 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007993 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008432 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007819 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007863 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009069 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008855 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007155 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007209 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009042 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007427 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010700 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008316 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008788 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007069 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010064 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7294242107554592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7294242107554592\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2060710227734603, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2060710227734603\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23291521098074647, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23291521098074647\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9624772341720846, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9624772341720846\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:38:06,901] Trial 133 finished with value: 0.11016379453303056 and parameters: {'lambda_l1': 0.2060710227734603, 'lambda_l2': 0.23291521098074647, 'num_leaves': 481, 'feature_fraction': 0.7294242107554592, 'bagging_fraction': 0.9624772341720846, 'bagging_freq': 2, 'min_child_samples': 5, 'depth': 10, 'learning_rate': 0.049975558096504585}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7257653641158536, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7257653641158536\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2207814441696231, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2207814441696231\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23396388443920255, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23396388443920255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9981697996775519, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9981697996775519\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7257653641158536, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7257653641158536\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2207814441696231, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2207814441696231\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23396388443920255, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23396388443920255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9981697996775519, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9981697996775519\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007422 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.005671 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010166 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008432 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007207 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007133 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008457 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008317 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008558 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007069 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007874 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009459 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008485 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007787 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008129 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008504 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009344 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008104 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010844 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007138 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008252 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010378 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007777 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007371 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.008670 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007956 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.007799 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.009906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010765 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.010776 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.019770 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.020322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.019110 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.017290 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.015811 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.013830 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.014034 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.013160 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.019414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.014458 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.017739 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.017472 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.016740 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.013178 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.027967 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.00 MB) transferred to GPU in 0.024666 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7257653641158536, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7257653641158536\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2207814441696231, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2207814441696231\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23396388443920255, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23396388443920255\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9981697996775519, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9981697996775519\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:38:39,745] Trial 134 finished with value: 0.10983148064578133 and parameters: {'lambda_l1': 0.2207814441696231, 'lambda_l2': 0.23396388443920255, 'num_leaves': 512, 'feature_fraction': 0.7257653641158536, 'bagging_fraction': 0.9981697996775519, 'bagging_freq': 2, 'min_child_samples': 4, 'depth': 10, 'learning_rate': 0.04991349038710073}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7337038761202918, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7337038761202918\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20399484685192903, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20399484685192903\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23931017290731052, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23931017290731052\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994439947957448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994439947957448\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7337038761202918, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7337038761202918\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20399484685192903, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20399484685192903\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23931017290731052, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23931017290731052\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994439947957448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994439947957448\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008019 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7337038761202918, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7337038761202918\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20399484685192903, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20399484685192903\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23931017290731052, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23931017290731052\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994439947957448, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994439947957448\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:39:03,682] Trial 135 finished with value: 0.11040708959445088 and parameters: {'lambda_l1': 0.20399484685192903, 'lambda_l2': 0.23931017290731052, 'num_leaves': 512, 'feature_fraction': 0.7337038761202918, 'bagging_fraction': 0.9994439947957448, 'bagging_freq': 1, 'min_child_samples': 5, 'depth': 10, 'learning_rate': 0.04834713877193439}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6878241923302559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6878241923302559\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21767485914202309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21767485914202309\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23090588785291588, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23090588785291588\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9782273760452316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9782273760452316\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6878241923302559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6878241923302559\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21767485914202309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21767485914202309\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23090588785291588, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23090588785291588\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9782273760452316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9782273760452316\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008043 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008913 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007890 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009202 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.010842 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009774 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009293 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008360 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009741 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.006863 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.010614 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.010469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007189 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009987 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008374 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.005901 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007309 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007861 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008331 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008662 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007012 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008194 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009823 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008824 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007125 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007317 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008154 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.011085 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008156 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007191 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007208 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008531 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008332 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008739 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.008219 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.006915 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009234 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.007413 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.90 MB) transferred to GPU in 0.009310 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6878241923302559, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6878241923302559\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21767485914202309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21767485914202309\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.23090588785291588, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.23090588785291588\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9782273760452316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9782273760452316\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:39:24,450] Trial 136 finished with value: 0.1116899038171943 and parameters: {'lambda_l1': 0.21767485914202309, 'lambda_l2': 0.23090588785291588, 'num_leaves': 482, 'feature_fraction': 0.6878241923302559, 'bagging_fraction': 0.9782273760452316, 'bagging_freq': 2, 'min_child_samples': 1, 'depth': 10, 'learning_rate': 0.04997002578318326}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7242937616395987, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242937616395987\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19386013737695718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19386013737695718\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21993344593886585, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21993344593886585\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9623624979352623, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9623624979352623\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7242937616395987, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242937616395987\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19386013737695718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19386013737695718\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21993344593886585, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21993344593886585\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9623624979352623, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9623624979352623\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.006909 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010994 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009041 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008692 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008601 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008676 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007816 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007912 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008199 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010421 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009833 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009477 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009215 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008027 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007542 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008365 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010008 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008513 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008397 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008850 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007864 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.012424 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.007936 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008197 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008214 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009895 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009192 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010101 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009973 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008731 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009918 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008887 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.011502 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009706 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008282 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.009457 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.010407 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008937 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.011645 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.011646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.011647 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.82 MB) transferred to GPU in 0.008200 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7242937616395987, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7242937616395987\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19386013737695718, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19386013737695718\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.21993344593886585, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.21993344593886585\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9623624979352623, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9623624979352623\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:39:46,872] Trial 137 finished with value: 0.11069709326204126 and parameters: {'lambda_l1': 0.19386013737695718, 'lambda_l2': 0.21993344593886585, 'num_leaves': 501, 'feature_fraction': 0.7242937616395987, 'bagging_fraction': 0.9623624979352623, 'bagging_freq': 2, 'min_child_samples': 6, 'depth': 10, 'learning_rate': 0.04710252155979053}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7543166264168404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7543166264168404\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23138924235425032, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23138924235425032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24941283079554388, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24941283079554388\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9497122116648399, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9497122116648399\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7543166264168404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7543166264168404\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23138924235425032, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23138924235425032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24941283079554388, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24941283079554388\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9497122116648399, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9497122116648399\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009926 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009671 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.008878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006696 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008205 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.008402 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008827 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006994 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008800 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007018 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.006966 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006640 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006782 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008197 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007515 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007696 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006830 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006805 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007805 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007214 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.009025 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.008559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007358 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007223 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.006822 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.006638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.010429 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008179 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008454 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.007718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.007285 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.008487 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.010158 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.020986 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.018695 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.015020 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.014881 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.013229 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.012578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.013748 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.020668 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.012584 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.025731 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.025427 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.022005 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.76 MB) transferred to GPU in 0.018680 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (4.75 MB) transferred to GPU in 0.012997 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7543166264168404, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7543166264168404\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23138924235425032, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23138924235425032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24941283079554388, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24941283079554388\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9497122116648399, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9497122116648399\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:40:15,784] Trial 138 finished with value: 0.11050571060300453 and parameters: {'lambda_l1': 0.23138924235425032, 'lambda_l2': 0.24941283079554388, 'num_leaves': 474, 'feature_fraction': 0.7543166264168404, 'bagging_fraction': 0.9497122116648399, 'bagging_freq': 2, 'min_child_samples': 9, 'depth': 10, 'learning_rate': 0.049007780850772675}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7079592492373135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7079592492373135\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20509756237260865, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20509756237260865\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18489402953846634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18489402953846634\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9995795527424532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9995795527424532\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7079592492373135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7079592492373135\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20509756237260865, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20509756237260865\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18489402953846634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18489402953846634\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9995795527424532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9995795527424532\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.018689 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.013319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011099 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008613 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009132 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008331 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008743 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.006098 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008950 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009666 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.011753 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007916 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008122 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008369 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009057 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007979 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008893 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007165 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007303 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008502 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009329 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008032 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007191 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007178 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009668 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007021 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007297 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7079592492373135, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7079592492373135\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.20509756237260865, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.20509756237260865\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.18489402953846634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.18489402953846634\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9995795527424532, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9995795527424532\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:40:33,718] Trial 139 finished with value: 0.11422677331927356 and parameters: {'lambda_l1': 0.20509756237260865, 'lambda_l2': 0.18489402953846634, 'num_leaves': 498, 'feature_fraction': 0.7079592492373135, 'bagging_fraction': 0.9995795527424532, 'bagging_freq': 3, 'min_child_samples': 4, 'depth': 9, 'learning_rate': 0.04527086450288634}. Best is trial 103 with value: 0.10955033538215246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7759195491829454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7759195491829454\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1891511193624356, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1891511193624356\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26957825068071495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26957825068071495\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97942649847836, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97942649847836\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7759195491829454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7759195491829454\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1891511193624356, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1891511193624356\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26957825068071495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26957825068071495\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97942649847836, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97942649847836\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009856 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7759195491829454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7759195491829454\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1891511193624356, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1891511193624356\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26957825068071495, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26957825068071495\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97942649847836, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97942649847836\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:40:57,962] Trial 140 finished with value: 0.10940168079695908 and parameters: {'lambda_l1': 0.1891511193624356, 'lambda_l2': 0.26957825068071495, 'num_leaves': 512, 'feature_fraction': 0.7759195491829454, 'bagging_fraction': 0.97942649847836, 'bagging_freq': 1, 'min_child_samples': 11, 'depth': 10, 'learning_rate': 0.04743528935357513}. Best is trial 140 with value: 0.10940168079695908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7871130026883549, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7871130026883549\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1867411049596616, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1867411049596616\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2628024639114307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2628024639114307\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9789001021567005, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9789001021567005\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7871130026883549, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7871130026883549\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1867411049596616, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1867411049596616\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2628024639114307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2628024639114307\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9789001021567005, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9789001021567005\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.010597 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7871130026883549, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7871130026883549\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1867411049596616, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1867411049596616\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2628024639114307, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2628024639114307\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9789001021567005, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9789001021567005\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:41:19,095] Trial 141 finished with value: 0.10948527514349471 and parameters: {'lambda_l1': 0.1867411049596616, 'lambda_l2': 0.2628024639114307, 'num_leaves': 509, 'feature_fraction': 0.7871130026883549, 'bagging_fraction': 0.9789001021567005, 'bagging_freq': 1, 'min_child_samples': 11, 'depth': 10, 'learning_rate': 0.047945422249224025}. Best is trial 140 with value: 0.10940168079695908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7811978183300101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7811978183300101\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1894380529891227, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1894380529891227\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26496847810059954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26496847810059954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9861179431354584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9861179431354584\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7811978183300101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7811978183300101\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1894380529891227, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1894380529891227\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26496847810059954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26496847810059954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9861179431354584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9861179431354584\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7811978183300101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7811978183300101\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1894380529891227, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1894380529891227\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26496847810059954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26496847810059954\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9861179431354584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9861179431354584\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:41:36,751] Trial 142 finished with value: 0.1098824958541448 and parameters: {'lambda_l1': 0.1894380529891227, 'lambda_l2': 0.26496847810059954, 'num_leaves': 507, 'feature_fraction': 0.7811978183300101, 'bagging_fraction': 0.9861179431354584, 'bagging_freq': 1, 'min_child_samples': 11, 'depth': 10, 'learning_rate': 0.04732268909546915}. Best is trial 140 with value: 0.10940168079695908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7804468822871994, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7804468822871994\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18794260867314214, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18794260867314214\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26865956404006713, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26865956404006713\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9885981744919332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9885981744919332\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7804468822871994, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7804468822871994\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18794260867314214, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18794260867314214\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26865956404006713, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26865956404006713\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9885981744919332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9885981744919332\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009674 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7804468822871994, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7804468822871994\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18794260867314214, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18794260867314214\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26865956404006713, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26865956404006713\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9885981744919332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9885981744919332\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:41:54,647] Trial 143 finished with value: 0.10982258420722942 and parameters: {'lambda_l1': 0.18794260867314214, 'lambda_l2': 0.26865956404006713, 'num_leaves': 511, 'feature_fraction': 0.7804468822871994, 'bagging_fraction': 0.9885981744919332, 'bagging_freq': 1, 'min_child_samples': 10, 'depth': 10, 'learning_rate': 0.0471381752263991}. Best is trial 140 with value: 0.10940168079695908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7757139440291877, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7757139440291877\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.188321452579106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.188321452579106\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2695119703494719, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2695119703494719\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.982151827286721, subsample=1.0 will be ignored. Current value: bagging_fraction=0.982151827286721\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7757139440291877, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7757139440291877\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.188321452579106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.188321452579106\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2695119703494719, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2695119703494719\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.982151827286721, subsample=1.0 will be ignored. Current value: bagging_fraction=0.982151827286721\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7757139440291877, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7757139440291877\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.188321452579106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.188321452579106\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2695119703494719, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2695119703494719\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.982151827286721, subsample=1.0 will be ignored. Current value: bagging_fraction=0.982151827286721\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:42:14,228] Trial 144 finished with value: 0.11011048386970038 and parameters: {'lambda_l1': 0.188321452579106, 'lambda_l2': 0.2695119703494719, 'num_leaves': 512, 'feature_fraction': 0.7757139440291877, 'bagging_fraction': 0.982151827286721, 'bagging_freq': 1, 'min_child_samples': 8, 'depth': 10, 'learning_rate': 0.046965256053744416}. Best is trial 140 with value: 0.10940168079695908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7530048608014923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7530048608014923\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18728241485045077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18728241485045077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25602264363993316, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25602264363993316\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9830654828877716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9830654828877716\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7530048608014923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7530048608014923\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18728241485045077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18728241485045077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25602264363993316, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25602264363993316\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9830654828877716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9830654828877716\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7530048608014923, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7530048608014923\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18728241485045077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18728241485045077\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25602264363993316, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25602264363993316\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9830654828877716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9830654828877716\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:42:34,270] Trial 145 finished with value: 0.1198702668648878 and parameters: {'lambda_l1': 0.18728241485045077, 'lambda_l2': 0.25602264363993316, 'num_leaves': 512, 'feature_fraction': 0.7530048608014923, 'bagging_fraction': 0.9830654828877716, 'bagging_freq': 1, 'min_child_samples': 11, 'depth': 10, 'learning_rate': 0.035119049008843675}. Best is trial 140 with value: 0.10940168079695908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7801161425528506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7801161425528506\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19747318940116498, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19747318940116498\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.272602869442682, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.272602869442682\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9982645413116632, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9982645413116632\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7801161425528506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7801161425528506\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19747318940116498, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19747318940116498\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.272602869442682, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.272602869442682\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9982645413116632, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9982645413116632\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007108 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7801161425528506, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7801161425528506\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.19747318940116498, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.19747318940116498\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.272602869442682, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.272602869442682\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9982645413116632, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9982645413116632\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:42:53,421] Trial 146 finished with value: 0.11120567172350741 and parameters: {'lambda_l1': 0.19747318940116498, 'lambda_l2': 0.272602869442682, 'num_leaves': 502, 'feature_fraction': 0.7801161425528506, 'bagging_fraction': 0.9982645413116632, 'bagging_freq': 0, 'min_child_samples': 10, 'depth': 10, 'learning_rate': 0.0437908476842125}. Best is trial 140 with value: 0.10940168079695908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7895590451181603, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7895590451181603\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18348477114539682, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18348477114539682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25598450860078575, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25598450860078575\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9744207246603653, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9744207246603653\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7895590451181603, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7895590451181603\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18348477114539682, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18348477114539682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25598450860078575, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25598450860078575\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9744207246603653, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9744207246603653\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.008963 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7895590451181603, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7895590451181603\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18348477114539682, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18348477114539682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.25598450860078575, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.25598450860078575\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9744207246603653, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9744207246603653\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:43:12,739] Trial 147 finished with value: 0.11194683174902494 and parameters: {'lambda_l1': 0.18348477114539682, 'lambda_l2': 0.25598450860078575, 'num_leaves': 495, 'feature_fraction': 0.7895590451181603, 'bagging_fraction': 0.9744207246603653, 'bagging_freq': 1, 'min_child_samples': 2, 'depth': 10, 'learning_rate': 0.04749104327143104}. Best is trial 140 with value: 0.10940168079695908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7668822677184215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668822677184215\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21844060002365762, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21844060002365762\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24360563643291527, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24360563643291527\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9462386572168595, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9462386572168595\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668822677184215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668822677184215\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21844060002365762, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21844060002365762\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24360563643291527, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24360563643291527\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9462386572168595, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9462386572168595\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.009856 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668822677184215, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668822677184215\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.21844060002365762, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21844060002365762\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.24360563643291527, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.24360563643291527\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9462386572168595, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9462386572168595\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:43:31,974] Trial 148 finished with value: 0.11148727300759287 and parameters: {'lambda_l1': 0.21844060002365762, 'lambda_l2': 0.24360563643291527, 'num_leaves': 503, 'feature_fraction': 0.7668822677184215, 'bagging_fraction': 0.9462386572168595, 'bagging_freq': 1, 'min_child_samples': 7, 'depth': 10, 'learning_rate': 0.045104343594530256}. Best is trial 140 with value: 0.10940168079695908.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8016913379892363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8016913379892363\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2366029990551643, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2366029990551643\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27974249330191536, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.27974249330191536\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9274655355084209, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9274655355084209\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8016913379892363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8016913379892363\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2366029990551643, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2366029990551643\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.27974249330191536, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.27974249330191536\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9274655355084209, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9274655355084209\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (5.01 MB) transferred to GPU in 0.007555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-08-29 17:43:38,686] Trial 149 failed with parameters: {'lambda_l1': 0.2366029990551643, 'lambda_l2': 0.27974249330191536, 'num_leaves': 512, 'feature_fraction': 0.8016913379892363, 'bagging_fraction': 0.9274655355084209, 'bagging_freq': 0, 'min_child_samples': 13, 'depth': 10, 'learning_rate': 0.026381604809910607} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\vsevo\\AppData\\Local\\Temp\\ipykernel_3084\\1644584269.py\", line 56, in lgbm_objective_reg\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1062, in fit\n",
      "    init_model=init_model\n",
      "  File \"c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\", line 851, in fit\n",
      "    callbacks=callbacks\n",
      "  File \"c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\lightgbm\\engine.py\", line 266, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\lightgbm\\basic.py\", line 3559, in update\n",
      "    ctypes.byref(is_finished)))\n",
      "KeyboardInterrupt\n",
      "[W 2023-08-29 17:43:38,692] Trial 149 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3084\\2697066646.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"minimize\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbm_objective_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m         )\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     ):\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3084\\1644584269.py\u001b[0m in \u001b[0;36mlgbm_objective_reg\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mpred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1062\u001b[1;33m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1063\u001b[0m         )\n\u001b[0;32m   1064\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    849\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m             \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m         )\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    264\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3557\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   3558\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3559\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   3560\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3561\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(lgbm_objective_reg, n_trials=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "613c685d-53aa-46cf-b83b-2b3d5c13d921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-29 17:43:51,706] A new study created in memory with name: no-name-cc63a406-c685-4507-be84-f87bcd49e8a3\n",
      "[I 2023-08-29 17:44:17,708] Trial 0 finished with value: 0.14659023189578757 and parameters: {'iterations': 2285, 'learning_rate': 0.029416835583228888, 'max_depth': 2, 'l2_leaf_reg': 0.7827301577410559}. Best is trial 0 with value: 0.14659023189578757.\n",
      "[I 2023-08-29 17:44:43,042] Trial 1 finished with value: 0.12695658878980526 and parameters: {'iterations': 1149, 'learning_rate': 0.03406152940610912, 'max_depth': 6, 'l2_leaf_reg': 0.9702562626022908}. Best is trial 1 with value: 0.12695658878980526.\n",
      "[I 2023-08-29 17:46:35,029] Trial 2 finished with value: 0.10193737545174451 and parameters: {'iterations': 2064, 'learning_rate': 0.040131647011355055, 'max_depth': 10, 'l2_leaf_reg': 0.5809000887906433}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:46:42,374] Trial 3 finished with value: 0.3670002968173224 and parameters: {'iterations': 140, 'learning_rate': 0.010482436855288968, 'max_depth': 6, 'l2_leaf_reg': 0.6169664584406642}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:47:07,935] Trial 4 finished with value: 0.13271335743673365 and parameters: {'iterations': 606, 'learning_rate': 0.026926982446987175, 'max_depth': 7, 'l2_leaf_reg': 0.7934400340509984}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:48:05,568] Trial 5 finished with value: 0.13704562710570145 and parameters: {'iterations': 2309, 'learning_rate': 0.03539232780167621, 'max_depth': 3, 'l2_leaf_reg': 0.8768364263167332}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:48:45,555] Trial 6 finished with value: 0.13037238922321473 and parameters: {'iterations': 1813, 'learning_rate': 0.041428100550229156, 'max_depth': 4, 'l2_leaf_reg': 0.2702408660447939}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:49:44,346] Trial 7 finished with value: 0.15252400711044417 and parameters: {'iterations': 2575, 'learning_rate': 0.002673464037090597, 'max_depth': 6, 'l2_leaf_reg': 0.6457700642730329}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:49:54,014] Trial 8 finished with value: 0.278490799700012 and parameters: {'iterations': 229, 'learning_rate': 0.008046421525695164, 'max_depth': 10, 'l2_leaf_reg': 0.13397298668973923}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:50:59,939] Trial 9 finished with value: 0.19947938188870853 and parameters: {'iterations': 1339, 'learning_rate': 0.002353308796683793, 'max_depth': 9, 'l2_leaf_reg': 0.9589136432224606}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:52:13,435] Trial 10 finished with value: 0.1075442824861837 and parameters: {'iterations': 2994, 'learning_rate': 0.049365057314617974, 'max_depth': 8, 'l2_leaf_reg': 0.3844125315027035}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:53:09,592] Trial 11 finished with value: 0.1099628338409848 and parameters: {'iterations': 2944, 'learning_rate': 0.04998184293391495, 'max_depth': 8, 'l2_leaf_reg': 0.43089522711117817}. Best is trial 2 with value: 0.10193737545174451.\n",
      "[I 2023-08-29 17:57:01,112] Trial 12 finished with value: 0.09386950365278958 and parameters: {'iterations': 2974, 'learning_rate': 0.049933384664045635, 'max_depth': 10, 'l2_leaf_reg': 0.4146524901999288}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 17:58:45,388] Trial 13 finished with value: 0.10265351770340947 and parameters: {'iterations': 1846, 'learning_rate': 0.041777899390758835, 'max_depth': 10, 'l2_leaf_reg': 0.5134863309977497}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 18:01:17,319] Trial 14 finished with value: 0.10673647636911429 and parameters: {'iterations': 2507, 'learning_rate': 0.02102150920769572, 'max_depth': 10, 'l2_leaf_reg': 0.2935660493544771}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 18:02:25,927] Trial 15 finished with value: 0.10960682021191734 and parameters: {'iterations': 1940, 'learning_rate': 0.04514308062935212, 'max_depth': 8, 'l2_leaf_reg': 0.008038745977265283}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 18:02:59,577] Trial 16 finished with value: 0.1164338184150795 and parameters: {'iterations': 891, 'learning_rate': 0.04147142088061476, 'max_depth': 9, 'l2_leaf_reg': 0.6007659523105006}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 18:03:53,937] Trial 17 finished with value: 0.12371127188699657 and parameters: {'iterations': 2682, 'learning_rate': 0.034943118888606454, 'max_depth': 5, 'l2_leaf_reg': 0.5032126193642052}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 18:05:09,026] Trial 18 finished with value: 0.10511628653815595 and parameters: {'iterations': 2088, 'learning_rate': 0.045140262591423466, 'max_depth': 9, 'l2_leaf_reg': 0.7090211389006971}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 18:05:52,180] Trial 19 finished with value: 0.11657195078660884 and parameters: {'iterations': 1570, 'learning_rate': 0.04932544271147475, 'max_depth': 7, 'l2_leaf_reg': 0.5309403060920028}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 18:06:58,544] Trial 20 finished with value: 0.11232686652527489 and parameters: {'iterations': 1561, 'learning_rate': 0.021989866097490724, 'max_depth': 10, 'l2_leaf_reg': 0.40591024632620476}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 18:08:28,434] Trial 21 finished with value: 0.10185463823603998 and parameters: {'iterations': 2117, 'learning_rate': 0.03940226596602812, 'max_depth': 10, 'l2_leaf_reg': 0.5328480189970595}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[I 2023-08-29 18:09:57,998] Trial 22 finished with value: 0.10667651893593884 and parameters: {'iterations': 2223, 'learning_rate': 0.03872758114666422, 'max_depth': 9, 'l2_leaf_reg': 0.5777477255649748}. Best is trial 12 with value: 0.09386950365278958.\n",
      "[W 2023-08-29 18:11:26,544] Trial 23 failed with parameters: {'iterations': 2786, 'learning_rate': 0.0457527677668123, 'max_depth': 10, 'l2_leaf_reg': 0.6632702792139415} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\vsevo\\AppData\\Local\\Temp\\ipykernel_3084\\1644584269.py\", line 76, in cb_objective_reg\n",
      "    model.fit(X_train, y_train, silent=True, eval_set=(X_test, y_test), early_stopping_rounds=50)\n",
      "  File \"c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\catboost\\core.py\", line 5707, in fit\n",
      "    save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "  File \"c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\catboost\\core.py\", line 2324, in _fit\n",
      "    train_params[\"init_model\"]\n",
      "  File \"c:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\catboost\\core.py\", line 1723, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4625, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4674, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2023-08-29 18:11:26,544] Trial 23 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3084\\1380874693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"minimize\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcb_objective_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m         )\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     ):\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3084\\1644584269.py\u001b[0m in \u001b[0;36mcb_objective_reg\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0mpred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5705\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5706\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5707\u001b[1;33m                          save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0m\u001b[0;32m   5708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5709\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"CPU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2322\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2323\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2324\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2325\u001b[0m             )\n\u001b[0;32m   2326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsevo\\pycharmprojects\\pythonproject2\\venv\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1723\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1724\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study1 = optuna.create_study(direction=\"minimize\")\n",
    "study1.optimize(cb_objective_reg, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7728433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_param = {'lambda_l1': 0.1873614189651116, 'lambda_l2': 0.30002810690969617, 'num_leaves': 462, 'feature_fraction': 0.775150906035067, 'bagging_fraction': 0.9126199831365078, 'bagging_freq': 8, 'min_child_samples': 15, 'depth': 10, 'learning_rate': 0.04885918962472099}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b395a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param = {'depth': 10, 'learning_rate': 0.04997590541942759, 'lambda': 0.0704821218024878, 'alpha': 0.38527237892202787, 'subsample': 0.9919547695879909}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cd3fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_param =  {'iterations': 2974, 'learning_rate': 0.049933384664045635, 'max_depth': 10, 'l2_leaf_reg': 0.4146524901999288}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59f9d23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] feature_fraction is set=0.775150906035067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775150906035067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1873614189651116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1873614189651116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30002810690969617, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30002810690969617\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9126199831365078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9126199831365078\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] feature_fraction is set=0.775150906035067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775150906035067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1873614189651116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1873614189651116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30002810690969617, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30002810690969617\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9126199831365078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9126199831365078\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1955\n",
      "[LightGBM] [Info] Number of data points in the train set: 437620, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 21133690.457420\n",
      "[18:16:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"depth\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "0:\tlearn: 35528733.3134412\ttotal: 81.7ms\tremaining: 4m 2s\n",
      "1:\tlearn: 34293866.1987887\ttotal: 159ms\tremaining: 3m 56s\n",
      "2:\tlearn: 33126959.8015162\ttotal: 238ms\tremaining: 3m 55s\n",
      "3:\tlearn: 32036804.9920359\ttotal: 323ms\tremaining: 3m 59s\n",
      "4:\tlearn: 31025211.5945105\ttotal: 404ms\tremaining: 3m 59s\n",
      "5:\tlearn: 30075778.3655329\ttotal: 479ms\tremaining: 3m 57s\n",
      "6:\tlearn: 29166714.8089258\ttotal: 553ms\tremaining: 3m 54s\n",
      "7:\tlearn: 28312067.9143089\ttotal: 626ms\tremaining: 3m 52s\n",
      "8:\tlearn: 27531975.6085143\ttotal: 697ms\tremaining: 3m 49s\n",
      "9:\tlearn: 26764099.7305219\ttotal: 771ms\tremaining: 3m 48s\n",
      "10:\tlearn: 26049395.8375972\ttotal: 861ms\tremaining: 3m 51s\n",
      "11:\tlearn: 25375488.0523112\ttotal: 935ms\tremaining: 3m 50s\n",
      "12:\tlearn: 24770152.6816086\ttotal: 1.02s\tremaining: 3m 51s\n",
      "13:\tlearn: 24164795.8368752\ttotal: 1.09s\tremaining: 3m 51s\n",
      "14:\tlearn: 23642597.2973149\ttotal: 1.17s\tremaining: 3m 50s\n",
      "15:\tlearn: 23117983.1538570\ttotal: 1.24s\tremaining: 3m 49s\n",
      "16:\tlearn: 22607215.7901885\ttotal: 1.31s\tremaining: 3m 48s\n",
      "17:\tlearn: 22155480.9316019\ttotal: 1.39s\tremaining: 3m 48s\n",
      "18:\tlearn: 21736675.2229548\ttotal: 1.46s\tremaining: 3m 47s\n",
      "19:\tlearn: 21332277.0272628\ttotal: 1.54s\tremaining: 3m 46s\n",
      "20:\tlearn: 20929246.2044667\ttotal: 1.61s\tremaining: 3m 46s\n",
      "21:\tlearn: 20573857.9665766\ttotal: 1.68s\tremaining: 3m 45s\n",
      "22:\tlearn: 20202794.6953977\ttotal: 1.75s\tremaining: 3m 45s\n",
      "23:\tlearn: 19898343.8210026\ttotal: 1.83s\tremaining: 3m 44s\n",
      "24:\tlearn: 19600443.7943556\ttotal: 1.91s\tremaining: 3m 45s\n",
      "25:\tlearn: 19312406.3220462\ttotal: 1.99s\tremaining: 3m 45s\n",
      "26:\tlearn: 19063539.4099670\ttotal: 2.07s\tremaining: 3m 45s\n",
      "27:\tlearn: 18818545.8051906\ttotal: 2.15s\tremaining: 3m 46s\n",
      "28:\tlearn: 18564789.6159300\ttotal: 2.23s\tremaining: 3m 46s\n",
      "29:\tlearn: 18345277.1305617\ttotal: 2.3s\tremaining: 3m 46s\n",
      "30:\tlearn: 18150529.8285492\ttotal: 2.38s\tremaining: 3m 45s\n",
      "31:\tlearn: 17964954.6916947\ttotal: 2.46s\tremaining: 3m 45s\n",
      "32:\tlearn: 17808899.9296366\ttotal: 2.53s\tremaining: 3m 45s\n",
      "33:\tlearn: 17655116.2155246\ttotal: 2.61s\tremaining: 3m 45s\n",
      "34:\tlearn: 17483335.1892271\ttotal: 2.69s\tremaining: 3m 45s\n",
      "35:\tlearn: 17339867.4313676\ttotal: 2.77s\tremaining: 3m 45s\n",
      "36:\tlearn: 17197372.1404434\ttotal: 2.85s\tremaining: 3m 46s\n",
      "37:\tlearn: 17053880.9461923\ttotal: 2.93s\tremaining: 3m 46s\n",
      "38:\tlearn: 16915575.9628025\ttotal: 3s\tremaining: 3m 46s\n",
      "39:\tlearn: 16793322.0568264\ttotal: 3.09s\tremaining: 3m 46s\n",
      "40:\tlearn: 16699459.9435650\ttotal: 3.16s\tremaining: 3m 46s\n",
      "41:\tlearn: 16577222.4094998\ttotal: 3.23s\tremaining: 3m 45s\n",
      "42:\tlearn: 16472958.3016854\ttotal: 3.31s\tremaining: 3m 45s\n",
      "43:\tlearn: 16365546.7578034\ttotal: 3.38s\tremaining: 3m 44s\n",
      "44:\tlearn: 16271988.2262848\ttotal: 3.45s\tremaining: 3m 44s\n",
      "45:\tlearn: 16178444.5538565\ttotal: 3.52s\tremaining: 3m 43s\n",
      "46:\tlearn: 16064444.7405047\ttotal: 3.6s\tremaining: 3m 44s\n",
      "47:\tlearn: 15970360.4783633\ttotal: 3.68s\tremaining: 3m 44s\n",
      "48:\tlearn: 15905190.9180506\ttotal: 3.76s\tremaining: 3m 44s\n",
      "49:\tlearn: 15833125.6828910\ttotal: 3.85s\tremaining: 3m 45s\n",
      "50:\tlearn: 15761772.0654600\ttotal: 3.94s\tremaining: 3m 45s\n",
      "51:\tlearn: 15677208.1113978\ttotal: 4.02s\tremaining: 3m 45s\n",
      "52:\tlearn: 15622925.3356364\ttotal: 4.11s\tremaining: 3m 46s\n",
      "53:\tlearn: 15521806.2344414\ttotal: 4.18s\tremaining: 3m 45s\n",
      "54:\tlearn: 15456390.7358355\ttotal: 4.25s\tremaining: 3m 45s\n",
      "55:\tlearn: 15409106.0808644\ttotal: 4.32s\tremaining: 3m 45s\n",
      "56:\tlearn: 15349949.2813545\ttotal: 4.4s\tremaining: 3m 45s\n",
      "57:\tlearn: 15276534.7610460\ttotal: 4.47s\tremaining: 3m 44s\n",
      "58:\tlearn: 15215925.2315704\ttotal: 4.56s\tremaining: 3m 45s\n",
      "59:\tlearn: 15165479.7630616\ttotal: 4.64s\tremaining: 3m 45s\n",
      "60:\tlearn: 15117560.3145823\ttotal: 4.72s\tremaining: 3m 45s\n",
      "61:\tlearn: 15071752.0027000\ttotal: 4.81s\tremaining: 3m 46s\n",
      "62:\tlearn: 15019070.6220851\ttotal: 4.9s\tremaining: 3m 46s\n",
      "63:\tlearn: 14962446.1420309\ttotal: 4.97s\tremaining: 3m 46s\n",
      "64:\tlearn: 14926326.1113811\ttotal: 5.05s\tremaining: 3m 46s\n",
      "65:\tlearn: 14881773.3966659\ttotal: 5.13s\tremaining: 3m 46s\n",
      "66:\tlearn: 14813901.8091973\ttotal: 5.21s\tremaining: 3m 46s\n",
      "67:\tlearn: 14764721.8622500\ttotal: 5.29s\tremaining: 3m 46s\n",
      "68:\tlearn: 14731618.1013119\ttotal: 5.37s\tremaining: 3m 46s\n",
      "69:\tlearn: 14683802.6007304\ttotal: 5.45s\tremaining: 3m 46s\n",
      "70:\tlearn: 14636390.5963732\ttotal: 5.53s\tremaining: 3m 46s\n",
      "71:\tlearn: 14609896.6557955\ttotal: 5.61s\tremaining: 3m 45s\n",
      "72:\tlearn: 14570832.8484287\ttotal: 5.68s\tremaining: 3m 45s\n",
      "73:\tlearn: 14511255.9474275\ttotal: 5.76s\tremaining: 3m 45s\n",
      "74:\tlearn: 14474793.4615313\ttotal: 5.84s\tremaining: 3m 45s\n",
      "75:\tlearn: 14441461.4160654\ttotal: 5.92s\tremaining: 3m 45s\n",
      "76:\tlearn: 14407842.2880663\ttotal: 6s\tremaining: 3m 45s\n",
      "77:\tlearn: 14368745.6120345\ttotal: 6.07s\tremaining: 3m 45s\n",
      "78:\tlearn: 14334492.1709308\ttotal: 6.14s\tremaining: 3m 45s\n",
      "79:\tlearn: 14295885.3122171\ttotal: 6.22s\tremaining: 3m 45s\n",
      "80:\tlearn: 14272062.7277137\ttotal: 6.31s\tremaining: 3m 45s\n",
      "81:\tlearn: 14241544.5535782\ttotal: 6.38s\tremaining: 3m 45s\n",
      "82:\tlearn: 14226492.0635852\ttotal: 6.45s\tremaining: 3m 44s\n",
      "83:\tlearn: 14197345.8865382\ttotal: 6.53s\tremaining: 3m 44s\n",
      "84:\tlearn: 14149967.9286070\ttotal: 6.6s\tremaining: 3m 44s\n",
      "85:\tlearn: 14130147.3042153\ttotal: 6.67s\tremaining: 3m 43s\n",
      "86:\tlearn: 14068404.6754832\ttotal: 6.75s\tremaining: 3m 43s\n",
      "87:\tlearn: 14037336.3465698\ttotal: 6.83s\tremaining: 3m 44s\n",
      "88:\tlearn: 14015039.6274683\ttotal: 6.92s\tremaining: 3m 44s\n",
      "89:\tlearn: 13977979.7537187\ttotal: 7s\tremaining: 3m 44s\n",
      "90:\tlearn: 13946438.4240550\ttotal: 7.09s\tremaining: 3m 44s\n",
      "91:\tlearn: 13916814.4765377\ttotal: 7.17s\tremaining: 3m 44s\n",
      "92:\tlearn: 13899778.3235539\ttotal: 7.26s\tremaining: 3m 44s\n",
      "93:\tlearn: 13876619.1322597\ttotal: 7.34s\tremaining: 3m 44s\n",
      "94:\tlearn: 13849661.9746410\ttotal: 7.42s\tremaining: 3m 45s\n",
      "95:\tlearn: 13834947.1651852\ttotal: 7.5s\tremaining: 3m 44s\n",
      "96:\tlearn: 13803035.7945342\ttotal: 7.57s\tremaining: 3m 44s\n",
      "97:\tlearn: 13781685.8400636\ttotal: 7.65s\tremaining: 3m 44s\n",
      "98:\tlearn: 13757216.7393334\ttotal: 7.73s\tremaining: 3m 44s\n",
      "99:\tlearn: 13744103.0469101\ttotal: 7.81s\tremaining: 3m 44s\n",
      "100:\tlearn: 13714430.9312962\ttotal: 7.89s\tremaining: 3m 44s\n",
      "101:\tlearn: 13666502.9982141\ttotal: 7.97s\tremaining: 3m 44s\n",
      "102:\tlearn: 13622622.1961295\ttotal: 8.05s\tremaining: 3m 44s\n",
      "103:\tlearn: 13600336.4648161\ttotal: 8.13s\tremaining: 3m 44s\n",
      "104:\tlearn: 13572919.2975421\ttotal: 8.2s\tremaining: 3m 44s\n",
      "105:\tlearn: 13549287.6122644\ttotal: 8.27s\tremaining: 3m 43s\n",
      "106:\tlearn: 13534155.1478926\ttotal: 8.35s\tremaining: 3m 43s\n",
      "107:\tlearn: 13520552.8641942\ttotal: 8.42s\tremaining: 3m 43s\n",
      "108:\tlearn: 13476003.8012796\ttotal: 8.49s\tremaining: 3m 43s\n",
      "109:\tlearn: 13451989.6775274\ttotal: 8.57s\tremaining: 3m 43s\n",
      "110:\tlearn: 13440020.1293523\ttotal: 8.64s\tremaining: 3m 42s\n",
      "111:\tlearn: 13413378.5136649\ttotal: 8.72s\tremaining: 3m 42s\n",
      "112:\tlearn: 13396973.7921064\ttotal: 8.8s\tremaining: 3m 42s\n",
      "113:\tlearn: 13370833.8693207\ttotal: 8.87s\tremaining: 3m 42s\n",
      "114:\tlearn: 13346933.1361435\ttotal: 8.94s\tremaining: 3m 42s\n",
      "115:\tlearn: 13329096.2904795\ttotal: 9.02s\tremaining: 3m 42s\n",
      "116:\tlearn: 13305909.7941793\ttotal: 9.11s\tremaining: 3m 42s\n",
      "117:\tlearn: 13281641.6813055\ttotal: 9.18s\tremaining: 3m 42s\n",
      "118:\tlearn: 13273539.5577669\ttotal: 9.26s\tremaining: 3m 42s\n",
      "119:\tlearn: 13265379.9523629\ttotal: 9.33s\tremaining: 3m 41s\n",
      "120:\tlearn: 13244269.3536985\ttotal: 9.4s\tremaining: 3m 41s\n",
      "121:\tlearn: 13200221.5872103\ttotal: 9.47s\tremaining: 3m 41s\n",
      "122:\tlearn: 13179724.2766473\ttotal: 9.54s\tremaining: 3m 41s\n",
      "123:\tlearn: 13158578.1519576\ttotal: 9.62s\tremaining: 3m 41s\n",
      "124:\tlearn: 13146221.8810436\ttotal: 9.7s\tremaining: 3m 41s\n",
      "125:\tlearn: 13123145.4335010\ttotal: 9.79s\tremaining: 3m 41s\n",
      "126:\tlearn: 13097083.5804005\ttotal: 9.87s\tremaining: 3m 41s\n",
      "127:\tlearn: 13085074.0701195\ttotal: 9.96s\tremaining: 3m 41s\n",
      "128:\tlearn: 13060122.3964349\ttotal: 10s\tremaining: 3m 41s\n",
      "129:\tlearn: 13046619.2045594\ttotal: 10.1s\tremaining: 3m 41s\n",
      "130:\tlearn: 13012985.2668991\ttotal: 10.2s\tremaining: 3m 40s\n",
      "131:\tlearn: 12991681.1813505\ttotal: 10.2s\tremaining: 3m 40s\n",
      "132:\tlearn: 12957357.4414210\ttotal: 10.3s\tremaining: 3m 40s\n",
      "133:\tlearn: 12929013.9797011\ttotal: 10.4s\tremaining: 3m 40s\n",
      "134:\tlearn: 12904621.4528831\ttotal: 10.5s\tremaining: 3m 40s\n",
      "135:\tlearn: 12865546.8801794\ttotal: 10.5s\tremaining: 3m 39s\n",
      "136:\tlearn: 12849645.5493597\ttotal: 10.6s\tremaining: 3m 40s\n",
      "137:\tlearn: 12816167.6180654\ttotal: 10.7s\tremaining: 3m 39s\n",
      "138:\tlearn: 12801530.7300875\ttotal: 10.8s\tremaining: 3m 39s\n",
      "139:\tlearn: 12777693.4059899\ttotal: 10.9s\tremaining: 3m 39s\n",
      "140:\tlearn: 12759132.4185803\ttotal: 10.9s\tremaining: 3m 39s\n",
      "141:\tlearn: 12751921.8540046\ttotal: 11s\tremaining: 3m 39s\n",
      "142:\tlearn: 12738331.4755780\ttotal: 11.1s\tremaining: 3m 39s\n",
      "143:\tlearn: 12717752.7473281\ttotal: 11.2s\tremaining: 3m 39s\n",
      "144:\tlearn: 12698092.8989593\ttotal: 11.2s\tremaining: 3m 39s\n",
      "145:\tlearn: 12680694.0296940\ttotal: 11.3s\tremaining: 3m 39s\n",
      "146:\tlearn: 12650648.5423443\ttotal: 11.4s\tremaining: 3m 38s\n",
      "147:\tlearn: 12639535.7665075\ttotal: 11.5s\tremaining: 3m 38s\n",
      "148:\tlearn: 12610627.9858706\ttotal: 11.5s\tremaining: 3m 38s\n",
      "149:\tlearn: 12580233.6962694\ttotal: 11.6s\tremaining: 3m 38s\n",
      "150:\tlearn: 12573073.4785173\ttotal: 11.7s\tremaining: 3m 38s\n",
      "151:\tlearn: 12556114.7796109\ttotal: 11.8s\tremaining: 3m 38s\n",
      "152:\tlearn: 12544552.2443417\ttotal: 11.8s\tremaining: 3m 38s\n",
      "153:\tlearn: 12524579.3421127\ttotal: 11.9s\tremaining: 3m 38s\n",
      "154:\tlearn: 12515452.1312142\ttotal: 12s\tremaining: 3m 38s\n",
      "155:\tlearn: 12501574.3609677\ttotal: 12.1s\tremaining: 3m 38s\n",
      "156:\tlearn: 12484104.2211665\ttotal: 12.2s\tremaining: 3m 38s\n",
      "157:\tlearn: 12463470.4345792\ttotal: 12.2s\tremaining: 3m 37s\n",
      "158:\tlearn: 12430933.3784929\ttotal: 12.3s\tremaining: 3m 37s\n",
      "159:\tlearn: 12392731.5916243\ttotal: 12.4s\tremaining: 3m 37s\n",
      "160:\tlearn: 12371866.4070733\ttotal: 12.4s\tremaining: 3m 37s\n",
      "161:\tlearn: 12360451.7373904\ttotal: 12.5s\tremaining: 3m 37s\n",
      "162:\tlearn: 12348154.1052009\ttotal: 12.6s\tremaining: 3m 36s\n",
      "163:\tlearn: 12336109.3101124\ttotal: 12.6s\tremaining: 3m 36s\n",
      "164:\tlearn: 12311070.3063056\ttotal: 12.7s\tremaining: 3m 36s\n",
      "165:\tlearn: 12298676.1844222\ttotal: 12.8s\tremaining: 3m 36s\n",
      "166:\tlearn: 12270573.8291478\ttotal: 12.9s\tremaining: 3m 36s\n",
      "167:\tlearn: 12248727.6938365\ttotal: 12.9s\tremaining: 3m 36s\n",
      "168:\tlearn: 12215438.0528185\ttotal: 13s\tremaining: 3m 36s\n",
      "169:\tlearn: 12207637.0671129\ttotal: 13.1s\tremaining: 3m 35s\n",
      "170:\tlearn: 12184352.0343560\ttotal: 13.2s\tremaining: 3m 35s\n",
      "171:\tlearn: 12175187.8828997\ttotal: 13.2s\tremaining: 3m 35s\n",
      "172:\tlearn: 12144762.0430219\ttotal: 13.3s\tremaining: 3m 35s\n",
      "173:\tlearn: 12110182.6685331\ttotal: 13.4s\tremaining: 3m 35s\n",
      "174:\tlearn: 12099860.7475523\ttotal: 13.5s\tremaining: 3m 35s\n",
      "175:\tlearn: 12050397.6620205\ttotal: 13.5s\tremaining: 3m 35s\n",
      "176:\tlearn: 12035911.4761451\ttotal: 13.6s\tremaining: 3m 34s\n",
      "177:\tlearn: 12027189.8690195\ttotal: 13.7s\tremaining: 3m 34s\n",
      "178:\tlearn: 11994418.3834860\ttotal: 13.7s\tremaining: 3m 34s\n",
      "179:\tlearn: 11978263.9836391\ttotal: 13.8s\tremaining: 3m 34s\n",
      "180:\tlearn: 11965757.7962038\ttotal: 13.9s\tremaining: 3m 34s\n",
      "181:\tlearn: 11958569.5399914\ttotal: 14s\tremaining: 3m 34s\n",
      "182:\tlearn: 11925594.0817883\ttotal: 14.1s\tremaining: 3m 34s\n",
      "183:\tlearn: 11920020.2791212\ttotal: 14.1s\tremaining: 3m 34s\n",
      "184:\tlearn: 11905169.7105975\ttotal: 14.2s\tremaining: 3m 34s\n",
      "185:\tlearn: 11894599.4706557\ttotal: 14.3s\tremaining: 3m 34s\n",
      "186:\tlearn: 11882031.1708788\ttotal: 14.4s\tremaining: 3m 34s\n",
      "187:\tlearn: 11873067.3632644\ttotal: 14.4s\tremaining: 3m 33s\n",
      "188:\tlearn: 11835056.1120076\ttotal: 14.5s\tremaining: 3m 33s\n",
      "189:\tlearn: 11814618.2712135\ttotal: 14.6s\tremaining: 3m 33s\n",
      "190:\tlearn: 11794474.4968935\ttotal: 14.7s\tremaining: 3m 33s\n",
      "191:\tlearn: 11773429.2406998\ttotal: 14.7s\tremaining: 3m 33s\n",
      "192:\tlearn: 11761866.5788438\ttotal: 14.8s\tremaining: 3m 33s\n",
      "193:\tlearn: 11733415.6302538\ttotal: 14.9s\tremaining: 3m 33s\n",
      "194:\tlearn: 11717030.9394868\ttotal: 15s\tremaining: 3m 33s\n",
      "195:\tlearn: 11705172.7265639\ttotal: 15.1s\tremaining: 3m 33s\n",
      "196:\tlearn: 11680289.1919418\ttotal: 15.1s\tremaining: 3m 33s\n",
      "197:\tlearn: 11668366.3892013\ttotal: 15.2s\tremaining: 3m 33s\n",
      "198:\tlearn: 11661597.4580901\ttotal: 15.3s\tremaining: 3m 33s\n",
      "199:\tlearn: 11656360.9736146\ttotal: 15.4s\tremaining: 3m 33s\n",
      "200:\tlearn: 11627635.9380396\ttotal: 15.4s\tremaining: 3m 32s\n",
      "201:\tlearn: 11623707.7861647\ttotal: 15.5s\tremaining: 3m 32s\n",
      "202:\tlearn: 11611493.9761105\ttotal: 15.6s\tremaining: 3m 32s\n",
      "203:\tlearn: 11594436.7948007\ttotal: 15.6s\tremaining: 3m 32s\n",
      "204:\tlearn: 11570727.6641451\ttotal: 15.7s\tremaining: 3m 32s\n",
      "205:\tlearn: 11556768.2381007\ttotal: 15.8s\tremaining: 3m 32s\n",
      "206:\tlearn: 11543481.6268737\ttotal: 15.9s\tremaining: 3m 31s\n",
      "207:\tlearn: 11519033.8175713\ttotal: 15.9s\tremaining: 3m 31s\n",
      "208:\tlearn: 11513989.0463394\ttotal: 16s\tremaining: 3m 31s\n",
      "209:\tlearn: 11501425.5250067\ttotal: 16.1s\tremaining: 3m 31s\n",
      "210:\tlearn: 11485436.1520666\ttotal: 16.1s\tremaining: 3m 31s\n",
      "211:\tlearn: 11477998.3960814\ttotal: 16.2s\tremaining: 3m 31s\n",
      "212:\tlearn: 11473321.3817198\ttotal: 16.3s\tremaining: 3m 31s\n",
      "213:\tlearn: 11462648.7454513\ttotal: 16.4s\tremaining: 3m 31s\n",
      "214:\tlearn: 11458703.4788681\ttotal: 16.4s\tremaining: 3m 31s\n",
      "215:\tlearn: 11447820.2187796\ttotal: 16.5s\tremaining: 3m 30s\n",
      "216:\tlearn: 11419342.9000330\ttotal: 16.6s\tremaining: 3m 30s\n",
      "217:\tlearn: 11410451.1030853\ttotal: 16.7s\tremaining: 3m 30s\n",
      "218:\tlearn: 11399322.5343295\ttotal: 16.8s\tremaining: 3m 30s\n",
      "219:\tlearn: 11373072.7343764\ttotal: 16.8s\tremaining: 3m 30s\n",
      "220:\tlearn: 11351748.5163406\ttotal: 16.9s\tremaining: 3m 30s\n",
      "221:\tlearn: 11328827.5039131\ttotal: 17s\tremaining: 3m 30s\n",
      "222:\tlearn: 11319409.2727857\ttotal: 17.1s\tremaining: 3m 30s\n",
      "223:\tlearn: 11304666.6114128\ttotal: 17.1s\tremaining: 3m 30s\n",
      "224:\tlearn: 11294078.2890548\ttotal: 17.2s\tremaining: 3m 30s\n",
      "225:\tlearn: 11281202.3563337\ttotal: 17.3s\tremaining: 3m 30s\n",
      "226:\tlearn: 11275342.1632522\ttotal: 17.4s\tremaining: 3m 30s\n",
      "227:\tlearn: 11265467.7245349\ttotal: 17.4s\tremaining: 3m 29s\n",
      "228:\tlearn: 11252722.0886366\ttotal: 17.5s\tremaining: 3m 29s\n",
      "229:\tlearn: 11241392.7646414\ttotal: 17.6s\tremaining: 3m 29s\n",
      "230:\tlearn: 11228967.7034116\ttotal: 17.7s\tremaining: 3m 29s\n",
      "231:\tlearn: 11209777.6197998\ttotal: 17.8s\tremaining: 3m 30s\n",
      "232:\tlearn: 11203084.9047641\ttotal: 17.9s\tremaining: 3m 30s\n",
      "233:\tlearn: 11192990.2324406\ttotal: 18s\tremaining: 3m 30s\n",
      "234:\tlearn: 11185714.0653291\ttotal: 18.1s\tremaining: 3m 30s\n",
      "235:\tlearn: 11179511.9387072\ttotal: 18.2s\tremaining: 3m 30s\n",
      "236:\tlearn: 11166418.8794062\ttotal: 18.3s\tremaining: 3m 30s\n",
      "237:\tlearn: 11157167.6919855\ttotal: 18.3s\tremaining: 3m 30s\n",
      "238:\tlearn: 11149539.6401513\ttotal: 18.4s\tremaining: 3m 31s\n",
      "239:\tlearn: 11120542.5455323\ttotal: 18.5s\tremaining: 3m 31s\n",
      "240:\tlearn: 11101011.1142955\ttotal: 18.6s\tremaining: 3m 31s\n",
      "241:\tlearn: 11081272.2957505\ttotal: 18.7s\tremaining: 3m 31s\n",
      "242:\tlearn: 11069822.6653519\ttotal: 18.8s\tremaining: 3m 31s\n",
      "243:\tlearn: 11062776.9773668\ttotal: 18.9s\tremaining: 3m 32s\n",
      "244:\tlearn: 11037567.1784711\ttotal: 19.1s\tremaining: 3m 32s\n",
      "245:\tlearn: 11023534.6517533\ttotal: 19.2s\tremaining: 3m 32s\n",
      "246:\tlearn: 11010323.4896488\ttotal: 19.3s\tremaining: 3m 32s\n",
      "247:\tlearn: 11003648.4650681\ttotal: 19.3s\tremaining: 3m 32s\n",
      "248:\tlearn: 10995713.5550414\ttotal: 19.4s\tremaining: 3m 32s\n",
      "249:\tlearn: 10989467.2675374\ttotal: 19.5s\tremaining: 3m 32s\n",
      "250:\tlearn: 10963751.1623731\ttotal: 19.6s\tremaining: 3m 32s\n",
      "251:\tlearn: 10951181.3433359\ttotal: 19.7s\tremaining: 3m 32s\n",
      "252:\tlearn: 10946947.8626760\ttotal: 19.8s\tremaining: 3m 32s\n",
      "253:\tlearn: 10931306.1307583\ttotal: 19.9s\tremaining: 3m 32s\n",
      "254:\tlearn: 10922464.1502748\ttotal: 20s\tremaining: 3m 33s\n",
      "255:\tlearn: 10916348.4747575\ttotal: 20.1s\tremaining: 3m 33s\n",
      "256:\tlearn: 10902107.0471912\ttotal: 20.2s\tremaining: 3m 33s\n",
      "257:\tlearn: 10897734.5584912\ttotal: 20.3s\tremaining: 3m 33s\n",
      "258:\tlearn: 10890522.9271149\ttotal: 20.4s\tremaining: 3m 33s\n",
      "259:\tlearn: 10880395.0893614\ttotal: 20.4s\tremaining: 3m 33s\n",
      "260:\tlearn: 10866233.6326825\ttotal: 20.5s\tremaining: 3m 33s\n",
      "261:\tlearn: 10859216.6935781\ttotal: 20.6s\tremaining: 3m 33s\n",
      "262:\tlearn: 10848305.4497486\ttotal: 20.7s\tremaining: 3m 33s\n",
      "263:\tlearn: 10832206.2169680\ttotal: 20.8s\tremaining: 3m 33s\n",
      "264:\tlearn: 10826618.6204415\ttotal: 20.9s\tremaining: 3m 33s\n",
      "265:\tlearn: 10812823.9339482\ttotal: 21s\tremaining: 3m 33s\n",
      "266:\tlearn: 10799882.0963516\ttotal: 21.1s\tremaining: 3m 33s\n",
      "267:\tlearn: 10788037.5409467\ttotal: 21.2s\tremaining: 3m 33s\n",
      "268:\tlearn: 10773894.8779991\ttotal: 21.2s\tremaining: 3m 33s\n",
      "269:\tlearn: 10760317.2997008\ttotal: 21.3s\tremaining: 3m 33s\n",
      "270:\tlearn: 10753985.0765795\ttotal: 21.4s\tremaining: 3m 33s\n",
      "271:\tlearn: 10745507.2920098\ttotal: 21.5s\tremaining: 3m 33s\n",
      "272:\tlearn: 10733238.5107617\ttotal: 21.6s\tremaining: 3m 33s\n",
      "273:\tlearn: 10720631.1979625\ttotal: 21.7s\tremaining: 3m 33s\n",
      "274:\tlearn: 10711254.9103610\ttotal: 21.8s\tremaining: 3m 33s\n",
      "275:\tlearn: 10708083.1347901\ttotal: 21.9s\tremaining: 3m 33s\n",
      "276:\tlearn: 10696587.7299597\ttotal: 22s\tremaining: 3m 33s\n",
      "277:\tlearn: 10680315.4758883\ttotal: 22.1s\tremaining: 3m 33s\n",
      "278:\tlearn: 10671746.8293852\ttotal: 22.1s\tremaining: 3m 33s\n",
      "279:\tlearn: 10662282.4033088\ttotal: 22.2s\tremaining: 3m 33s\n",
      "280:\tlearn: 10651396.9613168\ttotal: 22.3s\tremaining: 3m 33s\n",
      "281:\tlearn: 10647114.8958960\ttotal: 22.4s\tremaining: 3m 33s\n",
      "282:\tlearn: 10636149.8589555\ttotal: 22.5s\tremaining: 3m 33s\n",
      "283:\tlearn: 10628010.4860510\ttotal: 22.6s\tremaining: 3m 33s\n",
      "284:\tlearn: 10615124.5946296\ttotal: 22.7s\tremaining: 3m 33s\n",
      "285:\tlearn: 10603639.1591568\ttotal: 22.8s\tremaining: 3m 33s\n",
      "286:\tlearn: 10580605.7303174\ttotal: 22.9s\tremaining: 3m 33s\n",
      "287:\tlearn: 10566735.7481202\ttotal: 22.9s\tremaining: 3m 34s\n",
      "288:\tlearn: 10559000.8091087\ttotal: 23s\tremaining: 3m 34s\n",
      "289:\tlearn: 10554697.2602184\ttotal: 23.1s\tremaining: 3m 34s\n",
      "290:\tlearn: 10548045.9501058\ttotal: 23.2s\tremaining: 3m 34s\n",
      "291:\tlearn: 10542973.5163672\ttotal: 23.3s\tremaining: 3m 34s\n",
      "292:\tlearn: 10530397.9176750\ttotal: 23.4s\tremaining: 3m 34s\n",
      "293:\tlearn: 10500864.8964715\ttotal: 23.5s\tremaining: 3m 33s\n",
      "294:\tlearn: 10487455.1262503\ttotal: 23.6s\tremaining: 3m 33s\n",
      "295:\tlearn: 10478052.2671363\ttotal: 23.6s\tremaining: 3m 33s\n",
      "296:\tlearn: 10470393.9176829\ttotal: 23.7s\tremaining: 3m 33s\n",
      "297:\tlearn: 10457569.3436287\ttotal: 23.8s\tremaining: 3m 34s\n",
      "298:\tlearn: 10442698.2496003\ttotal: 23.9s\tremaining: 3m 34s\n",
      "299:\tlearn: 10431496.1740015\ttotal: 24s\tremaining: 3m 33s\n",
      "300:\tlearn: 10402618.1176433\ttotal: 24.1s\tremaining: 3m 33s\n",
      "301:\tlearn: 10390033.7454030\ttotal: 24.2s\tremaining: 3m 34s\n",
      "302:\tlearn: 10382534.0426760\ttotal: 24.3s\tremaining: 3m 34s\n",
      "303:\tlearn: 10370869.5596704\ttotal: 24.4s\tremaining: 3m 34s\n",
      "304:\tlearn: 10363471.3487656\ttotal: 24.5s\tremaining: 3m 34s\n",
      "305:\tlearn: 10359320.5548439\ttotal: 24.6s\tremaining: 3m 34s\n",
      "306:\tlearn: 10346741.4527566\ttotal: 24.7s\tremaining: 3m 34s\n",
      "307:\tlearn: 10334365.9382609\ttotal: 24.7s\tremaining: 3m 34s\n",
      "308:\tlearn: 10332241.4898697\ttotal: 24.8s\tremaining: 3m 34s\n",
      "309:\tlearn: 10329024.5391165\ttotal: 24.9s\tremaining: 3m 34s\n",
      "310:\tlearn: 10318131.4761549\ttotal: 25s\tremaining: 3m 34s\n",
      "311:\tlearn: 10295100.7317197\ttotal: 25.1s\tremaining: 3m 34s\n",
      "312:\tlearn: 10283427.5363994\ttotal: 25.2s\tremaining: 3m 34s\n",
      "313:\tlearn: 10274281.8671560\ttotal: 25.3s\tremaining: 3m 34s\n",
      "314:\tlearn: 10255275.0613786\ttotal: 25.4s\tremaining: 3m 34s\n",
      "315:\tlearn: 10245635.9504000\ttotal: 25.5s\tremaining: 3m 34s\n",
      "316:\tlearn: 10236652.9477136\ttotal: 25.6s\tremaining: 3m 34s\n",
      "317:\tlearn: 10231990.1472730\ttotal: 25.6s\tremaining: 3m 34s\n",
      "318:\tlearn: 10221368.8334997\ttotal: 25.7s\tremaining: 3m 34s\n",
      "319:\tlearn: 10211107.0971084\ttotal: 25.8s\tremaining: 3m 34s\n",
      "320:\tlearn: 10201067.1636767\ttotal: 25.9s\tremaining: 3m 34s\n",
      "321:\tlearn: 10191828.4352467\ttotal: 26s\tremaining: 3m 34s\n",
      "322:\tlearn: 10185715.1894758\ttotal: 26.1s\tremaining: 3m 34s\n",
      "323:\tlearn: 10175834.1416553\ttotal: 26.2s\tremaining: 3m 34s\n",
      "324:\tlearn: 10161933.3456645\ttotal: 26.3s\tremaining: 3m 34s\n",
      "325:\tlearn: 10152081.1372721\ttotal: 26.4s\tremaining: 3m 34s\n",
      "326:\tlearn: 10146938.6797305\ttotal: 26.5s\tremaining: 3m 34s\n",
      "327:\tlearn: 10135610.8278418\ttotal: 26.6s\tremaining: 3m 34s\n",
      "328:\tlearn: 10130771.9149948\ttotal: 26.6s\tremaining: 3m 34s\n",
      "329:\tlearn: 10117282.4898797\ttotal: 26.7s\tremaining: 3m 34s\n",
      "330:\tlearn: 10107072.3399144\ttotal: 26.8s\tremaining: 3m 34s\n",
      "331:\tlearn: 10098926.3963842\ttotal: 26.9s\tremaining: 3m 34s\n",
      "332:\tlearn: 10092716.6314923\ttotal: 27s\tremaining: 3m 34s\n",
      "333:\tlearn: 10088400.4267822\ttotal: 27.1s\tremaining: 3m 34s\n",
      "334:\tlearn: 10075276.5350461\ttotal: 27.2s\tremaining: 3m 34s\n",
      "335:\tlearn: 10070764.8181297\ttotal: 27.3s\tremaining: 3m 34s\n",
      "336:\tlearn: 10056829.3699122\ttotal: 27.4s\tremaining: 3m 34s\n",
      "337:\tlearn: 10043396.9450466\ttotal: 27.4s\tremaining: 3m 34s\n",
      "338:\tlearn: 10023071.0730734\ttotal: 27.5s\tremaining: 3m 34s\n",
      "339:\tlearn: 10013560.8689599\ttotal: 27.6s\tremaining: 3m 33s\n",
      "340:\tlearn: 10007875.8953435\ttotal: 27.7s\tremaining: 3m 33s\n",
      "341:\tlearn: 10003596.9714343\ttotal: 27.8s\tremaining: 3m 34s\n",
      "342:\tlearn: 9999590.7071745\ttotal: 27.9s\tremaining: 3m 34s\n",
      "343:\tlearn: 9992033.9210041\ttotal: 28s\tremaining: 3m 33s\n",
      "344:\tlearn: 9981330.4250570\ttotal: 28.1s\tremaining: 3m 34s\n",
      "345:\tlearn: 9973027.0164246\ttotal: 28.2s\tremaining: 3m 34s\n",
      "346:\tlearn: 9961755.2649016\ttotal: 28.3s\tremaining: 3m 34s\n",
      "347:\tlearn: 9955759.8831512\ttotal: 28.4s\tremaining: 3m 33s\n",
      "348:\tlearn: 9949041.2538622\ttotal: 28.4s\tremaining: 3m 33s\n",
      "349:\tlearn: 9939619.3339200\ttotal: 28.5s\tremaining: 3m 33s\n",
      "350:\tlearn: 9920665.2394472\ttotal: 28.6s\tremaining: 3m 33s\n",
      "351:\tlearn: 9910707.6310813\ttotal: 28.7s\tremaining: 3m 33s\n",
      "352:\tlearn: 9905700.6640092\ttotal: 28.8s\tremaining: 3m 33s\n",
      "353:\tlearn: 9902893.2583512\ttotal: 28.9s\tremaining: 3m 33s\n",
      "354:\tlearn: 9895195.7913450\ttotal: 29s\tremaining: 3m 33s\n",
      "355:\tlearn: 9888931.0269348\ttotal: 29.1s\tremaining: 3m 33s\n",
      "356:\tlearn: 9883289.7571615\ttotal: 29.2s\tremaining: 3m 33s\n",
      "357:\tlearn: 9870402.1441576\ttotal: 29.2s\tremaining: 3m 33s\n",
      "358:\tlearn: 9859643.3033027\ttotal: 29.3s\tremaining: 3m 33s\n",
      "359:\tlearn: 9854494.5358564\ttotal: 29.4s\tremaining: 3m 33s\n",
      "360:\tlearn: 9843600.2236550\ttotal: 29.5s\tremaining: 3m 33s\n",
      "361:\tlearn: 9835861.8637099\ttotal: 29.6s\tremaining: 3m 33s\n",
      "362:\tlearn: 9822687.5147231\ttotal: 29.7s\tremaining: 3m 33s\n",
      "363:\tlearn: 9812206.0580232\ttotal: 29.8s\tremaining: 3m 33s\n",
      "364:\tlearn: 9806151.2921118\ttotal: 29.9s\tremaining: 3m 33s\n",
      "365:\tlearn: 9801189.0997569\ttotal: 29.9s\tremaining: 3m 33s\n",
      "366:\tlearn: 9792148.4409177\ttotal: 30s\tremaining: 3m 33s\n",
      "367:\tlearn: 9781760.3775775\ttotal: 30.1s\tremaining: 3m 33s\n",
      "368:\tlearn: 9771423.9859458\ttotal: 30.2s\tremaining: 3m 33s\n",
      "369:\tlearn: 9760313.2672740\ttotal: 30.3s\tremaining: 3m 33s\n",
      "370:\tlearn: 9755495.0305661\ttotal: 30.4s\tremaining: 3m 33s\n",
      "371:\tlearn: 9750988.5841769\ttotal: 30.5s\tremaining: 3m 33s\n",
      "372:\tlearn: 9738146.9238444\ttotal: 30.6s\tremaining: 3m 33s\n",
      "373:\tlearn: 9726309.9729312\ttotal: 30.6s\tremaining: 3m 32s\n",
      "374:\tlearn: 9717842.1636712\ttotal: 30.7s\tremaining: 3m 32s\n",
      "375:\tlearn: 9703380.9291352\ttotal: 30.8s\tremaining: 3m 32s\n",
      "376:\tlearn: 9696782.9487761\ttotal: 30.9s\tremaining: 3m 32s\n",
      "377:\tlearn: 9687140.1650990\ttotal: 31s\tremaining: 3m 32s\n",
      "378:\tlearn: 9683714.7595817\ttotal: 31.1s\tremaining: 3m 32s\n",
      "379:\tlearn: 9675710.9996580\ttotal: 31.2s\tremaining: 3m 32s\n",
      "380:\tlearn: 9671993.2693349\ttotal: 31.3s\tremaining: 3m 32s\n",
      "381:\tlearn: 9668453.2086542\ttotal: 31.4s\tremaining: 3m 32s\n",
      "382:\tlearn: 9657958.5307019\ttotal: 31.4s\tremaining: 3m 32s\n",
      "383:\tlearn: 9652999.6608282\ttotal: 31.5s\tremaining: 3m 32s\n",
      "384:\tlearn: 9648092.0530350\ttotal: 31.6s\tremaining: 3m 32s\n",
      "385:\tlearn: 9645996.8788175\ttotal: 31.7s\tremaining: 3m 32s\n",
      "386:\tlearn: 9637654.2719768\ttotal: 31.8s\tremaining: 3m 32s\n",
      "387:\tlearn: 9632232.2095173\ttotal: 31.9s\tremaining: 3m 32s\n",
      "388:\tlearn: 9628007.6559595\ttotal: 32s\tremaining: 3m 32s\n",
      "389:\tlearn: 9608293.4484161\ttotal: 32.1s\tremaining: 3m 32s\n",
      "390:\tlearn: 9604760.3048724\ttotal: 32.2s\tremaining: 3m 32s\n",
      "391:\tlearn: 9597594.2908193\ttotal: 32.3s\tremaining: 3m 32s\n",
      "392:\tlearn: 9580390.4273446\ttotal: 32.4s\tremaining: 3m 32s\n",
      "393:\tlearn: 9577036.5553112\ttotal: 32.5s\tremaining: 3m 32s\n",
      "394:\tlearn: 9564553.1854694\ttotal: 32.5s\tremaining: 3m 32s\n",
      "395:\tlearn: 9555660.8849762\ttotal: 32.6s\tremaining: 3m 32s\n",
      "396:\tlearn: 9544058.0393865\ttotal: 32.7s\tremaining: 3m 32s\n",
      "397:\tlearn: 9537757.4641404\ttotal: 32.8s\tremaining: 3m 32s\n",
      "398:\tlearn: 9530908.7565330\ttotal: 32.9s\tremaining: 3m 32s\n",
      "399:\tlearn: 9523055.3095072\ttotal: 33s\tremaining: 3m 32s\n",
      "400:\tlearn: 9506684.8671863\ttotal: 33.1s\tremaining: 3m 32s\n",
      "401:\tlearn: 9498865.4598198\ttotal: 33.2s\tremaining: 3m 32s\n",
      "402:\tlearn: 9489810.4092197\ttotal: 33.3s\tremaining: 3m 32s\n",
      "403:\tlearn: 9484038.7013194\ttotal: 33.3s\tremaining: 3m 32s\n",
      "404:\tlearn: 9474585.3884135\ttotal: 33.4s\tremaining: 3m 32s\n",
      "405:\tlearn: 9464094.2092704\ttotal: 33.5s\tremaining: 3m 31s\n",
      "406:\tlearn: 9460927.1451947\ttotal: 33.6s\tremaining: 3m 31s\n",
      "407:\tlearn: 9453604.0632207\ttotal: 33.7s\tremaining: 3m 31s\n",
      "408:\tlearn: 9449461.0717063\ttotal: 33.8s\tremaining: 3m 31s\n",
      "409:\tlearn: 9444801.5350974\ttotal: 33.9s\tremaining: 3m 31s\n",
      "410:\tlearn: 9438603.7741070\ttotal: 34s\tremaining: 3m 31s\n",
      "411:\tlearn: 9434748.7171600\ttotal: 34.1s\tremaining: 3m 31s\n",
      "412:\tlearn: 9428608.5467623\ttotal: 34.1s\tremaining: 3m 31s\n",
      "413:\tlearn: 9410999.6848100\ttotal: 34.2s\tremaining: 3m 31s\n",
      "414:\tlearn: 9406255.0684216\ttotal: 34.3s\tremaining: 3m 31s\n",
      "415:\tlearn: 9391498.1639093\ttotal: 34.4s\tremaining: 3m 31s\n",
      "416:\tlearn: 9379338.4584012\ttotal: 34.5s\tremaining: 3m 31s\n",
      "417:\tlearn: 9371147.8026148\ttotal: 34.6s\tremaining: 3m 31s\n",
      "418:\tlearn: 9361498.9736462\ttotal: 34.6s\tremaining: 3m 31s\n",
      "419:\tlearn: 9350829.7160161\ttotal: 34.7s\tremaining: 3m 31s\n",
      "420:\tlearn: 9343898.0270260\ttotal: 34.8s\tremaining: 3m 31s\n",
      "421:\tlearn: 9336247.5346676\ttotal: 34.9s\tremaining: 3m 31s\n",
      "422:\tlearn: 9330140.9856863\ttotal: 35s\tremaining: 3m 31s\n",
      "423:\tlearn: 9328431.4316190\ttotal: 35.1s\tremaining: 3m 31s\n",
      "424:\tlearn: 9322275.1732270\ttotal: 35.2s\tremaining: 3m 30s\n",
      "425:\tlearn: 9305220.5016295\ttotal: 35.3s\tremaining: 3m 30s\n",
      "426:\tlearn: 9296443.7175861\ttotal: 35.4s\tremaining: 3m 30s\n",
      "427:\tlearn: 9293583.5857065\ttotal: 35.4s\tremaining: 3m 30s\n",
      "428:\tlearn: 9284637.1206659\ttotal: 35.5s\tremaining: 3m 30s\n",
      "429:\tlearn: 9280425.2701854\ttotal: 35.6s\tremaining: 3m 30s\n",
      "430:\tlearn: 9272636.0417675\ttotal: 35.7s\tremaining: 3m 30s\n",
      "431:\tlearn: 9232912.8893464\ttotal: 35.8s\tremaining: 3m 30s\n",
      "432:\tlearn: 9226007.0153681\ttotal: 35.9s\tremaining: 3m 30s\n",
      "433:\tlearn: 9214572.3168002\ttotal: 36s\tremaining: 3m 30s\n",
      "434:\tlearn: 9204968.0681440\ttotal: 36.1s\tremaining: 3m 30s\n",
      "435:\tlearn: 9202943.2320645\ttotal: 36.1s\tremaining: 3m 30s\n",
      "436:\tlearn: 9195551.2102952\ttotal: 36.2s\tremaining: 3m 30s\n",
      "437:\tlearn: 9189291.1373621\ttotal: 36.3s\tremaining: 3m 30s\n",
      "438:\tlearn: 9186483.8648970\ttotal: 36.4s\tremaining: 3m 30s\n",
      "439:\tlearn: 9183317.0547214\ttotal: 36.5s\tremaining: 3m 30s\n",
      "440:\tlearn: 9178460.1826894\ttotal: 36.6s\tremaining: 3m 30s\n",
      "441:\tlearn: 9174356.4374447\ttotal: 36.7s\tremaining: 3m 30s\n",
      "442:\tlearn: 9163045.3272384\ttotal: 36.8s\tremaining: 3m 30s\n",
      "443:\tlearn: 9156681.8325896\ttotal: 36.9s\tremaining: 3m 30s\n",
      "444:\tlearn: 9149152.6832776\ttotal: 37s\tremaining: 3m 30s\n",
      "445:\tlearn: 9146732.8803576\ttotal: 37s\tremaining: 3m 29s\n",
      "446:\tlearn: 9129379.0765326\ttotal: 37.1s\tremaining: 3m 29s\n",
      "447:\tlearn: 9121447.1711742\ttotal: 37.2s\tremaining: 3m 29s\n",
      "448:\tlearn: 9118506.6548200\ttotal: 37.3s\tremaining: 3m 29s\n",
      "449:\tlearn: 9113812.2184408\ttotal: 37.4s\tremaining: 3m 29s\n",
      "450:\tlearn: 9110933.4604362\ttotal: 37.5s\tremaining: 3m 29s\n",
      "451:\tlearn: 9102739.8657975\ttotal: 37.6s\tremaining: 3m 29s\n",
      "452:\tlearn: 9098737.2938255\ttotal: 37.7s\tremaining: 3m 29s\n",
      "453:\tlearn: 9089287.5444517\ttotal: 37.8s\tremaining: 3m 29s\n",
      "454:\tlearn: 9085237.5139472\ttotal: 37.9s\tremaining: 3m 29s\n",
      "455:\tlearn: 9076547.2809075\ttotal: 37.9s\tremaining: 3m 29s\n",
      "456:\tlearn: 9069370.9720550\ttotal: 38s\tremaining: 3m 29s\n",
      "457:\tlearn: 9052481.4954627\ttotal: 38.1s\tremaining: 3m 29s\n",
      "458:\tlearn: 9045573.9081241\ttotal: 38.2s\tremaining: 3m 29s\n",
      "459:\tlearn: 9039827.8712088\ttotal: 38.3s\tremaining: 3m 29s\n",
      "460:\tlearn: 9037386.1486219\ttotal: 38.4s\tremaining: 3m 29s\n",
      "461:\tlearn: 9028873.8673379\ttotal: 38.5s\tremaining: 3m 29s\n",
      "462:\tlearn: 9025269.3295327\ttotal: 38.5s\tremaining: 3m 29s\n",
      "463:\tlearn: 9018997.7174726\ttotal: 38.6s\tremaining: 3m 28s\n",
      "464:\tlearn: 9017511.6932249\ttotal: 38.7s\tremaining: 3m 28s\n",
      "465:\tlearn: 9013962.6600772\ttotal: 38.8s\tremaining: 3m 28s\n",
      "466:\tlearn: 9006384.7913801\ttotal: 38.9s\tremaining: 3m 28s\n",
      "467:\tlearn: 8996194.5198740\ttotal: 39s\tremaining: 3m 28s\n",
      "468:\tlearn: 8988534.4730361\ttotal: 39.1s\tremaining: 3m 28s\n",
      "469:\tlearn: 8985563.4721010\ttotal: 39.2s\tremaining: 3m 28s\n",
      "470:\tlearn: 8980870.4918216\ttotal: 39.3s\tremaining: 3m 28s\n",
      "471:\tlearn: 8978369.2666371\ttotal: 39.3s\tremaining: 3m 28s\n",
      "472:\tlearn: 8973474.1657295\ttotal: 39.4s\tremaining: 3m 28s\n",
      "473:\tlearn: 8968974.9145689\ttotal: 39.5s\tremaining: 3m 28s\n",
      "474:\tlearn: 8965979.6693114\ttotal: 39.6s\tremaining: 3m 28s\n",
      "475:\tlearn: 8963814.6677321\ttotal: 39.7s\tremaining: 3m 28s\n",
      "476:\tlearn: 8954368.2923228\ttotal: 39.8s\tremaining: 3m 28s\n",
      "477:\tlearn: 8951480.1611747\ttotal: 39.9s\tremaining: 3m 28s\n",
      "478:\tlearn: 8946118.8162090\ttotal: 40s\tremaining: 3m 28s\n",
      "479:\tlearn: 8930892.8534131\ttotal: 40s\tremaining: 3m 28s\n",
      "480:\tlearn: 8927146.0677256\ttotal: 40.1s\tremaining: 3m 28s\n",
      "481:\tlearn: 8924074.5155921\ttotal: 40.2s\tremaining: 3m 27s\n",
      "482:\tlearn: 8918134.8861019\ttotal: 40.3s\tremaining: 3m 27s\n",
      "483:\tlearn: 8907057.4807695\ttotal: 40.4s\tremaining: 3m 27s\n",
      "484:\tlearn: 8904870.9552628\ttotal: 40.5s\tremaining: 3m 27s\n",
      "485:\tlearn: 8901586.1448413\ttotal: 40.6s\tremaining: 3m 27s\n",
      "486:\tlearn: 8897914.3121392\ttotal: 40.7s\tremaining: 3m 27s\n",
      "487:\tlearn: 8888582.4342917\ttotal: 40.7s\tremaining: 3m 27s\n",
      "488:\tlearn: 8880971.6463138\ttotal: 40.8s\tremaining: 3m 27s\n",
      "489:\tlearn: 8876824.7102608\ttotal: 40.9s\tremaining: 3m 27s\n",
      "490:\tlearn: 8861833.0292793\ttotal: 41s\tremaining: 3m 27s\n",
      "491:\tlearn: 8857673.0348804\ttotal: 41.1s\tremaining: 3m 27s\n",
      "492:\tlearn: 8853662.7273688\ttotal: 41.2s\tremaining: 3m 27s\n",
      "493:\tlearn: 8850116.5818346\ttotal: 41.3s\tremaining: 3m 27s\n",
      "494:\tlearn: 8847138.4707248\ttotal: 41.4s\tremaining: 3m 27s\n",
      "495:\tlearn: 8836309.8779322\ttotal: 41.4s\tremaining: 3m 27s\n",
      "496:\tlearn: 8821178.3832854\ttotal: 41.5s\tremaining: 3m 26s\n",
      "497:\tlearn: 8815665.1276332\ttotal: 41.6s\tremaining: 3m 26s\n",
      "498:\tlearn: 8801373.7370442\ttotal: 41.7s\tremaining: 3m 26s\n",
      "499:\tlearn: 8796389.3394136\ttotal: 41.8s\tremaining: 3m 26s\n",
      "500:\tlearn: 8789109.3959302\ttotal: 41.9s\tremaining: 3m 26s\n",
      "501:\tlearn: 8786044.2966182\ttotal: 42s\tremaining: 3m 26s\n",
      "502:\tlearn: 8778959.8562011\ttotal: 42.1s\tremaining: 3m 26s\n",
      "503:\tlearn: 8775435.3784944\ttotal: 42.2s\tremaining: 3m 26s\n",
      "504:\tlearn: 8769423.6638428\ttotal: 42.2s\tremaining: 3m 26s\n",
      "505:\tlearn: 8768101.6065059\ttotal: 42.3s\tremaining: 3m 26s\n",
      "506:\tlearn: 8759728.7621731\ttotal: 42.4s\tremaining: 3m 26s\n",
      "507:\tlearn: 8757065.4154501\ttotal: 42.5s\tremaining: 3m 26s\n",
      "508:\tlearn: 8751501.5445607\ttotal: 42.6s\tremaining: 3m 26s\n",
      "509:\tlearn: 8748674.5301789\ttotal: 42.7s\tremaining: 3m 26s\n",
      "510:\tlearn: 8745187.6126383\ttotal: 42.8s\tremaining: 3m 26s\n",
      "511:\tlearn: 8742162.5967501\ttotal: 42.9s\tremaining: 3m 26s\n",
      "512:\tlearn: 8703166.2766040\ttotal: 42.9s\tremaining: 3m 26s\n",
      "513:\tlearn: 8701315.6681461\ttotal: 43s\tremaining: 3m 25s\n",
      "514:\tlearn: 8698542.9213516\ttotal: 43.1s\tremaining: 3m 25s\n",
      "515:\tlearn: 8696889.1400822\ttotal: 43.2s\tremaining: 3m 25s\n",
      "516:\tlearn: 8694014.3812022\ttotal: 43.3s\tremaining: 3m 25s\n",
      "517:\tlearn: 8688484.2853051\ttotal: 43.4s\tremaining: 3m 25s\n",
      "518:\tlearn: 8683411.7521404\ttotal: 43.5s\tremaining: 3m 25s\n",
      "519:\tlearn: 8678272.2264283\ttotal: 43.5s\tremaining: 3m 25s\n",
      "520:\tlearn: 8671780.6704379\ttotal: 43.6s\tremaining: 3m 25s\n",
      "521:\tlearn: 8662859.9520469\ttotal: 43.7s\tremaining: 3m 25s\n",
      "522:\tlearn: 8659390.1183713\ttotal: 43.8s\tremaining: 3m 25s\n",
      "523:\tlearn: 8641586.6391762\ttotal: 43.9s\tremaining: 3m 25s\n",
      "524:\tlearn: 8636630.4690722\ttotal: 44s\tremaining: 3m 25s\n",
      "525:\tlearn: 8621529.0276950\ttotal: 44.1s\tremaining: 3m 25s\n",
      "526:\tlearn: 8613522.0923211\ttotal: 44.2s\tremaining: 3m 25s\n",
      "527:\tlearn: 8610894.2724020\ttotal: 44.2s\tremaining: 3m 24s\n",
      "528:\tlearn: 8606408.3575770\ttotal: 44.3s\tremaining: 3m 24s\n",
      "529:\tlearn: 8599274.6003446\ttotal: 44.4s\tremaining: 3m 24s\n",
      "530:\tlearn: 8597187.2962454\ttotal: 44.5s\tremaining: 3m 24s\n",
      "531:\tlearn: 8594467.3495352\ttotal: 44.6s\tremaining: 3m 24s\n",
      "532:\tlearn: 8588182.3981195\ttotal: 44.7s\tremaining: 3m 24s\n",
      "533:\tlearn: 8583672.3427079\ttotal: 44.8s\tremaining: 3m 24s\n",
      "534:\tlearn: 8580271.6546125\ttotal: 44.9s\tremaining: 3m 24s\n",
      "535:\tlearn: 8573017.3053375\ttotal: 45s\tremaining: 3m 24s\n",
      "536:\tlearn: 8569819.3109451\ttotal: 45s\tremaining: 3m 24s\n",
      "537:\tlearn: 8541383.4409941\ttotal: 45.1s\tremaining: 3m 24s\n",
      "538:\tlearn: 8537007.3402334\ttotal: 45.2s\tremaining: 3m 24s\n",
      "539:\tlearn: 8524367.3349029\ttotal: 45.3s\tremaining: 3m 24s\n",
      "540:\tlearn: 8522655.3043058\ttotal: 45.4s\tremaining: 3m 24s\n",
      "541:\tlearn: 8514806.6236237\ttotal: 45.5s\tremaining: 3m 24s\n",
      "542:\tlearn: 8511681.4516273\ttotal: 45.6s\tremaining: 3m 23s\n",
      "543:\tlearn: 8506055.5369201\ttotal: 45.6s\tremaining: 3m 23s\n",
      "544:\tlearn: 8500406.9605517\ttotal: 45.7s\tremaining: 3m 23s\n",
      "545:\tlearn: 8497871.5674238\ttotal: 45.8s\tremaining: 3m 23s\n",
      "546:\tlearn: 8495214.1995441\ttotal: 45.9s\tremaining: 3m 23s\n",
      "547:\tlearn: 8479211.2029892\ttotal: 46s\tremaining: 3m 23s\n",
      "548:\tlearn: 8473680.5714108\ttotal: 46.1s\tremaining: 3m 23s\n",
      "549:\tlearn: 8470848.6574471\ttotal: 46.2s\tremaining: 3m 23s\n",
      "550:\tlearn: 8468243.1408922\ttotal: 46.2s\tremaining: 3m 23s\n",
      "551:\tlearn: 8461654.1339438\ttotal: 46.3s\tremaining: 3m 23s\n",
      "552:\tlearn: 8460225.1222878\ttotal: 46.4s\tremaining: 3m 23s\n",
      "553:\tlearn: 8452473.0897192\ttotal: 46.5s\tremaining: 3m 23s\n",
      "554:\tlearn: 8449961.1359102\ttotal: 46.6s\tremaining: 3m 23s\n",
      "555:\tlearn: 8445031.4715368\ttotal: 46.7s\tremaining: 3m 23s\n",
      "556:\tlearn: 8441000.1413957\ttotal: 46.8s\tremaining: 3m 23s\n",
      "557:\tlearn: 8427685.9985355\ttotal: 46.9s\tremaining: 3m 22s\n",
      "558:\tlearn: 8413915.0672666\ttotal: 47s\tremaining: 3m 22s\n",
      "559:\tlearn: 8411446.7874591\ttotal: 47s\tremaining: 3m 22s\n",
      "560:\tlearn: 8407942.1553009\ttotal: 47.1s\tremaining: 3m 22s\n",
      "561:\tlearn: 8401323.8936402\ttotal: 47.2s\tremaining: 3m 22s\n",
      "562:\tlearn: 8398129.5715496\ttotal: 47.3s\tremaining: 3m 22s\n",
      "563:\tlearn: 8387156.0214574\ttotal: 47.4s\tremaining: 3m 22s\n",
      "564:\tlearn: 8383045.9198259\ttotal: 47.5s\tremaining: 3m 22s\n",
      "565:\tlearn: 8374174.8742303\ttotal: 47.6s\tremaining: 3m 22s\n",
      "566:\tlearn: 8371499.9614617\ttotal: 47.6s\tremaining: 3m 22s\n",
      "567:\tlearn: 8355444.0227387\ttotal: 47.7s\tremaining: 3m 22s\n",
      "568:\tlearn: 8353363.0052958\ttotal: 47.8s\tremaining: 3m 22s\n",
      "569:\tlearn: 8347797.5515183\ttotal: 47.9s\tremaining: 3m 22s\n",
      "570:\tlearn: 8334058.9026611\ttotal: 48s\tremaining: 3m 22s\n",
      "571:\tlearn: 8332049.8498800\ttotal: 48.1s\tremaining: 3m 21s\n",
      "572:\tlearn: 8326347.0052137\ttotal: 48.2s\tremaining: 3m 21s\n",
      "573:\tlearn: 8319706.5209858\ttotal: 48.3s\tremaining: 3m 21s\n",
      "574:\tlearn: 8313474.7314127\ttotal: 48.3s\tremaining: 3m 21s\n",
      "575:\tlearn: 8310104.8033735\ttotal: 48.4s\tremaining: 3m 21s\n",
      "576:\tlearn: 8307572.6401646\ttotal: 48.5s\tremaining: 3m 21s\n",
      "577:\tlearn: 8305296.5252817\ttotal: 48.6s\tremaining: 3m 21s\n",
      "578:\tlearn: 8294876.7462151\ttotal: 48.7s\tremaining: 3m 21s\n",
      "579:\tlearn: 8290422.6965290\ttotal: 48.8s\tremaining: 3m 21s\n",
      "580:\tlearn: 8280332.4298332\ttotal: 48.9s\tremaining: 3m 21s\n",
      "581:\tlearn: 8271589.2599208\ttotal: 49s\tremaining: 3m 21s\n",
      "582:\tlearn: 8268743.2881930\ttotal: 49.1s\tremaining: 3m 21s\n",
      "583:\tlearn: 8266783.5715915\ttotal: 49.1s\tremaining: 3m 21s\n",
      "584:\tlearn: 8258708.2055855\ttotal: 49.2s\tremaining: 3m 21s\n",
      "585:\tlearn: 8253256.9320205\ttotal: 49.3s\tremaining: 3m 21s\n",
      "586:\tlearn: 8250437.9668275\ttotal: 49.4s\tremaining: 3m 20s\n",
      "587:\tlearn: 8241983.6720144\ttotal: 49.5s\tremaining: 3m 20s\n",
      "588:\tlearn: 8236819.8217228\ttotal: 49.6s\tremaining: 3m 20s\n",
      "589:\tlearn: 8229779.1508812\ttotal: 49.7s\tremaining: 3m 20s\n",
      "590:\tlearn: 8227344.6783798\ttotal: 49.8s\tremaining: 3m 20s\n",
      "591:\tlearn: 8223459.0576762\ttotal: 49.9s\tremaining: 3m 20s\n",
      "592:\tlearn: 8218241.6273600\ttotal: 50s\tremaining: 3m 20s\n",
      "593:\tlearn: 8214802.0575157\ttotal: 50.1s\tremaining: 3m 20s\n",
      "594:\tlearn: 8212138.2025874\ttotal: 50.2s\tremaining: 3m 20s\n",
      "595:\tlearn: 8200187.2657193\ttotal: 50.2s\tremaining: 3m 20s\n",
      "596:\tlearn: 8196571.9090572\ttotal: 50.3s\tremaining: 3m 20s\n",
      "597:\tlearn: 8188461.5986487\ttotal: 50.4s\tremaining: 3m 20s\n",
      "598:\tlearn: 8187523.9216891\ttotal: 50.5s\tremaining: 3m 20s\n",
      "599:\tlearn: 8183544.8489955\ttotal: 50.6s\tremaining: 3m 20s\n",
      "600:\tlearn: 8182230.8514021\ttotal: 50.7s\tremaining: 3m 20s\n",
      "601:\tlearn: 8180318.3743016\ttotal: 50.8s\tremaining: 3m 19s\n",
      "602:\tlearn: 8176952.5580832\ttotal: 50.8s\tremaining: 3m 19s\n",
      "603:\tlearn: 8174568.7635853\ttotal: 50.9s\tremaining: 3m 19s\n",
      "604:\tlearn: 8170117.3051655\ttotal: 51s\tremaining: 3m 19s\n",
      "605:\tlearn: 8165308.7758585\ttotal: 51.1s\tremaining: 3m 19s\n",
      "606:\tlearn: 8161352.1336719\ttotal: 51.2s\tremaining: 3m 19s\n",
      "607:\tlearn: 8157052.8491195\ttotal: 51.3s\tremaining: 3m 19s\n",
      "608:\tlearn: 8121538.4258473\ttotal: 51.4s\tremaining: 3m 19s\n",
      "609:\tlearn: 8113734.7158556\ttotal: 51.5s\tremaining: 3m 19s\n",
      "610:\tlearn: 8109717.5270313\ttotal: 51.5s\tremaining: 3m 19s\n",
      "611:\tlearn: 8098421.6430630\ttotal: 51.6s\tremaining: 3m 19s\n",
      "612:\tlearn: 8095408.5044819\ttotal: 51.7s\tremaining: 3m 19s\n",
      "613:\tlearn: 8082526.9260783\ttotal: 51.8s\tremaining: 3m 19s\n",
      "614:\tlearn: 8078693.4392351\ttotal: 51.9s\tremaining: 3m 19s\n",
      "615:\tlearn: 8076551.3545414\ttotal: 52s\tremaining: 3m 19s\n",
      "616:\tlearn: 8073554.1473194\ttotal: 52.1s\tremaining: 3m 19s\n",
      "617:\tlearn: 8071531.5703591\ttotal: 52.2s\tremaining: 3m 18s\n",
      "618:\tlearn: 8061283.6486168\ttotal: 52.3s\tremaining: 3m 18s\n",
      "619:\tlearn: 8060334.1444490\ttotal: 52.4s\tremaining: 3m 18s\n",
      "620:\tlearn: 8048333.1598738\ttotal: 52.5s\tremaining: 3m 18s\n",
      "621:\tlearn: 8044505.4273231\ttotal: 52.5s\tremaining: 3m 18s\n",
      "622:\tlearn: 8042549.3869752\ttotal: 52.6s\tremaining: 3m 18s\n",
      "623:\tlearn: 8039332.1519674\ttotal: 52.7s\tremaining: 3m 18s\n",
      "624:\tlearn: 8032119.2174851\ttotal: 52.8s\tremaining: 3m 18s\n",
      "625:\tlearn: 8024353.7881844\ttotal: 52.9s\tremaining: 3m 18s\n",
      "626:\tlearn: 8019790.4114564\ttotal: 53s\tremaining: 3m 18s\n",
      "627:\tlearn: 8014678.0817899\ttotal: 53.1s\tremaining: 3m 18s\n",
      "628:\tlearn: 8009318.4745913\ttotal: 53.2s\tremaining: 3m 18s\n",
      "629:\tlearn: 8005368.3569578\ttotal: 53.3s\tremaining: 3m 18s\n",
      "630:\tlearn: 8004048.0582613\ttotal: 53.3s\tremaining: 3m 18s\n",
      "631:\tlearn: 7998973.2295405\ttotal: 53.4s\tremaining: 3m 18s\n",
      "632:\tlearn: 7992411.2817603\ttotal: 53.5s\tremaining: 3m 17s\n",
      "633:\tlearn: 7987134.3372787\ttotal: 53.6s\tremaining: 3m 17s\n",
      "634:\tlearn: 7985552.6105974\ttotal: 53.7s\tremaining: 3m 17s\n",
      "635:\tlearn: 7981544.5162787\ttotal: 53.8s\tremaining: 3m 17s\n",
      "636:\tlearn: 7980112.8384809\ttotal: 53.9s\tremaining: 3m 17s\n",
      "637:\tlearn: 7977303.7837005\ttotal: 54s\tremaining: 3m 17s\n",
      "638:\tlearn: 7950814.6818683\ttotal: 54.1s\tremaining: 3m 17s\n",
      "639:\tlearn: 7941825.6234763\ttotal: 54.2s\tremaining: 3m 17s\n",
      "640:\tlearn: 7937454.4730904\ttotal: 54.3s\tremaining: 3m 17s\n",
      "641:\tlearn: 7933943.1521062\ttotal: 54.4s\tremaining: 3m 17s\n",
      "642:\tlearn: 7931771.0938967\ttotal: 54.4s\tremaining: 3m 17s\n",
      "643:\tlearn: 7925861.7947324\ttotal: 54.5s\tremaining: 3m 17s\n",
      "644:\tlearn: 7920834.6442193\ttotal: 54.6s\tremaining: 3m 17s\n",
      "645:\tlearn: 7918379.3082908\ttotal: 54.7s\tremaining: 3m 17s\n",
      "646:\tlearn: 7911377.7748615\ttotal: 54.8s\tremaining: 3m 17s\n",
      "647:\tlearn: 7909952.6728670\ttotal: 54.9s\tremaining: 3m 17s\n",
      "648:\tlearn: 7885496.8605920\ttotal: 55s\tremaining: 3m 17s\n",
      "649:\tlearn: 7882875.3135845\ttotal: 55.1s\tremaining: 3m 16s\n",
      "650:\tlearn: 7876026.6072704\ttotal: 55.2s\tremaining: 3m 16s\n",
      "651:\tlearn: 7869441.0338555\ttotal: 55.3s\tremaining: 3m 16s\n",
      "652:\tlearn: 7867883.6480630\ttotal: 55.4s\tremaining: 3m 16s\n",
      "653:\tlearn: 7864603.7361104\ttotal: 55.5s\tremaining: 3m 16s\n",
      "654:\tlearn: 7862296.2658286\ttotal: 55.5s\tremaining: 3m 16s\n",
      "655:\tlearn: 7859916.1215066\ttotal: 55.6s\tremaining: 3m 16s\n",
      "656:\tlearn: 7855539.2430674\ttotal: 55.7s\tremaining: 3m 16s\n",
      "657:\tlearn: 7853998.7984838\ttotal: 55.8s\tremaining: 3m 16s\n",
      "658:\tlearn: 7844016.5755683\ttotal: 55.9s\tremaining: 3m 16s\n",
      "659:\tlearn: 7842016.4286390\ttotal: 56s\tremaining: 3m 16s\n",
      "660:\tlearn: 7839828.5091184\ttotal: 56.1s\tremaining: 3m 16s\n",
      "661:\tlearn: 7831057.4942858\ttotal: 56.2s\tremaining: 3m 16s\n",
      "662:\tlearn: 7813962.0368737\ttotal: 56.3s\tremaining: 3m 16s\n",
      "663:\tlearn: 7812252.2902458\ttotal: 56.4s\tremaining: 3m 16s\n",
      "664:\tlearn: 7810922.4832376\ttotal: 56.5s\tremaining: 3m 16s\n",
      "665:\tlearn: 7799533.4023589\ttotal: 56.6s\tremaining: 3m 16s\n",
      "666:\tlearn: 7788323.7342821\ttotal: 56.7s\tremaining: 3m 16s\n",
      "667:\tlearn: 7782659.5224538\ttotal: 56.8s\tremaining: 3m 15s\n",
      "668:\tlearn: 7780723.4124276\ttotal: 56.9s\tremaining: 3m 15s\n",
      "669:\tlearn: 7776898.0548049\ttotal: 56.9s\tremaining: 3m 15s\n",
      "670:\tlearn: 7774948.7238391\ttotal: 57s\tremaining: 3m 15s\n",
      "671:\tlearn: 7744772.4592040\ttotal: 57.1s\tremaining: 3m 15s\n",
      "672:\tlearn: 7740710.6792229\ttotal: 57.2s\tremaining: 3m 15s\n",
      "673:\tlearn: 7734987.6521068\ttotal: 57.3s\tremaining: 3m 15s\n",
      "674:\tlearn: 7731009.8744323\ttotal: 57.4s\tremaining: 3m 15s\n",
      "675:\tlearn: 7727740.5912891\ttotal: 57.5s\tremaining: 3m 15s\n",
      "676:\tlearn: 7721713.4962127\ttotal: 57.6s\tremaining: 3m 15s\n",
      "677:\tlearn: 7716388.2801987\ttotal: 57.7s\tremaining: 3m 15s\n",
      "678:\tlearn: 7715511.9227696\ttotal: 57.8s\tremaining: 3m 15s\n",
      "679:\tlearn: 7705512.4689597\ttotal: 57.9s\tremaining: 3m 15s\n",
      "680:\tlearn: 7697599.2907254\ttotal: 58s\tremaining: 3m 15s\n",
      "681:\tlearn: 7672293.0962091\ttotal: 58.1s\tremaining: 3m 15s\n",
      "682:\tlearn: 7668323.2143959\ttotal: 58.2s\tremaining: 3m 15s\n",
      "683:\tlearn: 7665846.5075812\ttotal: 58.3s\tremaining: 3m 15s\n",
      "684:\tlearn: 7661315.5187501\ttotal: 58.4s\tremaining: 3m 15s\n",
      "685:\tlearn: 7656505.2351290\ttotal: 58.5s\tremaining: 3m 15s\n",
      "686:\tlearn: 7655042.0021442\ttotal: 58.6s\tremaining: 3m 14s\n",
      "687:\tlearn: 7649320.9083844\ttotal: 58.7s\tremaining: 3m 14s\n",
      "688:\tlearn: 7646864.0402380\ttotal: 58.8s\tremaining: 3m 14s\n",
      "689:\tlearn: 7641295.3307923\ttotal: 58.9s\tremaining: 3m 14s\n",
      "690:\tlearn: 7634174.5361612\ttotal: 59s\tremaining: 3m 14s\n",
      "691:\tlearn: 7630382.3088641\ttotal: 59.1s\tremaining: 3m 14s\n",
      "692:\tlearn: 7625754.6598976\ttotal: 59.2s\tremaining: 3m 14s\n",
      "693:\tlearn: 7618274.6582547\ttotal: 59.2s\tremaining: 3m 14s\n",
      "694:\tlearn: 7615643.7859243\ttotal: 59.3s\tremaining: 3m 14s\n",
      "695:\tlearn: 7610323.6272187\ttotal: 59.4s\tremaining: 3m 14s\n",
      "696:\tlearn: 7605135.3417955\ttotal: 59.5s\tremaining: 3m 14s\n",
      "697:\tlearn: 7599170.0236197\ttotal: 59.6s\tremaining: 3m 14s\n",
      "698:\tlearn: 7591403.8161199\ttotal: 59.7s\tremaining: 3m 14s\n",
      "699:\tlearn: 7589128.7530420\ttotal: 59.8s\tremaining: 3m 14s\n",
      "700:\tlearn: 7587320.6237956\ttotal: 59.9s\tremaining: 3m 14s\n",
      "701:\tlearn: 7580710.3082752\ttotal: 1m\tremaining: 3m 14s\n",
      "702:\tlearn: 7579384.6242321\ttotal: 1m\tremaining: 3m 14s\n",
      "703:\tlearn: 7566801.9047803\ttotal: 1m\tremaining: 3m 14s\n",
      "704:\tlearn: 7554591.3709373\ttotal: 1m\tremaining: 3m 14s\n",
      "705:\tlearn: 7542037.6578225\ttotal: 1m\tremaining: 3m 14s\n",
      "706:\tlearn: 7536225.6533943\ttotal: 1m\tremaining: 3m 13s\n",
      "707:\tlearn: 7515851.1744623\ttotal: 1m\tremaining: 3m 13s\n",
      "708:\tlearn: 7512024.3067082\ttotal: 1m\tremaining: 3m 13s\n",
      "709:\tlearn: 7508024.5570073\ttotal: 1m\tremaining: 3m 13s\n",
      "710:\tlearn: 7502423.0235994\ttotal: 1m\tremaining: 3m 13s\n",
      "711:\tlearn: 7501534.7294188\ttotal: 1m\tremaining: 3m 13s\n",
      "712:\tlearn: 7498177.6439265\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "713:\tlearn: 7494490.2678620\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "714:\tlearn: 7492742.2356903\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "715:\tlearn: 7491059.3156702\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "716:\tlearn: 7489042.9467290\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "717:\tlearn: 7473439.8250596\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "718:\tlearn: 7469939.4270264\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "719:\tlearn: 7467427.0702571\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "720:\tlearn: 7466252.5137952\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "721:\tlearn: 7462206.9635407\ttotal: 1m 1s\tremaining: 3m 12s\n",
      "722:\tlearn: 7452671.6199053\ttotal: 1m 1s\tremaining: 3m 12s\n",
      "723:\tlearn: 7447923.4599890\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "724:\tlearn: 7446014.2377074\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "725:\tlearn: 7436203.2287434\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "726:\tlearn: 7430235.5547902\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "727:\tlearn: 7426491.7961653\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "728:\tlearn: 7422792.3230259\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "729:\tlearn: 7418496.5663492\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "730:\tlearn: 7416571.4517755\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "731:\tlearn: 7412029.4159368\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "732:\tlearn: 7393029.3849022\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "733:\tlearn: 7389283.2782871\ttotal: 1m 2s\tremaining: 3m 12s\n",
      "734:\tlearn: 7387218.4671324\ttotal: 1m 3s\tremaining: 3m 12s\n",
      "735:\tlearn: 7376261.1836158\ttotal: 1m 3s\tremaining: 3m 12s\n",
      "736:\tlearn: 7361723.9210668\ttotal: 1m 3s\tremaining: 3m 12s\n",
      "737:\tlearn: 7359459.0677739\ttotal: 1m 3s\tremaining: 3m 12s\n",
      "738:\tlearn: 7354903.8618515\ttotal: 1m 3s\tremaining: 3m 11s\n",
      "739:\tlearn: 7352017.9324602\ttotal: 1m 3s\tremaining: 3m 11s\n",
      "740:\tlearn: 7348682.5579028\ttotal: 1m 3s\tremaining: 3m 11s\n",
      "741:\tlearn: 7346053.0901196\ttotal: 1m 3s\tremaining: 3m 11s\n",
      "742:\tlearn: 7341558.9745809\ttotal: 1m 3s\tremaining: 3m 11s\n",
      "743:\tlearn: 7339792.0979313\ttotal: 1m 3s\tremaining: 3m 11s\n",
      "744:\tlearn: 7337057.4530521\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "745:\tlearn: 7334519.0544141\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "746:\tlearn: 7333186.8406498\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "747:\tlearn: 7323951.4617641\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "748:\tlearn: 7321342.3714177\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "749:\tlearn: 7315834.1173856\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "750:\tlearn: 7313597.0720026\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "751:\tlearn: 7310963.3880623\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "752:\tlearn: 7305576.5203162\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "753:\tlearn: 7302306.2316747\ttotal: 1m 4s\tremaining: 3m 11s\n",
      "754:\tlearn: 7296230.2195648\ttotal: 1m 5s\tremaining: 3m 11s\n",
      "755:\tlearn: 7294923.6447036\ttotal: 1m 5s\tremaining: 3m 11s\n",
      "756:\tlearn: 7292531.1946578\ttotal: 1m 5s\tremaining: 3m 11s\n",
      "757:\tlearn: 7290394.3687985\ttotal: 1m 5s\tremaining: 3m 10s\n",
      "758:\tlearn: 7284275.5025356\ttotal: 1m 5s\tremaining: 3m 10s\n",
      "759:\tlearn: 7280842.5804718\ttotal: 1m 5s\tremaining: 3m 10s\n",
      "760:\tlearn: 7277991.5120126\ttotal: 1m 5s\tremaining: 3m 10s\n",
      "761:\tlearn: 7271942.0220827\ttotal: 1m 5s\tremaining: 3m 10s\n",
      "762:\tlearn: 7270522.4412023\ttotal: 1m 5s\tremaining: 3m 10s\n",
      "763:\tlearn: 7269131.1603916\ttotal: 1m 5s\tremaining: 3m 10s\n",
      "764:\tlearn: 7266605.6725869\ttotal: 1m 5s\tremaining: 3m 10s\n",
      "765:\tlearn: 7264352.5650786\ttotal: 1m 6s\tremaining: 3m 10s\n",
      "766:\tlearn: 7262494.0188810\ttotal: 1m 6s\tremaining: 3m 10s\n",
      "767:\tlearn: 7246846.6628209\ttotal: 1m 6s\tremaining: 3m 10s\n",
      "768:\tlearn: 7243216.5614997\ttotal: 1m 6s\tremaining: 3m 10s\n",
      "769:\tlearn: 7239859.1258027\ttotal: 1m 6s\tremaining: 3m 10s\n",
      "770:\tlearn: 7237772.2188876\ttotal: 1m 6s\tremaining: 3m 10s\n",
      "771:\tlearn: 7236298.6633916\ttotal: 1m 6s\tremaining: 3m 10s\n",
      "772:\tlearn: 7233882.4206439\ttotal: 1m 6s\tremaining: 3m 10s\n",
      "773:\tlearn: 7217759.8788527\ttotal: 1m 6s\tremaining: 3m 9s\n",
      "774:\tlearn: 7214447.4257613\ttotal: 1m 6s\tremaining: 3m 9s\n",
      "775:\tlearn: 7196523.0378553\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "776:\tlearn: 7194894.4731202\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "777:\tlearn: 7192008.8030233\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "778:\tlearn: 7190408.8377899\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "779:\tlearn: 7188152.1762560\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "780:\tlearn: 7186502.9534162\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "781:\tlearn: 7184924.7387831\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "782:\tlearn: 7168590.4041314\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "783:\tlearn: 7166434.0080470\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "784:\tlearn: 7164072.7485352\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "785:\tlearn: 7161383.1962770\ttotal: 1m 7s\tremaining: 3m 9s\n",
      "786:\tlearn: 7157702.2157042\ttotal: 1m 8s\tremaining: 3m 9s\n",
      "787:\tlearn: 7154716.4606276\ttotal: 1m 8s\tremaining: 3m 9s\n",
      "788:\tlearn: 7146097.2377704\ttotal: 1m 8s\tremaining: 3m 9s\n",
      "789:\tlearn: 7143832.9480596\ttotal: 1m 8s\tremaining: 3m 8s\n",
      "790:\tlearn: 7141682.3493681\ttotal: 1m 8s\tremaining: 3m 8s\n",
      "791:\tlearn: 7138238.8193572\ttotal: 1m 8s\tremaining: 3m 8s\n",
      "792:\tlearn: 7132207.4595655\ttotal: 1m 8s\tremaining: 3m 8s\n",
      "793:\tlearn: 7127660.3404523\ttotal: 1m 8s\tremaining: 3m 8s\n",
      "794:\tlearn: 7123413.0149151\ttotal: 1m 8s\tremaining: 3m 8s\n",
      "795:\tlearn: 7121569.2524535\ttotal: 1m 8s\tremaining: 3m 8s\n",
      "796:\tlearn: 7120395.3282611\ttotal: 1m 9s\tremaining: 3m 8s\n",
      "797:\tlearn: 7118182.2920031\ttotal: 1m 9s\tremaining: 3m 8s\n",
      "798:\tlearn: 7107464.3293620\ttotal: 1m 9s\tremaining: 3m 8s\n",
      "799:\tlearn: 7103094.7810164\ttotal: 1m 9s\tremaining: 3m 8s\n",
      "800:\tlearn: 7100628.3237015\ttotal: 1m 9s\tremaining: 3m 8s\n",
      "801:\tlearn: 7098298.2733120\ttotal: 1m 9s\tremaining: 3m 8s\n",
      "802:\tlearn: 7096641.9314526\ttotal: 1m 9s\tremaining: 3m 8s\n",
      "803:\tlearn: 7084369.7571258\ttotal: 1m 9s\tremaining: 3m 7s\n",
      "804:\tlearn: 7080372.0199380\ttotal: 1m 9s\tremaining: 3m 7s\n",
      "805:\tlearn: 7071500.2067374\ttotal: 1m 9s\tremaining: 3m 7s\n",
      "806:\tlearn: 7068535.5570622\ttotal: 1m 9s\tremaining: 3m 7s\n",
      "807:\tlearn: 7066951.5433507\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "808:\tlearn: 7062951.6286487\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "809:\tlearn: 7062004.6336260\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "810:\tlearn: 7058334.3680775\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "811:\tlearn: 7042378.1907007\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "812:\tlearn: 7038386.5183511\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "813:\tlearn: 7023809.0791253\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "814:\tlearn: 7020167.4015862\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "815:\tlearn: 7013831.6542135\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "816:\tlearn: 7012044.2345018\ttotal: 1m 10s\tremaining: 3m 7s\n",
      "817:\tlearn: 7005916.4786833\ttotal: 1m 10s\tremaining: 3m 6s\n",
      "818:\tlearn: 7001134.8298939\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "819:\tlearn: 6996941.7647001\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "820:\tlearn: 6993440.9695528\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "821:\tlearn: 6990217.2949913\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "822:\tlearn: 6987757.5435334\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "823:\tlearn: 6986092.3927081\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "824:\tlearn: 6983598.2812604\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "825:\tlearn: 6980300.9816270\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "826:\tlearn: 6978885.6549048\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "827:\tlearn: 6974919.7726485\ttotal: 1m 11s\tremaining: 3m 6s\n",
      "828:\tlearn: 6969736.2213049\ttotal: 1m 12s\tremaining: 3m 6s\n",
      "829:\tlearn: 6966938.9327792\ttotal: 1m 12s\tremaining: 3m 6s\n",
      "830:\tlearn: 6964901.9103155\ttotal: 1m 12s\tremaining: 3m 6s\n",
      "831:\tlearn: 6960082.4303828\ttotal: 1m 12s\tremaining: 3m 6s\n",
      "832:\tlearn: 6958089.1140401\ttotal: 1m 12s\tremaining: 3m 6s\n",
      "833:\tlearn: 6955640.7061503\ttotal: 1m 12s\tremaining: 3m 5s\n",
      "834:\tlearn: 6952301.7781514\ttotal: 1m 12s\tremaining: 3m 5s\n",
      "835:\tlearn: 6948969.6623631\ttotal: 1m 12s\tremaining: 3m 5s\n",
      "836:\tlearn: 6941661.7333871\ttotal: 1m 12s\tremaining: 3m 5s\n",
      "837:\tlearn: 6940342.6954167\ttotal: 1m 12s\tremaining: 3m 5s\n",
      "838:\tlearn: 6938253.3265240\ttotal: 1m 12s\tremaining: 3m 5s\n",
      "839:\tlearn: 6935696.3620267\ttotal: 1m 13s\tremaining: 3m 5s\n",
      "840:\tlearn: 6933969.0996505\ttotal: 1m 13s\tremaining: 3m 5s\n",
      "841:\tlearn: 6931917.1801261\ttotal: 1m 13s\tremaining: 3m 5s\n",
      "842:\tlearn: 6929155.6657563\ttotal: 1m 13s\tremaining: 3m 5s\n",
      "843:\tlearn: 6912303.3945318\ttotal: 1m 13s\tremaining: 3m 5s\n",
      "844:\tlearn: 6906653.8174556\ttotal: 1m 13s\tremaining: 3m 5s\n",
      "845:\tlearn: 6904830.7477926\ttotal: 1m 13s\tremaining: 3m 4s\n",
      "846:\tlearn: 6900085.6107153\ttotal: 1m 13s\tremaining: 3m 4s\n",
      "847:\tlearn: 6898298.0282232\ttotal: 1m 13s\tremaining: 3m 4s\n",
      "848:\tlearn: 6891594.0389600\ttotal: 1m 13s\tremaining: 3m 4s\n",
      "849:\tlearn: 6881345.1618908\ttotal: 1m 13s\tremaining: 3m 4s\n",
      "850:\tlearn: 6878307.8758116\ttotal: 1m 13s\tremaining: 3m 4s\n",
      "851:\tlearn: 6871950.5424294\ttotal: 1m 14s\tremaining: 3m 4s\n",
      "852:\tlearn: 6870720.5543125\ttotal: 1m 14s\tremaining: 3m 4s\n",
      "853:\tlearn: 6867751.9666111\ttotal: 1m 14s\tremaining: 3m 4s\n",
      "854:\tlearn: 6861479.6994864\ttotal: 1m 14s\tremaining: 3m 4s\n",
      "855:\tlearn: 6848785.6479674\ttotal: 1m 14s\tremaining: 3m 4s\n",
      "856:\tlearn: 6844877.4149960\ttotal: 1m 14s\tremaining: 3m 4s\n",
      "857:\tlearn: 6843464.6406875\ttotal: 1m 14s\tremaining: 3m 3s\n",
      "858:\tlearn: 6829633.1376058\ttotal: 1m 14s\tremaining: 3m 3s\n",
      "859:\tlearn: 6828674.2760687\ttotal: 1m 14s\tremaining: 3m 3s\n",
      "860:\tlearn: 6826880.3264125\ttotal: 1m 14s\tremaining: 3m 3s\n",
      "861:\tlearn: 6812739.4086225\ttotal: 1m 14s\tremaining: 3m 3s\n",
      "862:\tlearn: 6803846.5673888\ttotal: 1m 15s\tremaining: 3m 3s\n",
      "863:\tlearn: 6801688.6312888\ttotal: 1m 15s\tremaining: 3m 3s\n",
      "864:\tlearn: 6799690.8768443\ttotal: 1m 15s\tremaining: 3m 3s\n",
      "865:\tlearn: 6798067.7154582\ttotal: 1m 15s\tremaining: 3m 3s\n",
      "866:\tlearn: 6794856.8126225\ttotal: 1m 15s\tremaining: 3m 3s\n",
      "867:\tlearn: 6792058.4643490\ttotal: 1m 15s\tremaining: 3m 3s\n",
      "868:\tlearn: 6789893.8610954\ttotal: 1m 15s\tremaining: 3m 3s\n",
      "869:\tlearn: 6786666.7979232\ttotal: 1m 15s\tremaining: 3m 2s\n",
      "870:\tlearn: 6785400.1653094\ttotal: 1m 15s\tremaining: 3m 2s\n",
      "871:\tlearn: 6783687.8861375\ttotal: 1m 15s\tremaining: 3m 2s\n",
      "872:\tlearn: 6780151.5097400\ttotal: 1m 15s\tremaining: 3m 2s\n",
      "873:\tlearn: 6776000.0788523\ttotal: 1m 16s\tremaining: 3m 2s\n",
      "874:\tlearn: 6772093.0888684\ttotal: 1m 16s\tremaining: 3m 2s\n",
      "875:\tlearn: 6769988.1323604\ttotal: 1m 16s\tremaining: 3m 2s\n",
      "876:\tlearn: 6766715.2899659\ttotal: 1m 16s\tremaining: 3m 2s\n",
      "877:\tlearn: 6764061.9791740\ttotal: 1m 16s\tremaining: 3m 2s\n",
      "878:\tlearn: 6761643.3045110\ttotal: 1m 16s\tremaining: 3m 2s\n",
      "879:\tlearn: 6748307.7220917\ttotal: 1m 16s\tremaining: 3m 2s\n",
      "880:\tlearn: 6746123.4187732\ttotal: 1m 16s\tremaining: 3m 2s\n",
      "881:\tlearn: 6743414.3361673\ttotal: 1m 16s\tremaining: 3m 1s\n",
      "882:\tlearn: 6740026.3032585\ttotal: 1m 16s\tremaining: 3m 1s\n",
      "883:\tlearn: 6736181.9773158\ttotal: 1m 16s\tremaining: 3m 1s\n",
      "884:\tlearn: 6734279.8043075\ttotal: 1m 16s\tremaining: 3m 1s\n",
      "885:\tlearn: 6732658.1897586\ttotal: 1m 17s\tremaining: 3m 1s\n",
      "886:\tlearn: 6724105.7703555\ttotal: 1m 17s\tremaining: 3m 1s\n",
      "887:\tlearn: 6721944.6088550\ttotal: 1m 17s\tremaining: 3m 1s\n",
      "888:\tlearn: 6718475.4739144\ttotal: 1m 17s\tremaining: 3m 1s\n",
      "889:\tlearn: 6717028.2679955\ttotal: 1m 17s\tremaining: 3m 1s\n",
      "890:\tlearn: 6712854.0495044\ttotal: 1m 17s\tremaining: 3m 1s\n",
      "891:\tlearn: 6710743.6273464\ttotal: 1m 17s\tremaining: 3m 1s\n",
      "892:\tlearn: 6708369.9554956\ttotal: 1m 17s\tremaining: 3m 1s\n",
      "893:\tlearn: 6695552.3942412\ttotal: 1m 17s\tremaining: 3m\n",
      "894:\tlearn: 6693765.3575191\ttotal: 1m 17s\tremaining: 3m\n",
      "895:\tlearn: 6691867.1433519\ttotal: 1m 17s\tremaining: 3m\n",
      "896:\tlearn: 6689585.4221708\ttotal: 1m 18s\tremaining: 3m\n",
      "897:\tlearn: 6686561.4463928\ttotal: 1m 18s\tremaining: 3m\n",
      "898:\tlearn: 6684468.0371574\ttotal: 1m 18s\tremaining: 3m\n",
      "899:\tlearn: 6682684.5360009\ttotal: 1m 18s\tremaining: 3m\n",
      "900:\tlearn: 6681847.8023767\ttotal: 1m 18s\tremaining: 3m\n",
      "901:\tlearn: 6671714.7670612\ttotal: 1m 18s\tremaining: 3m\n",
      "902:\tlearn: 6670388.3276882\ttotal: 1m 18s\tremaining: 3m\n",
      "903:\tlearn: 6667807.2253258\ttotal: 1m 18s\tremaining: 3m\n",
      "904:\tlearn: 6663422.2349081\ttotal: 1m 18s\tremaining: 3m\n",
      "905:\tlearn: 6658128.5313062\ttotal: 1m 18s\tremaining: 2m 59s\n",
      "906:\tlearn: 6651812.9623776\ttotal: 1m 18s\tremaining: 2m 59s\n",
      "907:\tlearn: 6647534.4647587\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "908:\tlearn: 6646375.8269872\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "909:\tlearn: 6642045.3142590\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "910:\tlearn: 6637954.8734293\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "911:\tlearn: 6633381.4044074\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "912:\tlearn: 6629281.2445886\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "913:\tlearn: 6626575.1942756\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "914:\tlearn: 6622734.6147298\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "915:\tlearn: 6622053.1831130\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "916:\tlearn: 6617075.6908426\ttotal: 1m 19s\tremaining: 2m 59s\n",
      "917:\tlearn: 6615906.4239409\ttotal: 1m 19s\tremaining: 2m 58s\n",
      "918:\tlearn: 6610014.2770997\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "919:\tlearn: 6606260.5211558\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "920:\tlearn: 6603547.9369670\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "921:\tlearn: 6590106.0335568\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "922:\tlearn: 6586116.1133732\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "923:\tlearn: 6583998.9965580\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "924:\tlearn: 6582987.3800734\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "925:\tlearn: 6580929.1283823\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "926:\tlearn: 6578597.3837215\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "927:\tlearn: 6575897.1427460\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "928:\tlearn: 6571831.2544067\ttotal: 1m 20s\tremaining: 2m 58s\n",
      "929:\tlearn: 6567322.4811547\ttotal: 1m 21s\tremaining: 2m 58s\n",
      "930:\tlearn: 6565823.5842394\ttotal: 1m 21s\tremaining: 2m 58s\n",
      "931:\tlearn: 6561316.1326627\ttotal: 1m 21s\tremaining: 2m 57s\n",
      "932:\tlearn: 6558589.4070639\ttotal: 1m 21s\tremaining: 2m 57s\n",
      "933:\tlearn: 6556637.4584052\ttotal: 1m 21s\tremaining: 2m 57s\n",
      "934:\tlearn: 6553932.8082225\ttotal: 1m 21s\tremaining: 2m 57s\n",
      "935:\tlearn: 6551359.0294938\ttotal: 1m 21s\tremaining: 2m 57s\n",
      "936:\tlearn: 6549593.5538382\ttotal: 1m 21s\tremaining: 2m 57s\n",
      "937:\tlearn: 6545567.5784136\ttotal: 1m 21s\tremaining: 2m 57s\n",
      "938:\tlearn: 6541408.9875612\ttotal: 1m 21s\tremaining: 2m 57s\n",
      "939:\tlearn: 6529309.6777112\ttotal: 1m 21s\tremaining: 2m 57s\n",
      "940:\tlearn: 6516691.5403860\ttotal: 1m 22s\tremaining: 2m 57s\n",
      "941:\tlearn: 6514445.4248374\ttotal: 1m 22s\tremaining: 2m 57s\n",
      "942:\tlearn: 6511018.1540519\ttotal: 1m 22s\tremaining: 2m 57s\n",
      "943:\tlearn: 6507952.2936813\ttotal: 1m 22s\tremaining: 2m 57s\n",
      "944:\tlearn: 6505603.7522872\ttotal: 1m 22s\tremaining: 2m 57s\n",
      "945:\tlearn: 6502740.4845788\ttotal: 1m 22s\tremaining: 2m 56s\n",
      "946:\tlearn: 6501423.9675616\ttotal: 1m 22s\tremaining: 2m 56s\n",
      "947:\tlearn: 6499923.2467889\ttotal: 1m 22s\tremaining: 2m 56s\n",
      "948:\tlearn: 6498588.0776807\ttotal: 1m 22s\tremaining: 2m 56s\n",
      "949:\tlearn: 6496514.9558355\ttotal: 1m 22s\tremaining: 2m 56s\n",
      "950:\tlearn: 6485721.9135556\ttotal: 1m 23s\tremaining: 2m 56s\n",
      "951:\tlearn: 6484815.7167595\ttotal: 1m 23s\tremaining: 2m 56s\n",
      "952:\tlearn: 6473686.5611079\ttotal: 1m 23s\tremaining: 2m 56s\n",
      "953:\tlearn: 6470314.2055784\ttotal: 1m 23s\tremaining: 2m 56s\n",
      "954:\tlearn: 6467566.3172155\ttotal: 1m 23s\tremaining: 2m 56s\n",
      "955:\tlearn: 6464798.8286620\ttotal: 1m 23s\tremaining: 2m 56s\n",
      "956:\tlearn: 6460350.9106380\ttotal: 1m 23s\tremaining: 2m 56s\n",
      "957:\tlearn: 6454564.7943124\ttotal: 1m 23s\tremaining: 2m 56s\n",
      "958:\tlearn: 6443654.5395205\ttotal: 1m 23s\tremaining: 2m 56s\n",
      "959:\tlearn: 6442135.7911174\ttotal: 1m 23s\tremaining: 2m 55s\n",
      "960:\tlearn: 6440303.7600752\ttotal: 1m 23s\tremaining: 2m 55s\n",
      "961:\tlearn: 6435151.9357433\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "962:\tlearn: 6431692.0072416\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "963:\tlearn: 6428500.7005627\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "964:\tlearn: 6426908.6680485\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "965:\tlearn: 6426081.3814808\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "966:\tlearn: 6424779.5469803\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "967:\tlearn: 6423088.2776083\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "968:\tlearn: 6420793.2827257\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "969:\tlearn: 6409754.8507144\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "970:\tlearn: 6408855.9371733\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "971:\tlearn: 6407689.4861238\ttotal: 1m 24s\tremaining: 2m 55s\n",
      "972:\tlearn: 6405536.3582525\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "973:\tlearn: 6397495.2775832\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "974:\tlearn: 6395652.8696807\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "975:\tlearn: 6394565.5157468\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "976:\tlearn: 6392640.2330081\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "977:\tlearn: 6383585.4639681\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "978:\tlearn: 6381142.4933053\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "979:\tlearn: 6380325.4599111\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "980:\tlearn: 6378066.1877768\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "981:\tlearn: 6374920.8672364\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "982:\tlearn: 6372549.1568450\ttotal: 1m 25s\tremaining: 2m 54s\n",
      "983:\tlearn: 6354407.5286673\ttotal: 1m 26s\tremaining: 2m 54s\n",
      "984:\tlearn: 6353368.8191864\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "985:\tlearn: 6351747.5677538\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "986:\tlearn: 6351228.6708957\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "987:\tlearn: 6347253.0943422\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "988:\tlearn: 6337305.5613462\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "989:\tlearn: 6322272.4212230\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "990:\tlearn: 6319546.2800288\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "991:\tlearn: 6315301.8578654\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "992:\tlearn: 6312820.5075162\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "993:\tlearn: 6311092.6830915\ttotal: 1m 26s\tremaining: 2m 53s\n",
      "994:\tlearn: 6309802.1596479\ttotal: 1m 27s\tremaining: 2m 53s\n",
      "995:\tlearn: 6305918.8674983\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "996:\tlearn: 6304213.6783630\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "997:\tlearn: 6303194.5001693\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "998:\tlearn: 6301547.9779659\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "999:\tlearn: 6299574.7850185\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "1000:\tlearn: 6296657.9088488\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "1001:\tlearn: 6295124.6176841\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "1002:\tlearn: 6293498.0623705\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "1003:\tlearn: 6291955.9485374\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "1004:\tlearn: 6290639.6896379\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "1005:\tlearn: 6288950.8835734\ttotal: 1m 27s\tremaining: 2m 52s\n",
      "1006:\tlearn: 6286536.0231369\ttotal: 1m 28s\tremaining: 2m 52s\n",
      "1007:\tlearn: 6280610.0893036\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1008:\tlearn: 6278347.9435011\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1009:\tlearn: 6274949.3463076\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1010:\tlearn: 6263893.9391583\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1011:\tlearn: 6262029.4519826\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1012:\tlearn: 6260092.1124831\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1013:\tlearn: 6259307.2851968\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1014:\tlearn: 6257620.4246391\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1015:\tlearn: 6256308.0821048\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1016:\tlearn: 6254197.8198633\ttotal: 1m 28s\tremaining: 2m 51s\n",
      "1017:\tlearn: 6251447.3390400\ttotal: 1m 29s\tremaining: 2m 51s\n",
      "1018:\tlearn: 6249922.6815991\ttotal: 1m 29s\tremaining: 2m 51s\n",
      "1019:\tlearn: 6248587.2911752\ttotal: 1m 29s\tremaining: 2m 50s\n",
      "1020:\tlearn: 6235650.1550792\ttotal: 1m 29s\tremaining: 2m 50s\n",
      "1021:\tlearn: 6230998.1175377\ttotal: 1m 29s\tremaining: 2m 50s\n",
      "1022:\tlearn: 6228965.0548087\ttotal: 1m 29s\tremaining: 2m 50s\n",
      "1023:\tlearn: 6227337.4436321\ttotal: 1m 29s\tremaining: 2m 50s\n",
      "1024:\tlearn: 6225020.5961580\ttotal: 1m 29s\tremaining: 2m 50s\n",
      "1025:\tlearn: 6221005.1164740\ttotal: 1m 29s\tremaining: 2m 50s\n",
      "1026:\tlearn: 6217736.7954972\ttotal: 1m 29s\tremaining: 2m 50s\n",
      "1027:\tlearn: 6214465.8005195\ttotal: 1m 29s\tremaining: 2m 50s\n",
      "1028:\tlearn: 6211740.5493084\ttotal: 1m 30s\tremaining: 2m 50s\n",
      "1029:\tlearn: 6210870.7528836\ttotal: 1m 30s\tremaining: 2m 50s\n",
      "1030:\tlearn: 6209632.2130310\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1031:\tlearn: 6206669.8638566\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1032:\tlearn: 6202741.5175908\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1033:\tlearn: 6197798.0180858\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1034:\tlearn: 6194430.0292414\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1035:\tlearn: 6193095.0349416\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1036:\tlearn: 6190798.1761026\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1037:\tlearn: 6187727.5239871\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1038:\tlearn: 6184803.3678037\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1039:\tlearn: 6183291.7031334\ttotal: 1m 30s\tremaining: 2m 49s\n",
      "1040:\tlearn: 6181567.8338268\ttotal: 1m 31s\tremaining: 2m 49s\n",
      "1041:\tlearn: 6179033.9717497\ttotal: 1m 31s\tremaining: 2m 49s\n",
      "1042:\tlearn: 6177637.2496286\ttotal: 1m 31s\tremaining: 2m 48s\n",
      "1043:\tlearn: 6176331.2543441\ttotal: 1m 31s\tremaining: 2m 48s\n",
      "1044:\tlearn: 6174718.7330931\ttotal: 1m 31s\tremaining: 2m 48s\n",
      "1045:\tlearn: 6173267.1489863\ttotal: 1m 31s\tremaining: 2m 48s\n",
      "1046:\tlearn: 6171897.5144866\ttotal: 1m 31s\tremaining: 2m 48s\n",
      "1047:\tlearn: 6162209.0282298\ttotal: 1m 31s\tremaining: 2m 48s\n",
      "1048:\tlearn: 6160127.3207573\ttotal: 1m 31s\tremaining: 2m 48s\n",
      "1049:\tlearn: 6158892.3393633\ttotal: 1m 31s\tremaining: 2m 48s\n",
      "1050:\tlearn: 6155206.3521673\ttotal: 1m 31s\tremaining: 2m 48s\n",
      "1051:\tlearn: 6154136.6897619\ttotal: 1m 32s\tremaining: 2m 48s\n",
      "1052:\tlearn: 6150057.7097814\ttotal: 1m 32s\tremaining: 2m 48s\n",
      "1053:\tlearn: 6148188.4197378\ttotal: 1m 32s\tremaining: 2m 48s\n",
      "1054:\tlearn: 6145911.3320491\ttotal: 1m 32s\tremaining: 2m 47s\n",
      "1055:\tlearn: 6144198.2462011\ttotal: 1m 32s\tremaining: 2m 47s\n",
      "1056:\tlearn: 6143520.0891780\ttotal: 1m 32s\tremaining: 2m 47s\n",
      "1057:\tlearn: 6141862.1939261\ttotal: 1m 32s\tremaining: 2m 47s\n",
      "1058:\tlearn: 6119809.8416042\ttotal: 1m 32s\tremaining: 2m 47s\n",
      "1059:\tlearn: 6116986.9677467\ttotal: 1m 32s\tremaining: 2m 47s\n",
      "1060:\tlearn: 6115091.2672337\ttotal: 1m 32s\tremaining: 2m 47s\n",
      "1061:\tlearn: 6110950.2352616\ttotal: 1m 32s\tremaining: 2m 47s\n",
      "1062:\tlearn: 6109603.3712422\ttotal: 1m 33s\tremaining: 2m 47s\n",
      "1063:\tlearn: 6100715.2809788\ttotal: 1m 33s\tremaining: 2m 47s\n",
      "1064:\tlearn: 6083956.7599602\ttotal: 1m 33s\tremaining: 2m 47s\n",
      "1065:\tlearn: 6082848.4554510\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "1066:\tlearn: 6080099.3041962\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "1067:\tlearn: 6079386.6871187\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "1068:\tlearn: 6075910.3264874\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "1069:\tlearn: 6074004.9475984\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "1070:\tlearn: 6064064.6360520\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "1071:\tlearn: 6062219.5724185\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "1072:\tlearn: 6060158.9967086\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "1073:\tlearn: 6057631.4742827\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "1074:\tlearn: 6056287.3343410\ttotal: 1m 34s\tremaining: 2m 46s\n",
      "1075:\tlearn: 6054953.3690308\ttotal: 1m 34s\tremaining: 2m 46s\n",
      "1076:\tlearn: 6051061.7767372\ttotal: 1m 34s\tremaining: 2m 45s\n",
      "1077:\tlearn: 6049266.1773863\ttotal: 1m 34s\tremaining: 2m 45s\n",
      "1078:\tlearn: 6047261.6778266\ttotal: 1m 34s\tremaining: 2m 45s\n",
      "1079:\tlearn: 6043459.0579053\ttotal: 1m 34s\tremaining: 2m 45s\n",
      "1080:\tlearn: 6041950.5640191\ttotal: 1m 34s\tremaining: 2m 45s\n",
      "1081:\tlearn: 6038144.1558317\ttotal: 1m 34s\tremaining: 2m 45s\n",
      "1082:\tlearn: 6036204.7857006\ttotal: 1m 34s\tremaining: 2m 45s\n",
      "1083:\tlearn: 6034099.8302045\ttotal: 1m 34s\tremaining: 2m 45s\n",
      "1084:\tlearn: 6032925.3363793\ttotal: 1m 34s\tremaining: 2m 45s\n",
      "1085:\tlearn: 6028871.7498426\ttotal: 1m 35s\tremaining: 2m 45s\n",
      "1086:\tlearn: 6026848.2428077\ttotal: 1m 35s\tremaining: 2m 45s\n",
      "1087:\tlearn: 6024438.5298516\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1088:\tlearn: 6023790.0053713\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1089:\tlearn: 6022504.7498794\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1090:\tlearn: 6020996.9936940\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1091:\tlearn: 6018978.9419668\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1092:\tlearn: 6017037.4674154\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1093:\tlearn: 6015637.1494775\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1094:\tlearn: 6012544.7883409\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1095:\tlearn: 6011734.8887890\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1096:\tlearn: 6011124.9970241\ttotal: 1m 35s\tremaining: 2m 44s\n",
      "1097:\tlearn: 6009378.7261969\ttotal: 1m 36s\tremaining: 2m 44s\n",
      "1098:\tlearn: 6008364.9623662\ttotal: 1m 36s\tremaining: 2m 44s\n",
      "1099:\tlearn: 6006526.4197506\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1100:\tlearn: 6004453.9573431\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1101:\tlearn: 5993743.3167344\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1102:\tlearn: 5991455.2611456\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1103:\tlearn: 5987123.8120179\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1104:\tlearn: 5984756.6284009\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1105:\tlearn: 5982623.9775779\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1106:\tlearn: 5979823.0117965\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1107:\tlearn: 5978342.6072158\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1108:\tlearn: 5977246.7061347\ttotal: 1m 36s\tremaining: 2m 43s\n",
      "1109:\tlearn: 5975848.2515069\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1110:\tlearn: 5973172.1671752\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1111:\tlearn: 5971485.9179666\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1112:\tlearn: 5969740.5999535\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1113:\tlearn: 5968026.2667989\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1114:\tlearn: 5966186.3412515\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1115:\tlearn: 5963177.9313697\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1116:\tlearn: 5962107.6586178\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1117:\tlearn: 5960640.7750104\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1118:\tlearn: 5957397.7785740\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1119:\tlearn: 5956442.7475056\ttotal: 1m 37s\tremaining: 2m 42s\n",
      "1120:\tlearn: 5954706.2627906\ttotal: 1m 37s\tremaining: 2m 41s\n",
      "1121:\tlearn: 5953594.7738785\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1122:\tlearn: 5952566.3701630\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1123:\tlearn: 5951881.8890447\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1124:\tlearn: 5937125.9027807\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1125:\tlearn: 5935928.0009778\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1126:\tlearn: 5933695.9090427\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1127:\tlearn: 5932725.5174206\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1128:\tlearn: 5930996.9762742\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1129:\tlearn: 5929401.5042075\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1130:\tlearn: 5927698.5555794\ttotal: 1m 38s\tremaining: 2m 41s\n",
      "1131:\tlearn: 5926289.4386401\ttotal: 1m 38s\tremaining: 2m 40s\n",
      "1132:\tlearn: 5922621.1113540\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1133:\tlearn: 5921667.4122144\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1134:\tlearn: 5919772.0955413\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1135:\tlearn: 5918524.6248240\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1136:\tlearn: 5917151.7689943\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1137:\tlearn: 5915035.5307083\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1138:\tlearn: 5912622.9125402\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1139:\tlearn: 5910680.1721327\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1140:\tlearn: 5907902.7407861\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1141:\tlearn: 5905794.8326441\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1142:\tlearn: 5902779.4503630\ttotal: 1m 39s\tremaining: 2m 40s\n",
      "1143:\tlearn: 5901119.7746562\ttotal: 1m 40s\tremaining: 2m 40s\n",
      "1144:\tlearn: 5897667.2231271\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1145:\tlearn: 5893999.6115115\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1146:\tlearn: 5888441.2487493\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1147:\tlearn: 5886885.5887124\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1148:\tlearn: 5885722.5907396\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1149:\tlearn: 5882971.2016290\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1150:\tlearn: 5872281.1525910\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1151:\tlearn: 5870868.8422735\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1152:\tlearn: 5867709.1799083\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1153:\tlearn: 5866127.9385036\ttotal: 1m 40s\tremaining: 2m 39s\n",
      "1154:\tlearn: 5864348.4144578\ttotal: 1m 41s\tremaining: 2m 39s\n",
      "1155:\tlearn: 5863188.9894648\ttotal: 1m 41s\tremaining: 2m 39s\n",
      "1156:\tlearn: 5861014.1308733\ttotal: 1m 41s\tremaining: 2m 38s\n",
      "1157:\tlearn: 5859560.5934656\ttotal: 1m 41s\tremaining: 2m 38s\n",
      "1158:\tlearn: 5858200.1436188\ttotal: 1m 41s\tremaining: 2m 38s\n",
      "1159:\tlearn: 5848755.0060035\ttotal: 1m 41s\tremaining: 2m 38s\n",
      "1160:\tlearn: 5847319.3629063\ttotal: 1m 41s\tremaining: 2m 38s\n",
      "1161:\tlearn: 5845630.9133054\ttotal: 1m 41s\tremaining: 2m 38s\n",
      "1162:\tlearn: 5844151.2376068\ttotal: 1m 41s\tremaining: 2m 38s\n",
      "1163:\tlearn: 5835067.9979398\ttotal: 1m 41s\tremaining: 2m 38s\n",
      "1164:\tlearn: 5833487.5854748\ttotal: 1m 41s\tremaining: 2m 38s\n",
      "1165:\tlearn: 5832196.4406191\ttotal: 1m 42s\tremaining: 2m 38s\n",
      "1166:\tlearn: 5831061.8540392\ttotal: 1m 42s\tremaining: 2m 38s\n",
      "1167:\tlearn: 5823662.6423661\ttotal: 1m 42s\tremaining: 2m 38s\n",
      "1168:\tlearn: 5822574.6624260\ttotal: 1m 42s\tremaining: 2m 37s\n",
      "1169:\tlearn: 5821176.8413174\ttotal: 1m 42s\tremaining: 2m 37s\n",
      "1170:\tlearn: 5820274.9211773\ttotal: 1m 42s\tremaining: 2m 37s\n",
      "1171:\tlearn: 5818489.1283782\ttotal: 1m 42s\tremaining: 2m 37s\n",
      "1172:\tlearn: 5816782.6181833\ttotal: 1m 42s\tremaining: 2m 37s\n",
      "1173:\tlearn: 5815298.1105200\ttotal: 1m 42s\tremaining: 2m 37s\n",
      "1174:\tlearn: 5813654.6274854\ttotal: 1m 42s\tremaining: 2m 37s\n",
      "1175:\tlearn: 5812344.1005507\ttotal: 1m 42s\tremaining: 2m 37s\n",
      "1176:\tlearn: 5811340.9289432\ttotal: 1m 42s\tremaining: 2m 37s\n",
      "1177:\tlearn: 5808708.3459104\ttotal: 1m 43s\tremaining: 2m 37s\n",
      "1178:\tlearn: 5807333.6600615\ttotal: 1m 43s\tremaining: 2m 37s\n",
      "1179:\tlearn: 5805631.7684831\ttotal: 1m 43s\tremaining: 2m 36s\n",
      "1180:\tlearn: 5804261.5492105\ttotal: 1m 43s\tremaining: 2m 36s\n",
      "1181:\tlearn: 5800795.4004580\ttotal: 1m 43s\tremaining: 2m 36s\n",
      "1182:\tlearn: 5798713.8748496\ttotal: 1m 43s\tremaining: 2m 36s\n",
      "1183:\tlearn: 5797395.1307187\ttotal: 1m 43s\tremaining: 2m 36s\n",
      "1184:\tlearn: 5795637.6319090\ttotal: 1m 43s\tremaining: 2m 36s\n",
      "1185:\tlearn: 5794321.4890324\ttotal: 1m 43s\tremaining: 2m 36s\n",
      "1186:\tlearn: 5793218.0302456\ttotal: 1m 43s\tremaining: 2m 36s\n",
      "1187:\tlearn: 5792589.2456381\ttotal: 1m 43s\tremaining: 2m 36s\n",
      "1188:\tlearn: 5790916.5148568\ttotal: 1m 44s\tremaining: 2m 36s\n",
      "1189:\tlearn: 5786692.1536468\ttotal: 1m 44s\tremaining: 2m 36s\n",
      "1190:\tlearn: 5785954.7160698\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1191:\tlearn: 5783372.0102219\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1192:\tlearn: 5781042.9266521\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1193:\tlearn: 5774158.9640270\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1194:\tlearn: 5771096.9865822\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1195:\tlearn: 5768562.3097716\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1196:\tlearn: 5767547.6758508\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1197:\tlearn: 5758489.8134811\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1198:\tlearn: 5756259.7110007\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1199:\tlearn: 5754028.2672773\ttotal: 1m 44s\tremaining: 2m 35s\n",
      "1200:\tlearn: 5753133.1084361\ttotal: 1m 45s\tremaining: 2m 35s\n",
      "1201:\tlearn: 5748373.5774080\ttotal: 1m 45s\tremaining: 2m 35s\n",
      "1202:\tlearn: 5747003.1850129\ttotal: 1m 45s\tremaining: 2m 34s\n",
      "1203:\tlearn: 5745665.3012479\ttotal: 1m 45s\tremaining: 2m 34s\n",
      "1204:\tlearn: 5742498.2806001\ttotal: 1m 45s\tremaining: 2m 34s\n",
      "1205:\tlearn: 5729648.2406841\ttotal: 1m 45s\tremaining: 2m 34s\n",
      "1206:\tlearn: 5716264.8794219\ttotal: 1m 45s\tremaining: 2m 34s\n",
      "1207:\tlearn: 5713970.2416476\ttotal: 1m 45s\tremaining: 2m 34s\n",
      "1208:\tlearn: 5713331.2489905\ttotal: 1m 45s\tremaining: 2m 34s\n",
      "1209:\tlearn: 5710786.0888126\ttotal: 1m 45s\tremaining: 2m 34s\n",
      "1210:\tlearn: 5708533.9661116\ttotal: 1m 45s\tremaining: 2m 34s\n",
      "1211:\tlearn: 5707301.7198927\ttotal: 1m 46s\tremaining: 2m 34s\n",
      "1212:\tlearn: 5700328.0612417\ttotal: 1m 46s\tremaining: 2m 34s\n",
      "1213:\tlearn: 5698780.8564857\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1214:\tlearn: 5693774.4358389\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1215:\tlearn: 5691154.2736957\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1216:\tlearn: 5689058.0657483\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1217:\tlearn: 5688455.7721790\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1218:\tlearn: 5687239.2308351\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1219:\tlearn: 5684835.4555210\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1220:\tlearn: 5681858.7365749\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1221:\tlearn: 5680646.0052594\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1222:\tlearn: 5680008.8280898\ttotal: 1m 46s\tremaining: 2m 33s\n",
      "1223:\tlearn: 5676541.6656517\ttotal: 1m 47s\tremaining: 2m 33s\n",
      "1224:\tlearn: 5674971.4450644\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1225:\tlearn: 5673764.5130038\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1226:\tlearn: 5672419.6769056\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1227:\tlearn: 5657598.6208687\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1228:\tlearn: 5656259.7161181\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1229:\tlearn: 5650685.9576470\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1230:\tlearn: 5649684.0860195\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1231:\tlearn: 5647081.7782715\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1232:\tlearn: 5646143.0786847\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1233:\tlearn: 5644639.5231773\ttotal: 1m 47s\tremaining: 2m 32s\n",
      "1234:\tlearn: 5642268.8249456\ttotal: 1m 47s\tremaining: 2m 31s\n",
      "1235:\tlearn: 5639319.8916955\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1236:\tlearn: 5637431.4544072\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1237:\tlearn: 5634776.4065699\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1238:\tlearn: 5630119.7705501\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1239:\tlearn: 5621547.7206337\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1240:\tlearn: 5620067.9691012\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1241:\tlearn: 5618962.9809881\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1242:\tlearn: 5617766.8825472\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1243:\tlearn: 5610434.1033203\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1244:\tlearn: 5609714.9763315\ttotal: 1m 48s\tremaining: 2m 31s\n",
      "1245:\tlearn: 5608184.8848894\ttotal: 1m 48s\tremaining: 2m 30s\n",
      "1246:\tlearn: 5606924.4714981\ttotal: 1m 48s\tremaining: 2m 30s\n",
      "1247:\tlearn: 5597694.0531624\ttotal: 1m 49s\tremaining: 2m 30s\n",
      "1248:\tlearn: 5595204.3563302\ttotal: 1m 49s\tremaining: 2m 30s\n",
      "1249:\tlearn: 5593730.0378508\ttotal: 1m 49s\tremaining: 2m 30s\n",
      "1250:\tlearn: 5591888.8179947\ttotal: 1m 49s\tremaining: 2m 30s\n",
      "1251:\tlearn: 5585806.9310422\ttotal: 1m 49s\tremaining: 2m 30s\n",
      "1252:\tlearn: 5571718.9639965\ttotal: 1m 49s\tremaining: 2m 30s\n",
      "1253:\tlearn: 5570651.3332606\ttotal: 1m 49s\tremaining: 2m 30s\n",
      "1254:\tlearn: 5569190.5024528\ttotal: 1m 49s\tremaining: 2m 30s\n",
      "1255:\tlearn: 5568030.5898015\ttotal: 1m 49s\tremaining: 2m 30s\n",
      "1256:\tlearn: 5564254.3864668\ttotal: 1m 49s\tremaining: 2m 29s\n",
      "1257:\tlearn: 5562589.8966108\ttotal: 1m 49s\tremaining: 2m 29s\n",
      "1258:\tlearn: 5559251.3976348\ttotal: 1m 49s\tremaining: 2m 29s\n",
      "1259:\tlearn: 5555868.5150182\ttotal: 1m 50s\tremaining: 2m 29s\n",
      "1260:\tlearn: 5554019.6359972\ttotal: 1m 50s\tremaining: 2m 29s\n",
      "1261:\tlearn: 5551944.2524131\ttotal: 1m 50s\tremaining: 2m 29s\n",
      "1262:\tlearn: 5548581.1086714\ttotal: 1m 50s\tremaining: 2m 29s\n",
      "1263:\tlearn: 5546755.2739957\ttotal: 1m 50s\tremaining: 2m 29s\n",
      "1264:\tlearn: 5543415.2322513\ttotal: 1m 50s\tremaining: 2m 29s\n",
      "1265:\tlearn: 5540331.6422851\ttotal: 1m 50s\tremaining: 2m 29s\n",
      "1266:\tlearn: 5538929.6572346\ttotal: 1m 50s\tremaining: 2m 29s\n",
      "1267:\tlearn: 5537229.9586344\ttotal: 1m 51s\tremaining: 2m 29s\n",
      "1268:\tlearn: 5537001.0365929\ttotal: 1m 51s\tremaining: 2m 29s\n",
      "1269:\tlearn: 5536022.0448181\ttotal: 1m 51s\tremaining: 2m 29s\n",
      "1270:\tlearn: 5535080.1771455\ttotal: 1m 51s\tremaining: 2m 29s\n",
      "1271:\tlearn: 5533673.5628417\ttotal: 1m 51s\tremaining: 2m 29s\n",
      "1272:\tlearn: 5532632.3395848\ttotal: 1m 52s\tremaining: 2m 29s\n",
      "1273:\tlearn: 5530576.0213851\ttotal: 1m 52s\tremaining: 2m 29s\n",
      "1274:\tlearn: 5529379.9712353\ttotal: 1m 52s\tremaining: 2m 29s\n",
      "1275:\tlearn: 5527703.1159307\ttotal: 1m 52s\tremaining: 2m 29s\n",
      "1276:\tlearn: 5526164.4866132\ttotal: 1m 52s\tremaining: 2m 29s\n",
      "1277:\tlearn: 5524440.5054853\ttotal: 1m 53s\tremaining: 2m 30s\n",
      "1278:\tlearn: 5523635.6355344\ttotal: 1m 53s\tremaining: 2m 30s\n",
      "1279:\tlearn: 5522239.4682212\ttotal: 1m 53s\tremaining: 2m 30s\n",
      "1280:\tlearn: 5519905.6844311\ttotal: 1m 53s\tremaining: 2m 30s\n",
      "1281:\tlearn: 5518006.1887070\ttotal: 1m 53s\tremaining: 2m 30s\n",
      "1282:\tlearn: 5515376.7898736\ttotal: 1m 53s\tremaining: 2m 30s\n",
      "1283:\tlearn: 5514657.1120088\ttotal: 1m 54s\tremaining: 2m 30s\n",
      "1284:\tlearn: 5512212.6199574\ttotal: 1m 54s\tremaining: 2m 30s\n",
      "1285:\tlearn: 5510783.5756527\ttotal: 1m 54s\tremaining: 2m 30s\n",
      "1286:\tlearn: 5509997.3400601\ttotal: 1m 54s\tremaining: 2m 30s\n",
      "1287:\tlearn: 5507214.4457166\ttotal: 1m 54s\tremaining: 2m 30s\n",
      "1288:\tlearn: 5505904.9254052\ttotal: 1m 55s\tremaining: 2m 30s\n",
      "1289:\tlearn: 5504151.4992171\ttotal: 1m 55s\tremaining: 2m 30s\n",
      "1290:\tlearn: 5503139.5058208\ttotal: 1m 55s\tremaining: 2m 30s\n",
      "1291:\tlearn: 5501779.9507096\ttotal: 1m 55s\tremaining: 2m 30s\n",
      "1292:\tlearn: 5499649.3735171\ttotal: 1m 55s\tremaining: 2m 30s\n",
      "1293:\tlearn: 5498438.7064265\ttotal: 1m 56s\tremaining: 2m 30s\n",
      "1294:\tlearn: 5497186.6360229\ttotal: 1m 56s\tremaining: 2m 30s\n",
      "1295:\tlearn: 5493825.2273979\ttotal: 1m 56s\tremaining: 2m 30s\n",
      "1296:\tlearn: 5492421.5562399\ttotal: 1m 56s\tremaining: 2m 30s\n",
      "1297:\tlearn: 5489016.4843989\ttotal: 1m 56s\tremaining: 2m 30s\n",
      "1298:\tlearn: 5485995.1641917\ttotal: 1m 56s\tremaining: 2m 30s\n",
      "1299:\tlearn: 5484093.8342729\ttotal: 1m 56s\tremaining: 2m 30s\n",
      "1300:\tlearn: 5482422.3703963\ttotal: 1m 57s\tremaining: 2m 30s\n",
      "1301:\tlearn: 5480019.1214830\ttotal: 1m 57s\tremaining: 2m 30s\n",
      "1302:\tlearn: 5478993.9096355\ttotal: 1m 57s\tremaining: 2m 30s\n",
      "1303:\tlearn: 5477519.0226528\ttotal: 1m 57s\tremaining: 2m 30s\n",
      "1304:\tlearn: 5475605.0604426\ttotal: 1m 57s\tremaining: 2m 30s\n",
      "1305:\tlearn: 5468431.6804577\ttotal: 1m 57s\tremaining: 2m 30s\n",
      "1306:\tlearn: 5466144.3706232\ttotal: 1m 58s\tremaining: 2m 30s\n",
      "1307:\tlearn: 5464785.1816029\ttotal: 1m 58s\tremaining: 2m 30s\n",
      "1308:\tlearn: 5457898.1928762\ttotal: 1m 58s\tremaining: 2m 30s\n",
      "1309:\tlearn: 5452074.6681106\ttotal: 1m 58s\tremaining: 2m 30s\n",
      "1310:\tlearn: 5451062.7666063\ttotal: 1m 58s\tremaining: 2m 30s\n",
      "1311:\tlearn: 5449603.0300466\ttotal: 1m 58s\tremaining: 2m 30s\n",
      "1312:\tlearn: 5449014.0378460\ttotal: 1m 59s\tremaining: 2m 30s\n",
      "1313:\tlearn: 5447665.9010322\ttotal: 1m 59s\tremaining: 2m 30s\n",
      "1314:\tlearn: 5446031.9652791\ttotal: 1m 59s\tremaining: 2m 30s\n",
      "1315:\tlearn: 5444809.5773420\ttotal: 1m 59s\tremaining: 2m 30s\n",
      "1316:\tlearn: 5442854.8047937\ttotal: 1m 59s\tremaining: 2m 30s\n",
      "1317:\tlearn: 5440954.7990461\ttotal: 2m\tremaining: 2m 30s\n",
      "1318:\tlearn: 5437986.3786586\ttotal: 2m\tremaining: 2m 30s\n",
      "1319:\tlearn: 5436200.8581974\ttotal: 2m\tremaining: 2m 30s\n",
      "1320:\tlearn: 5433818.6134641\ttotal: 2m\tremaining: 2m 30s\n",
      "1321:\tlearn: 5432303.8440578\ttotal: 2m\tremaining: 2m 30s\n",
      "1322:\tlearn: 5429936.0835135\ttotal: 2m\tremaining: 2m 30s\n",
      "1323:\tlearn: 5427477.3113146\ttotal: 2m 1s\tremaining: 2m 30s\n",
      "1324:\tlearn: 5426261.9984182\ttotal: 2m 1s\tremaining: 2m 30s\n",
      "1325:\tlearn: 5422409.2776076\ttotal: 2m 1s\tremaining: 2m 30s\n",
      "1326:\tlearn: 5417946.3508256\ttotal: 2m 1s\tremaining: 2m 30s\n",
      "1327:\tlearn: 5416974.6642108\ttotal: 2m 1s\tremaining: 2m 30s\n",
      "1328:\tlearn: 5415260.1705267\ttotal: 2m 1s\tremaining: 2m 30s\n",
      "1329:\tlearn: 5414205.3853472\ttotal: 2m 2s\tremaining: 2m 30s\n",
      "1330:\tlearn: 5413292.7829230\ttotal: 2m 2s\tremaining: 2m 30s\n",
      "1331:\tlearn: 5411854.0077414\ttotal: 2m 2s\tremaining: 2m 30s\n",
      "1332:\tlearn: 5410752.0933556\ttotal: 2m 2s\tremaining: 2m 30s\n",
      "1333:\tlearn: 5405899.3454951\ttotal: 2m 2s\tremaining: 2m 31s\n",
      "1334:\tlearn: 5403778.3180183\ttotal: 2m 3s\tremaining: 2m 31s\n",
      "1335:\tlearn: 5402578.3696219\ttotal: 2m 3s\tremaining: 2m 31s\n",
      "1336:\tlearn: 5399512.5534513\ttotal: 2m 3s\tremaining: 2m 31s\n",
      "1337:\tlearn: 5398663.5901059\ttotal: 2m 3s\tremaining: 2m 31s\n",
      "1338:\tlearn: 5396561.6665303\ttotal: 2m 3s\tremaining: 2m 31s\n",
      "1339:\tlearn: 5394572.9605241\ttotal: 2m 3s\tremaining: 2m 31s\n",
      "1340:\tlearn: 5393381.0434203\ttotal: 2m 4s\tremaining: 2m 31s\n",
      "1341:\tlearn: 5391146.3964302\ttotal: 2m 4s\tremaining: 2m 31s\n",
      "1342:\tlearn: 5390230.2818445\ttotal: 2m 4s\tremaining: 2m 31s\n",
      "1343:\tlearn: 5389041.8384612\ttotal: 2m 4s\tremaining: 2m 31s\n",
      "1344:\tlearn: 5386385.3069674\ttotal: 2m 4s\tremaining: 2m 31s\n",
      "1345:\tlearn: 5384391.2411713\ttotal: 2m 5s\tremaining: 2m 31s\n",
      "1346:\tlearn: 5376411.3783666\ttotal: 2m 5s\tremaining: 2m 31s\n",
      "1347:\tlearn: 5374748.2678227\ttotal: 2m 5s\tremaining: 2m 31s\n",
      "1348:\tlearn: 5372682.7547217\ttotal: 2m 5s\tremaining: 2m 31s\n",
      "1349:\tlearn: 5372236.5717757\ttotal: 2m 5s\tremaining: 2m 31s\n",
      "1350:\tlearn: 5370828.3565182\ttotal: 2m 5s\tremaining: 2m 31s\n",
      "1351:\tlearn: 5369571.8376648\ttotal: 2m 5s\tremaining: 2m 31s\n",
      "1352:\tlearn: 5368084.8217259\ttotal: 2m 6s\tremaining: 2m 31s\n",
      "1353:\tlearn: 5361949.4256680\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1354:\tlearn: 5357712.1863882\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1355:\tlearn: 5356497.1699126\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1356:\tlearn: 5353728.4386092\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1357:\tlearn: 5353086.6930973\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1358:\tlearn: 5352219.1613397\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1359:\tlearn: 5351673.7982072\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1360:\tlearn: 5350250.4113315\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1361:\tlearn: 5347740.0826496\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1362:\tlearn: 5346733.3431778\ttotal: 2m 6s\tremaining: 2m 30s\n",
      "1363:\tlearn: 5344276.1696818\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1364:\tlearn: 5343100.9398087\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1365:\tlearn: 5342372.4083788\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1366:\tlearn: 5340677.7466200\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1367:\tlearn: 5339799.1851676\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1368:\tlearn: 5338396.4003823\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1369:\tlearn: 5336754.5710325\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1370:\tlearn: 5335871.3066341\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1371:\tlearn: 5323801.6435999\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1372:\tlearn: 5322401.5481171\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1373:\tlearn: 5320685.4347943\ttotal: 2m 7s\tremaining: 2m 29s\n",
      "1374:\tlearn: 5317859.7818930\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1375:\tlearn: 5316265.7812504\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1376:\tlearn: 5315190.8878010\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1377:\tlearn: 5308899.0439721\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1378:\tlearn: 5303413.2883827\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1379:\tlearn: 5301284.9754660\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1380:\tlearn: 5300241.6456453\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1381:\tlearn: 5299620.8811606\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1382:\tlearn: 5288247.9032977\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1383:\tlearn: 5286356.8151126\ttotal: 2m 8s\tremaining: 2m 28s\n",
      "1384:\tlearn: 5283779.4163583\ttotal: 2m 8s\tremaining: 2m 27s\n",
      "1385:\tlearn: 5278751.6895543\ttotal: 2m 9s\tremaining: 2m 27s\n",
      "1386:\tlearn: 5277695.5362727\ttotal: 2m 9s\tremaining: 2m 27s\n",
      "1387:\tlearn: 5275391.5333515\ttotal: 2m 9s\tremaining: 2m 27s\n",
      "1388:\tlearn: 5274576.9451347\ttotal: 2m 9s\tremaining: 2m 27s\n",
      "1389:\tlearn: 5266372.6369685\ttotal: 2m 9s\tremaining: 2m 27s\n",
      "1390:\tlearn: 5265228.7858479\ttotal: 2m 9s\tremaining: 2m 27s\n",
      "1391:\tlearn: 5263443.3439766\ttotal: 2m 9s\tremaining: 2m 27s\n",
      "1392:\tlearn: 5262462.5236479\ttotal: 2m 9s\tremaining: 2m 27s\n",
      "1393:\tlearn: 5257250.6047916\ttotal: 2m 9s\tremaining: 2m 27s\n",
      "1394:\tlearn: 5254572.3109579\ttotal: 2m 9s\tremaining: 2m 26s\n",
      "1395:\tlearn: 5253409.9258087\ttotal: 2m 9s\tremaining: 2m 26s\n",
      "1396:\tlearn: 5251779.5074228\ttotal: 2m 10s\tremaining: 2m 26s\n",
      "1397:\tlearn: 5246568.2406705\ttotal: 2m 10s\tremaining: 2m 26s\n",
      "1398:\tlearn: 5245059.7916517\ttotal: 2m 10s\tremaining: 2m 26s\n",
      "1399:\tlearn: 5234487.5843896\ttotal: 2m 10s\tremaining: 2m 26s\n",
      "1400:\tlearn: 5232184.2127118\ttotal: 2m 10s\tremaining: 2m 26s\n",
      "1401:\tlearn: 5231029.3782338\ttotal: 2m 10s\tremaining: 2m 26s\n",
      "1402:\tlearn: 5227652.6123922\ttotal: 2m 10s\tremaining: 2m 26s\n",
      "1403:\tlearn: 5222675.0191231\ttotal: 2m 10s\tremaining: 2m 26s\n",
      "1404:\tlearn: 5220549.8560891\ttotal: 2m 10s\tremaining: 2m 25s\n",
      "1405:\tlearn: 5217404.0449631\ttotal: 2m 10s\tremaining: 2m 25s\n",
      "1406:\tlearn: 5216242.3973396\ttotal: 2m 10s\tremaining: 2m 25s\n",
      "1407:\tlearn: 5215352.7815436\ttotal: 2m 11s\tremaining: 2m 25s\n",
      "1408:\tlearn: 5214347.9651761\ttotal: 2m 11s\tremaining: 2m 25s\n",
      "1409:\tlearn: 5213138.1352832\ttotal: 2m 11s\tremaining: 2m 25s\n",
      "1410:\tlearn: 5212227.9968204\ttotal: 2m 11s\tremaining: 2m 25s\n",
      "1411:\tlearn: 5209984.5211526\ttotal: 2m 11s\tremaining: 2m 25s\n",
      "1412:\tlearn: 5205252.3846352\ttotal: 2m 11s\tremaining: 2m 25s\n",
      "1413:\tlearn: 5203572.2922246\ttotal: 2m 11s\tremaining: 2m 25s\n",
      "1414:\tlearn: 5199887.1625081\ttotal: 2m 11s\tremaining: 2m 25s\n",
      "1415:\tlearn: 5197829.5525679\ttotal: 2m 11s\tremaining: 2m 25s\n",
      "1416:\tlearn: 5195679.5797688\ttotal: 2m 11s\tremaining: 2m 24s\n",
      "1417:\tlearn: 5194687.2317949\ttotal: 2m 11s\tremaining: 2m 24s\n",
      "1418:\tlearn: 5193952.6962251\ttotal: 2m 12s\tremaining: 2m 24s\n",
      "1419:\tlearn: 5191268.9315499\ttotal: 2m 12s\tremaining: 2m 24s\n",
      "1420:\tlearn: 5189147.5237347\ttotal: 2m 12s\tremaining: 2m 24s\n",
      "1421:\tlearn: 5187305.7262288\ttotal: 2m 12s\tremaining: 2m 24s\n",
      "1422:\tlearn: 5186468.3776468\ttotal: 2m 12s\tremaining: 2m 24s\n",
      "1423:\tlearn: 5183801.0318949\ttotal: 2m 12s\tremaining: 2m 24s\n",
      "1424:\tlearn: 5181032.2376575\ttotal: 2m 12s\tremaining: 2m 24s\n",
      "1425:\tlearn: 5178779.5910414\ttotal: 2m 12s\tremaining: 2m 24s\n",
      "1426:\tlearn: 5178028.0684181\ttotal: 2m 12s\tremaining: 2m 23s\n",
      "1427:\tlearn: 5176772.4784929\ttotal: 2m 12s\tremaining: 2m 23s\n",
      "1428:\tlearn: 5174120.6111336\ttotal: 2m 12s\tremaining: 2m 23s\n",
      "1429:\tlearn: 5171571.8152017\ttotal: 2m 13s\tremaining: 2m 23s\n",
      "1430:\tlearn: 5169500.2715222\ttotal: 2m 13s\tremaining: 2m 23s\n",
      "1431:\tlearn: 5168434.6743537\ttotal: 2m 13s\tremaining: 2m 23s\n",
      "1432:\tlearn: 5165184.0204708\ttotal: 2m 13s\tremaining: 2m 23s\n",
      "1433:\tlearn: 5162823.9558581\ttotal: 2m 13s\tremaining: 2m 23s\n",
      "1434:\tlearn: 5161472.3562921\ttotal: 2m 13s\tremaining: 2m 23s\n",
      "1435:\tlearn: 5160085.6642676\ttotal: 2m 13s\tremaining: 2m 23s\n",
      "1436:\tlearn: 5153533.8685908\ttotal: 2m 13s\tremaining: 2m 23s\n",
      "1437:\tlearn: 5151806.0657143\ttotal: 2m 13s\tremaining: 2m 22s\n",
      "1438:\tlearn: 5149073.6992232\ttotal: 2m 13s\tremaining: 2m 22s\n",
      "1439:\tlearn: 5147291.1681519\ttotal: 2m 14s\tremaining: 2m 22s\n",
      "1440:\tlearn: 5145907.5947039\ttotal: 2m 14s\tremaining: 2m 22s\n",
      "1441:\tlearn: 5145349.9398447\ttotal: 2m 14s\tremaining: 2m 22s\n",
      "1442:\tlearn: 5142950.1359563\ttotal: 2m 14s\tremaining: 2m 22s\n",
      "1443:\tlearn: 5142043.8518954\ttotal: 2m 14s\tremaining: 2m 22s\n",
      "1444:\tlearn: 5137003.0645336\ttotal: 2m 14s\tremaining: 2m 22s\n",
      "1445:\tlearn: 5135613.8639214\ttotal: 2m 14s\tremaining: 2m 22s\n",
      "1446:\tlearn: 5134919.5803008\ttotal: 2m 14s\tremaining: 2m 22s\n",
      "1447:\tlearn: 5133877.3408340\ttotal: 2m 14s\tremaining: 2m 22s\n",
      "1448:\tlearn: 5133030.0250664\ttotal: 2m 14s\tremaining: 2m 21s\n",
      "1449:\tlearn: 5130227.8506413\ttotal: 2m 14s\tremaining: 2m 21s\n",
      "1450:\tlearn: 5129486.9940563\ttotal: 2m 15s\tremaining: 2m 21s\n",
      "1451:\tlearn: 5128711.9949920\ttotal: 2m 15s\tremaining: 2m 21s\n",
      "1452:\tlearn: 5127838.9929988\ttotal: 2m 15s\tremaining: 2m 21s\n",
      "1453:\tlearn: 5126886.8794501\ttotal: 2m 15s\tremaining: 2m 21s\n",
      "1454:\tlearn: 5126663.7446911\ttotal: 2m 15s\tremaining: 2m 21s\n",
      "1455:\tlearn: 5125328.3126851\ttotal: 2m 15s\tremaining: 2m 21s\n",
      "1456:\tlearn: 5124241.6536438\ttotal: 2m 15s\tremaining: 2m 21s\n",
      "1457:\tlearn: 5123735.2948946\ttotal: 2m 15s\tremaining: 2m 21s\n",
      "1458:\tlearn: 5121585.8954652\ttotal: 2m 15s\tremaining: 2m 20s\n",
      "1459:\tlearn: 5119591.1517391\ttotal: 2m 15s\tremaining: 2m 20s\n",
      "1460:\tlearn: 5118736.1457667\ttotal: 2m 15s\tremaining: 2m 20s\n",
      "1461:\tlearn: 5117470.3848886\ttotal: 2m 16s\tremaining: 2m 20s\n",
      "1462:\tlearn: 5116291.6762682\ttotal: 2m 16s\tremaining: 2m 20s\n",
      "1463:\tlearn: 5114402.7151373\ttotal: 2m 16s\tremaining: 2m 20s\n",
      "1464:\tlearn: 5112605.3646709\ttotal: 2m 16s\tremaining: 2m 20s\n",
      "1465:\tlearn: 5102362.8281687\ttotal: 2m 16s\tremaining: 2m 20s\n",
      "1466:\tlearn: 5101077.1212742\ttotal: 2m 16s\tremaining: 2m 20s\n",
      "1467:\tlearn: 5099689.2910532\ttotal: 2m 16s\tremaining: 2m 20s\n",
      "1468:\tlearn: 5098952.7625684\ttotal: 2m 16s\tremaining: 2m 20s\n",
      "1469:\tlearn: 5097325.4823627\ttotal: 2m 16s\tremaining: 2m 19s\n",
      "1470:\tlearn: 5096376.9219122\ttotal: 2m 16s\tremaining: 2m 19s\n",
      "1471:\tlearn: 5091354.0496797\ttotal: 2m 16s\tremaining: 2m 19s\n",
      "1472:\tlearn: 5088521.0295326\ttotal: 2m 17s\tremaining: 2m 19s\n",
      "1473:\tlearn: 5078958.1791628\ttotal: 2m 17s\tremaining: 2m 19s\n",
      "1474:\tlearn: 5078115.3611360\ttotal: 2m 17s\tremaining: 2m 19s\n",
      "1475:\tlearn: 5076961.2424862\ttotal: 2m 17s\tremaining: 2m 19s\n",
      "1476:\tlearn: 5076187.0063750\ttotal: 2m 17s\tremaining: 2m 19s\n",
      "1477:\tlearn: 5074569.1961871\ttotal: 2m 17s\tremaining: 2m 19s\n",
      "1478:\tlearn: 5071538.1774603\ttotal: 2m 17s\tremaining: 2m 19s\n",
      "1479:\tlearn: 5069722.3763559\ttotal: 2m 17s\tremaining: 2m 18s\n",
      "1480:\tlearn: 5060125.8856766\ttotal: 2m 17s\tremaining: 2m 18s\n",
      "1481:\tlearn: 5058765.6086359\ttotal: 2m 17s\tremaining: 2m 18s\n",
      "1482:\tlearn: 5051374.5138401\ttotal: 2m 17s\tremaining: 2m 18s\n",
      "1483:\tlearn: 5050769.0583091\ttotal: 2m 18s\tremaining: 2m 18s\n",
      "1484:\tlearn: 5049613.3972868\ttotal: 2m 18s\tremaining: 2m 18s\n",
      "1485:\tlearn: 5047039.7411333\ttotal: 2m 18s\tremaining: 2m 18s\n",
      "1486:\tlearn: 5044947.7576643\ttotal: 2m 18s\tremaining: 2m 18s\n",
      "1487:\tlearn: 5043207.7986810\ttotal: 2m 18s\tremaining: 2m 18s\n",
      "1488:\tlearn: 5042316.8958212\ttotal: 2m 18s\tremaining: 2m 18s\n",
      "1489:\tlearn: 5040509.0551967\ttotal: 2m 18s\tremaining: 2m 18s\n",
      "1490:\tlearn: 5038200.7941813\ttotal: 2m 18s\tremaining: 2m 17s\n",
      "1491:\tlearn: 5036616.7544848\ttotal: 2m 18s\tremaining: 2m 17s\n",
      "1492:\tlearn: 5034668.1774791\ttotal: 2m 18s\tremaining: 2m 17s\n",
      "1493:\tlearn: 5027698.1382575\ttotal: 2m 18s\tremaining: 2m 17s\n",
      "1494:\tlearn: 5026574.9829726\ttotal: 2m 19s\tremaining: 2m 17s\n",
      "1495:\tlearn: 5025236.1661782\ttotal: 2m 19s\tremaining: 2m 17s\n",
      "1496:\tlearn: 5022612.0986646\ttotal: 2m 19s\tremaining: 2m 17s\n",
      "1497:\tlearn: 5021066.0282121\ttotal: 2m 19s\tremaining: 2m 17s\n",
      "1498:\tlearn: 5020374.8359547\ttotal: 2m 19s\tremaining: 2m 17s\n",
      "1499:\tlearn: 5018149.1199942\ttotal: 2m 19s\tremaining: 2m 17s\n",
      "1500:\tlearn: 5017018.7574051\ttotal: 2m 19s\tremaining: 2m 16s\n",
      "1501:\tlearn: 5016249.3384594\ttotal: 2m 19s\tremaining: 2m 16s\n",
      "1502:\tlearn: 5015159.5363011\ttotal: 2m 19s\tremaining: 2m 16s\n",
      "1503:\tlearn: 5013319.4220579\ttotal: 2m 19s\tremaining: 2m 16s\n",
      "1504:\tlearn: 5011819.6677002\ttotal: 2m 19s\tremaining: 2m 16s\n",
      "1505:\tlearn: 5009557.1298057\ttotal: 2m 19s\tremaining: 2m 16s\n",
      "1506:\tlearn: 5009125.7106611\ttotal: 2m 20s\tremaining: 2m 16s\n",
      "1507:\tlearn: 5006117.8502361\ttotal: 2m 20s\tremaining: 2m 16s\n",
      "1508:\tlearn: 5004969.1473980\ttotal: 2m 20s\tremaining: 2m 16s\n",
      "1509:\tlearn: 5002859.9505323\ttotal: 2m 20s\tremaining: 2m 16s\n",
      "1510:\tlearn: 5001635.3400499\ttotal: 2m 20s\tremaining: 2m 15s\n",
      "1511:\tlearn: 4996417.5243359\ttotal: 2m 20s\tremaining: 2m 15s\n",
      "1512:\tlearn: 4995524.4256281\ttotal: 2m 20s\tremaining: 2m 15s\n",
      "1513:\tlearn: 4994104.2983343\ttotal: 2m 20s\tremaining: 2m 15s\n",
      "1514:\tlearn: 4992956.5850715\ttotal: 2m 20s\tremaining: 2m 15s\n",
      "1515:\tlearn: 4990826.9099545\ttotal: 2m 20s\tremaining: 2m 15s\n",
      "1516:\tlearn: 4990235.8752654\ttotal: 2m 20s\tremaining: 2m 15s\n",
      "1517:\tlearn: 4985179.5196601\ttotal: 2m 21s\tremaining: 2m 15s\n",
      "1518:\tlearn: 4983500.6154987\ttotal: 2m 21s\tremaining: 2m 15s\n",
      "1519:\tlearn: 4974416.3032731\ttotal: 2m 21s\tremaining: 2m 15s\n",
      "1520:\tlearn: 4972639.0558853\ttotal: 2m 21s\tremaining: 2m 14s\n",
      "1521:\tlearn: 4971569.4969034\ttotal: 2m 21s\tremaining: 2m 14s\n",
      "1522:\tlearn: 4969881.7755758\ttotal: 2m 21s\tremaining: 2m 14s\n",
      "1523:\tlearn: 4969147.5412167\ttotal: 2m 21s\tremaining: 2m 14s\n",
      "1524:\tlearn: 4965813.4112210\ttotal: 2m 21s\tremaining: 2m 14s\n",
      "1525:\tlearn: 4963653.4913214\ttotal: 2m 21s\tremaining: 2m 14s\n",
      "1526:\tlearn: 4961921.9122087\ttotal: 2m 21s\tremaining: 2m 14s\n",
      "1527:\tlearn: 4960893.2555442\ttotal: 2m 21s\tremaining: 2m 14s\n",
      "1528:\tlearn: 4959399.5768620\ttotal: 2m 22s\tremaining: 2m 14s\n",
      "1529:\tlearn: 4958454.6115657\ttotal: 2m 22s\tremaining: 2m 14s\n",
      "1530:\tlearn: 4957143.9649012\ttotal: 2m 22s\tremaining: 2m 14s\n",
      "1531:\tlearn: 4955378.6236689\ttotal: 2m 22s\tremaining: 2m 13s\n",
      "1532:\tlearn: 4953549.2545556\ttotal: 2m 22s\tremaining: 2m 13s\n",
      "1533:\tlearn: 4952825.5826954\ttotal: 2m 22s\tremaining: 2m 13s\n",
      "1534:\tlearn: 4947062.4636771\ttotal: 2m 22s\tremaining: 2m 13s\n",
      "1535:\tlearn: 4946112.6348241\ttotal: 2m 22s\tremaining: 2m 13s\n",
      "1536:\tlearn: 4945584.2321006\ttotal: 2m 22s\tremaining: 2m 13s\n",
      "1537:\tlearn: 4945061.4828607\ttotal: 2m 22s\tremaining: 2m 13s\n",
      "1538:\tlearn: 4943329.2146570\ttotal: 2m 22s\tremaining: 2m 13s\n",
      "1539:\tlearn: 4939931.0264319\ttotal: 2m 23s\tremaining: 2m 13s\n",
      "1540:\tlearn: 4938103.0515265\ttotal: 2m 23s\tremaining: 2m 13s\n",
      "1541:\tlearn: 4937260.9220967\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1542:\tlearn: 4936345.0407133\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1543:\tlearn: 4934567.6569076\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1544:\tlearn: 4933127.0029167\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1545:\tlearn: 4932059.0197846\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1546:\tlearn: 4930175.9977267\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1547:\tlearn: 4928748.7399996\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1548:\tlearn: 4926010.6634099\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1549:\tlearn: 4925393.4858973\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1550:\tlearn: 4924316.8894725\ttotal: 2m 23s\tremaining: 2m 12s\n",
      "1551:\tlearn: 4922772.7606447\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1552:\tlearn: 4922214.7419402\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1553:\tlearn: 4921555.3440488\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1554:\tlearn: 4912711.5801162\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1555:\tlearn: 4906196.6994960\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1556:\tlearn: 4903253.0399126\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1557:\tlearn: 4902303.7219668\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1558:\tlearn: 4894378.4959901\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1559:\tlearn: 4893881.2569810\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1560:\tlearn: 4889628.4020240\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1561:\tlearn: 4888179.2830942\ttotal: 2m 24s\tremaining: 2m 11s\n",
      "1562:\tlearn: 4886381.5754598\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1563:\tlearn: 4883953.3155816\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1564:\tlearn: 4882873.8920630\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1565:\tlearn: 4881291.7559463\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1566:\tlearn: 4876387.8154376\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1567:\tlearn: 4875772.4559207\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1568:\tlearn: 4873845.2547047\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1569:\tlearn: 4865713.5305048\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1570:\tlearn: 4863954.1785239\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1571:\tlearn: 4863442.6371410\ttotal: 2m 25s\tremaining: 2m 10s\n",
      "1572:\tlearn: 4862216.7171704\ttotal: 2m 25s\tremaining: 2m 9s\n",
      "1573:\tlearn: 4859863.3590288\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1574:\tlearn: 4858412.8467541\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1575:\tlearn: 4857025.4131558\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1576:\tlearn: 4855882.0818397\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1577:\tlearn: 4846364.8947678\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1578:\tlearn: 4844154.5299524\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1579:\tlearn: 4841649.7542287\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1580:\tlearn: 4840343.2250091\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1581:\tlearn: 4839384.3430589\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1582:\tlearn: 4837849.2889565\ttotal: 2m 26s\tremaining: 2m 9s\n",
      "1583:\tlearn: 4837073.6038090\ttotal: 2m 26s\tremaining: 2m 8s\n",
      "1584:\tlearn: 4835933.5277715\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1585:\tlearn: 4833493.4205188\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1586:\tlearn: 4830786.3443926\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1587:\tlearn: 4830130.7787665\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1588:\tlearn: 4827456.9700043\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1589:\tlearn: 4821743.4521767\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1590:\tlearn: 4820023.9652400\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1591:\tlearn: 4819068.1892808\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1592:\tlearn: 4818455.3548800\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1593:\tlearn: 4817640.3243386\ttotal: 2m 27s\tremaining: 2m 8s\n",
      "1594:\tlearn: 4816985.8078162\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1595:\tlearn: 4816474.7250846\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1596:\tlearn: 4815215.1386476\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1597:\tlearn: 4813066.2504697\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1598:\tlearn: 4812430.5413302\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1599:\tlearn: 4810532.1014029\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1600:\tlearn: 4809056.0781252\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1601:\tlearn: 4808723.3178398\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1602:\tlearn: 4804009.5493725\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1603:\tlearn: 4802245.5971275\ttotal: 2m 28s\tremaining: 2m 7s\n",
      "1604:\tlearn: 4801375.8854687\ttotal: 2m 28s\tremaining: 2m 6s\n",
      "1605:\tlearn: 4801137.5748888\ttotal: 2m 28s\tremaining: 2m 6s\n",
      "1606:\tlearn: 4800321.7353222\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "1607:\tlearn: 4799143.1861296\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "1608:\tlearn: 4797344.8235068\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "1609:\tlearn: 4796303.2733531\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "1610:\tlearn: 4795352.3581949\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "1611:\tlearn: 4794640.9668980\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "1612:\tlearn: 4793727.3301131\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "1613:\tlearn: 4793281.4754407\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "1614:\tlearn: 4792389.1619788\ttotal: 2m 29s\tremaining: 2m 6s\n",
      "1615:\tlearn: 4791123.6804625\ttotal: 2m 29s\tremaining: 2m 5s\n",
      "1616:\tlearn: 4790219.6067481\ttotal: 2m 29s\tremaining: 2m 5s\n",
      "1617:\tlearn: 4789466.9836825\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "1618:\tlearn: 4788327.7194018\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "1619:\tlearn: 4787252.9296054\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "1620:\tlearn: 4786508.7623286\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "1621:\tlearn: 4785543.8401895\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "1622:\tlearn: 4781416.7580113\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "1623:\tlearn: 4778995.9634585\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "1624:\tlearn: 4777516.5630896\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "1625:\tlearn: 4776364.6586026\ttotal: 2m 30s\tremaining: 2m 5s\n",
      "1626:\tlearn: 4775520.8288774\ttotal: 2m 30s\tremaining: 2m 4s\n",
      "1627:\tlearn: 4774555.5008947\ttotal: 2m 30s\tremaining: 2m 4s\n",
      "1628:\tlearn: 4772910.5773358\ttotal: 2m 31s\tremaining: 2m 4s\n",
      "1629:\tlearn: 4771357.5799551\ttotal: 2m 31s\tremaining: 2m 4s\n",
      "1630:\tlearn: 4770870.1504395\ttotal: 2m 31s\tremaining: 2m 4s\n",
      "1631:\tlearn: 4770031.0429135\ttotal: 2m 31s\tremaining: 2m 4s\n",
      "1632:\tlearn: 4769004.8671931\ttotal: 2m 31s\tremaining: 2m 4s\n",
      "1633:\tlearn: 4768252.0744494\ttotal: 2m 31s\tremaining: 2m 4s\n",
      "1634:\tlearn: 4758126.6298398\ttotal: 2m 31s\tremaining: 2m 4s\n",
      "1635:\tlearn: 4757192.5285836\ttotal: 2m 31s\tremaining: 2m 4s\n",
      "1636:\tlearn: 4755495.5142071\ttotal: 2m 31s\tremaining: 2m 3s\n",
      "1637:\tlearn: 4754075.1557401\ttotal: 2m 31s\tremaining: 2m 3s\n",
      "1638:\tlearn: 4753720.4755179\ttotal: 2m 31s\tremaining: 2m 3s\n",
      "1639:\tlearn: 4753200.2234491\ttotal: 2m 32s\tremaining: 2m 3s\n",
      "1640:\tlearn: 4752056.5303654\ttotal: 2m 32s\tremaining: 2m 3s\n",
      "1641:\tlearn: 4751715.7844126\ttotal: 2m 32s\tremaining: 2m 3s\n",
      "1642:\tlearn: 4750536.7282271\ttotal: 2m 32s\tremaining: 2m 3s\n",
      "1643:\tlearn: 4747850.3072012\ttotal: 2m 32s\tremaining: 2m 3s\n",
      "1644:\tlearn: 4746283.0502523\ttotal: 2m 32s\tremaining: 2m 3s\n",
      "1645:\tlearn: 4744194.9717548\ttotal: 2m 32s\tremaining: 2m 3s\n",
      "1646:\tlearn: 4741974.9317607\ttotal: 2m 32s\tremaining: 2m 3s\n",
      "1647:\tlearn: 4740899.5946700\ttotal: 2m 32s\tremaining: 2m 2s\n",
      "1648:\tlearn: 4740133.0406247\ttotal: 2m 32s\tremaining: 2m 2s\n",
      "1649:\tlearn: 4739154.0816505\ttotal: 2m 32s\tremaining: 2m 2s\n",
      "1650:\tlearn: 4738078.6022753\ttotal: 2m 33s\tremaining: 2m 2s\n",
      "1651:\tlearn: 4737263.6920225\ttotal: 2m 33s\tremaining: 2m 2s\n",
      "1652:\tlearn: 4734874.0643974\ttotal: 2m 33s\tremaining: 2m 2s\n",
      "1653:\tlearn: 4733615.4719422\ttotal: 2m 33s\tremaining: 2m 2s\n",
      "1654:\tlearn: 4732293.0859218\ttotal: 2m 33s\tremaining: 2m 2s\n",
      "1655:\tlearn: 4730009.8528108\ttotal: 2m 33s\tremaining: 2m 2s\n",
      "1656:\tlearn: 4727276.8102689\ttotal: 2m 33s\tremaining: 2m 2s\n",
      "1657:\tlearn: 4726602.8523715\ttotal: 2m 33s\tremaining: 2m 1s\n",
      "1658:\tlearn: 4724465.5785693\ttotal: 2m 33s\tremaining: 2m 1s\n",
      "1659:\tlearn: 4722590.1897436\ttotal: 2m 33s\tremaining: 2m 1s\n",
      "1660:\tlearn: 4721692.6808614\ttotal: 2m 33s\tremaining: 2m 1s\n",
      "1661:\tlearn: 4721065.4845371\ttotal: 2m 34s\tremaining: 2m 1s\n",
      "1662:\tlearn: 4720046.4045982\ttotal: 2m 34s\tremaining: 2m 1s\n",
      "1663:\tlearn: 4717921.6372361\ttotal: 2m 34s\tremaining: 2m 1s\n",
      "1664:\tlearn: 4716636.3371269\ttotal: 2m 34s\tremaining: 2m 1s\n",
      "1665:\tlearn: 4715715.5202823\ttotal: 2m 34s\tremaining: 2m 1s\n",
      "1666:\tlearn: 4714964.7144268\ttotal: 2m 34s\tremaining: 2m 1s\n",
      "1667:\tlearn: 4712790.7559121\ttotal: 2m 34s\tremaining: 2m 1s\n",
      "1668:\tlearn: 4711277.8781829\ttotal: 2m 34s\tremaining: 2m\n",
      "1669:\tlearn: 4708730.2438270\ttotal: 2m 34s\tremaining: 2m\n",
      "1670:\tlearn: 4707520.9818771\ttotal: 2m 34s\tremaining: 2m\n",
      "1671:\tlearn: 4706649.0363984\ttotal: 2m 34s\tremaining: 2m\n",
      "1672:\tlearn: 4704722.2810495\ttotal: 2m 34s\tremaining: 2m\n",
      "1673:\tlearn: 4703396.4168865\ttotal: 2m 35s\tremaining: 2m\n",
      "1674:\tlearn: 4702705.7700068\ttotal: 2m 35s\tremaining: 2m\n",
      "1675:\tlearn: 4701885.7296607\ttotal: 2m 35s\tremaining: 2m\n",
      "1676:\tlearn: 4699372.1646652\ttotal: 2m 35s\tremaining: 2m\n",
      "1677:\tlearn: 4692769.5850183\ttotal: 2m 35s\tremaining: 2m\n",
      "1678:\tlearn: 4691613.2908831\ttotal: 2m 35s\tremaining: 1m 59s\n",
      "1679:\tlearn: 4690772.0319857\ttotal: 2m 35s\tremaining: 1m 59s\n",
      "1680:\tlearn: 4690442.9922931\ttotal: 2m 35s\tremaining: 1m 59s\n",
      "1681:\tlearn: 4689300.1551827\ttotal: 2m 35s\tremaining: 1m 59s\n",
      "1682:\tlearn: 4685780.3573366\ttotal: 2m 35s\tremaining: 1m 59s\n",
      "1683:\tlearn: 4685308.1811264\ttotal: 2m 35s\tremaining: 1m 59s\n",
      "1684:\tlearn: 4676825.0088091\ttotal: 2m 35s\tremaining: 1m 59s\n",
      "1685:\tlearn: 4675438.8028735\ttotal: 2m 36s\tremaining: 1m 59s\n",
      "1686:\tlearn: 4674619.3733081\ttotal: 2m 36s\tremaining: 1m 59s\n",
      "1687:\tlearn: 4673367.0366075\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1688:\tlearn: 4671759.3979563\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1689:\tlearn: 4666229.9614946\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1690:\tlearn: 4661131.8947454\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1691:\tlearn: 4659766.6810906\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1692:\tlearn: 4658223.2314032\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1693:\tlearn: 4655242.1881970\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1694:\tlearn: 4654043.1268239\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1695:\tlearn: 4648743.3632835\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1696:\tlearn: 4647299.5594113\ttotal: 2m 36s\tremaining: 1m 58s\n",
      "1697:\tlearn: 4646653.8927260\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1698:\tlearn: 4645323.3377438\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1699:\tlearn: 4642800.2123981\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1700:\tlearn: 4640198.4809256\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1701:\tlearn: 4630434.7184324\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1702:\tlearn: 4629783.6499828\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1703:\tlearn: 4621389.6205038\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1704:\tlearn: 4620798.0086025\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1705:\tlearn: 4617317.4483082\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1706:\tlearn: 4616639.9227493\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1707:\tlearn: 4614929.9315296\ttotal: 2m 37s\tremaining: 1m 57s\n",
      "1708:\tlearn: 4614521.3671251\ttotal: 2m 37s\tremaining: 1m 56s\n",
      "1709:\tlearn: 4613600.7841296\ttotal: 2m 38s\tremaining: 1m 56s\n",
      "1710:\tlearn: 4612607.4853105\ttotal: 2m 38s\tremaining: 1m 56s\n",
      "1711:\tlearn: 4604698.5430717\ttotal: 2m 38s\tremaining: 1m 56s\n",
      "1712:\tlearn: 4603208.0870566\ttotal: 2m 38s\tremaining: 1m 56s\n",
      "1713:\tlearn: 4602761.1515798\ttotal: 2m 38s\tremaining: 1m 56s\n",
      "1714:\tlearn: 4601525.2773551\ttotal: 2m 38s\tremaining: 1m 56s\n",
      "1715:\tlearn: 4599949.3035983\ttotal: 2m 38s\tremaining: 1m 56s\n",
      "1716:\tlearn: 4595128.2321606\ttotal: 2m 38s\tremaining: 1m 56s\n",
      "1717:\tlearn: 4592969.8036854\ttotal: 2m 38s\tremaining: 1m 56s\n",
      "1718:\tlearn: 4590265.6496412\ttotal: 2m 38s\tremaining: 1m 55s\n",
      "1719:\tlearn: 4588599.7904608\ttotal: 2m 38s\tremaining: 1m 55s\n",
      "1720:\tlearn: 4587969.5669740\ttotal: 2m 38s\tremaining: 1m 55s\n",
      "1721:\tlearn: 4586972.8235174\ttotal: 2m 39s\tremaining: 1m 55s\n",
      "1722:\tlearn: 4581257.0052701\ttotal: 2m 39s\tremaining: 1m 55s\n",
      "1723:\tlearn: 4578789.1689225\ttotal: 2m 39s\tremaining: 1m 55s\n",
      "1724:\tlearn: 4569705.1118517\ttotal: 2m 39s\tremaining: 1m 55s\n",
      "1725:\tlearn: 4568719.1497834\ttotal: 2m 39s\tremaining: 1m 55s\n",
      "1726:\tlearn: 4567179.8061717\ttotal: 2m 39s\tremaining: 1m 55s\n",
      "1727:\tlearn: 4564973.8377368\ttotal: 2m 39s\tremaining: 1m 55s\n",
      "1728:\tlearn: 4563865.7641968\ttotal: 2m 39s\tremaining: 1m 54s\n",
      "1729:\tlearn: 4563240.8236860\ttotal: 2m 39s\tremaining: 1m 54s\n",
      "1730:\tlearn: 4555360.2152675\ttotal: 2m 39s\tremaining: 1m 54s\n",
      "1731:\tlearn: 4553247.3808046\ttotal: 2m 39s\tremaining: 1m 54s\n",
      "1732:\tlearn: 4552162.5367934\ttotal: 2m 40s\tremaining: 1m 54s\n",
      "1733:\tlearn: 4548581.5358904\ttotal: 2m 40s\tremaining: 1m 54s\n",
      "1734:\tlearn: 4548188.0520468\ttotal: 2m 40s\tremaining: 1m 54s\n",
      "1735:\tlearn: 4546213.5137367\ttotal: 2m 40s\tremaining: 1m 54s\n",
      "1736:\tlearn: 4544947.0773543\ttotal: 2m 40s\tremaining: 1m 54s\n",
      "1737:\tlearn: 4544038.1680941\ttotal: 2m 40s\tremaining: 1m 54s\n",
      "1738:\tlearn: 4543209.9210075\ttotal: 2m 40s\tremaining: 1m 54s\n",
      "1739:\tlearn: 4542228.2928125\ttotal: 2m 40s\tremaining: 1m 53s\n",
      "1740:\tlearn: 4540800.3166173\ttotal: 2m 40s\tremaining: 1m 53s\n",
      "1741:\tlearn: 4539736.4592005\ttotal: 2m 40s\tremaining: 1m 53s\n",
      "1742:\tlearn: 4538404.4011353\ttotal: 2m 40s\tremaining: 1m 53s\n",
      "1743:\tlearn: 4536037.1881140\ttotal: 2m 41s\tremaining: 1m 53s\n",
      "1744:\tlearn: 4535420.1157509\ttotal: 2m 41s\tremaining: 1m 53s\n",
      "1745:\tlearn: 4534751.4594416\ttotal: 2m 41s\tremaining: 1m 53s\n",
      "1746:\tlearn: 4534362.1319459\ttotal: 2m 41s\tremaining: 1m 53s\n",
      "1747:\tlearn: 4532801.3839645\ttotal: 2m 41s\tremaining: 1m 53s\n",
      "1748:\tlearn: 4531939.4069297\ttotal: 2m 41s\tremaining: 1m 53s\n",
      "1749:\tlearn: 4531557.5541762\ttotal: 2m 41s\tremaining: 1m 53s\n",
      "1750:\tlearn: 4529442.3271832\ttotal: 2m 41s\tremaining: 1m 52s\n",
      "1751:\tlearn: 4528690.2360393\ttotal: 2m 41s\tremaining: 1m 52s\n",
      "1752:\tlearn: 4525531.6430294\ttotal: 2m 41s\tremaining: 1m 52s\n",
      "1753:\tlearn: 4523711.0517666\ttotal: 2m 41s\tremaining: 1m 52s\n",
      "1754:\tlearn: 4522444.9667896\ttotal: 2m 42s\tremaining: 1m 52s\n",
      "1755:\tlearn: 4520566.0807386\ttotal: 2m 42s\tremaining: 1m 52s\n",
      "1756:\tlearn: 4519200.8221062\ttotal: 2m 42s\tremaining: 1m 52s\n",
      "1757:\tlearn: 4518866.4056922\ttotal: 2m 42s\tremaining: 1m 52s\n",
      "1758:\tlearn: 4517492.8391931\ttotal: 2m 42s\tremaining: 1m 52s\n",
      "1759:\tlearn: 4515963.5383131\ttotal: 2m 42s\tremaining: 1m 52s\n",
      "1760:\tlearn: 4514081.3585123\ttotal: 2m 42s\tremaining: 1m 51s\n",
      "1761:\tlearn: 4509062.8261905\ttotal: 2m 42s\tremaining: 1m 51s\n",
      "1762:\tlearn: 4508815.9236172\ttotal: 2m 42s\tremaining: 1m 51s\n",
      "1763:\tlearn: 4508098.0548123\ttotal: 2m 42s\tremaining: 1m 51s\n",
      "1764:\tlearn: 4507186.8231990\ttotal: 2m 42s\tremaining: 1m 51s\n",
      "1765:\tlearn: 4504065.1736844\ttotal: 2m 43s\tremaining: 1m 51s\n",
      "1766:\tlearn: 4502278.1149912\ttotal: 2m 43s\tremaining: 1m 51s\n",
      "1767:\tlearn: 4501204.1606173\ttotal: 2m 43s\tremaining: 1m 51s\n",
      "1768:\tlearn: 4500426.0029319\ttotal: 2m 43s\tremaining: 1m 51s\n",
      "1769:\tlearn: 4499611.4171943\ttotal: 2m 43s\tremaining: 1m 51s\n",
      "1770:\tlearn: 4498266.5625097\ttotal: 2m 43s\tremaining: 1m 51s\n",
      "1771:\tlearn: 4495406.7853820\ttotal: 2m 43s\tremaining: 1m 50s\n",
      "1772:\tlearn: 4494616.6465506\ttotal: 2m 43s\tremaining: 1m 50s\n",
      "1773:\tlearn: 4493148.8271738\ttotal: 2m 43s\tremaining: 1m 50s\n",
      "1774:\tlearn: 4491773.3968952\ttotal: 2m 43s\tremaining: 1m 50s\n",
      "1775:\tlearn: 4491225.6478521\ttotal: 2m 43s\tremaining: 1m 50s\n",
      "1776:\tlearn: 4486473.3805376\ttotal: 2m 43s\tremaining: 1m 50s\n",
      "1777:\tlearn: 4486065.3960426\ttotal: 2m 44s\tremaining: 1m 50s\n",
      "1778:\tlearn: 4485438.7092452\ttotal: 2m 44s\tremaining: 1m 50s\n",
      "1779:\tlearn: 4483446.3474750\ttotal: 2m 44s\tremaining: 1m 50s\n",
      "1780:\tlearn: 4482773.1099009\ttotal: 2m 44s\tremaining: 1m 50s\n",
      "1781:\tlearn: 4481619.7893838\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "1782:\tlearn: 4480378.8214661\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "1783:\tlearn: 4479309.7615823\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "1784:\tlearn: 4477948.6945703\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "1785:\tlearn: 4476857.6665980\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "1786:\tlearn: 4476200.0317087\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "1787:\tlearn: 4475610.8118588\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "1788:\tlearn: 4474290.0071015\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "1789:\tlearn: 4472524.7667285\ttotal: 2m 45s\tremaining: 1m 49s\n",
      "1790:\tlearn: 4471874.2439520\ttotal: 2m 45s\tremaining: 1m 49s\n",
      "1791:\tlearn: 4471071.7866109\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1792:\tlearn: 4470230.9685727\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1793:\tlearn: 4467936.9670127\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1794:\tlearn: 4466972.7643279\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1795:\tlearn: 4466565.6164883\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1796:\tlearn: 4464925.8307004\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1797:\tlearn: 4464524.6577542\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1798:\tlearn: 4463710.3078190\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1799:\tlearn: 4460844.2390188\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1800:\tlearn: 4459664.6462618\ttotal: 2m 45s\tremaining: 1m 48s\n",
      "1801:\tlearn: 4458441.0746541\ttotal: 2m 46s\tremaining: 1m 48s\n",
      "1802:\tlearn: 4453889.6200716\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1803:\tlearn: 4453277.5850678\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1804:\tlearn: 4451282.6693367\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1805:\tlearn: 4449986.2483955\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1806:\tlearn: 4448805.2217274\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1807:\tlearn: 4448400.4099633\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1808:\tlearn: 4446932.9217010\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1809:\tlearn: 4446509.4309010\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1810:\tlearn: 4441849.8249893\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1811:\tlearn: 4441014.4264487\ttotal: 2m 46s\tremaining: 1m 47s\n",
      "1812:\tlearn: 4439690.8648122\ttotal: 2m 46s\tremaining: 1m 46s\n",
      "1813:\tlearn: 4438336.8741067\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "1814:\tlearn: 4435340.1476282\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "1815:\tlearn: 4430934.0760291\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "1816:\tlearn: 4429499.1124180\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "1817:\tlearn: 4428496.8833839\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "1818:\tlearn: 4426529.9502050\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "1819:\tlearn: 4423363.0669523\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "1820:\tlearn: 4420733.6020327\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "1821:\tlearn: 4419885.7194765\ttotal: 2m 47s\tremaining: 1m 46s\n",
      "1822:\tlearn: 4415725.5192089\ttotal: 2m 47s\tremaining: 1m 45s\n",
      "1823:\tlearn: 4414703.2404279\ttotal: 2m 47s\tremaining: 1m 45s\n",
      "1824:\tlearn: 4414269.5599722\ttotal: 2m 47s\tremaining: 1m 45s\n",
      "1825:\tlearn: 4413130.3045285\ttotal: 2m 48s\tremaining: 1m 45s\n",
      "1826:\tlearn: 4412410.8171839\ttotal: 2m 48s\tremaining: 1m 45s\n",
      "1827:\tlearn: 4411264.0030378\ttotal: 2m 48s\tremaining: 1m 45s\n",
      "1828:\tlearn: 4410587.5292932\ttotal: 2m 48s\tremaining: 1m 45s\n",
      "1829:\tlearn: 4409542.6444996\ttotal: 2m 48s\tremaining: 1m 45s\n",
      "1830:\tlearn: 4408421.4377941\ttotal: 2m 48s\tremaining: 1m 45s\n",
      "1831:\tlearn: 4408079.3869240\ttotal: 2m 48s\tremaining: 1m 45s\n",
      "1832:\tlearn: 4404103.2005911\ttotal: 2m 48s\tremaining: 1m 44s\n",
      "1833:\tlearn: 4402368.1907124\ttotal: 2m 48s\tremaining: 1m 44s\n",
      "1834:\tlearn: 4401603.5947095\ttotal: 2m 48s\tremaining: 1m 44s\n",
      "1835:\tlearn: 4400955.8232566\ttotal: 2m 48s\tremaining: 1m 44s\n",
      "1836:\tlearn: 4397532.7196984\ttotal: 2m 48s\tremaining: 1m 44s\n",
      "1837:\tlearn: 4396580.5895641\ttotal: 2m 49s\tremaining: 1m 44s\n",
      "1838:\tlearn: 4395875.2679053\ttotal: 2m 49s\tremaining: 1m 44s\n",
      "1839:\tlearn: 4394978.7511198\ttotal: 2m 49s\tremaining: 1m 44s\n",
      "1840:\tlearn: 4394554.2571607\ttotal: 2m 49s\tremaining: 1m 44s\n",
      "1841:\tlearn: 4394073.1925853\ttotal: 2m 49s\tremaining: 1m 44s\n",
      "1842:\tlearn: 4392316.3142493\ttotal: 2m 49s\tremaining: 1m 43s\n",
      "1843:\tlearn: 4390940.6046244\ttotal: 2m 49s\tremaining: 1m 43s\n",
      "1844:\tlearn: 4390333.6084126\ttotal: 2m 49s\tremaining: 1m 43s\n",
      "1845:\tlearn: 4389313.7333448\ttotal: 2m 49s\tremaining: 1m 43s\n",
      "1846:\tlearn: 4388735.2711344\ttotal: 2m 49s\tremaining: 1m 43s\n",
      "1847:\tlearn: 4388098.0224508\ttotal: 2m 49s\tremaining: 1m 43s\n",
      "1848:\tlearn: 4385992.7043925\ttotal: 2m 49s\tremaining: 1m 43s\n",
      "1849:\tlearn: 4385162.1052665\ttotal: 2m 50s\tremaining: 1m 43s\n",
      "1850:\tlearn: 4383976.5798939\ttotal: 2m 50s\tremaining: 1m 43s\n",
      "1851:\tlearn: 4381503.0572437\ttotal: 2m 50s\tremaining: 1m 43s\n",
      "1852:\tlearn: 4381031.5237611\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1853:\tlearn: 4380130.4334466\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1854:\tlearn: 4379209.6312508\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1855:\tlearn: 4377132.2436577\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1856:\tlearn: 4376356.4326875\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1857:\tlearn: 4376011.8169197\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1858:\tlearn: 4372613.6136797\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1859:\tlearn: 4371176.9967215\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1860:\tlearn: 4371022.9915721\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1861:\tlearn: 4370217.0854228\ttotal: 2m 50s\tremaining: 1m 42s\n",
      "1862:\tlearn: 4368471.5188019\ttotal: 2m 51s\tremaining: 1m 42s\n",
      "1863:\tlearn: 4367957.3449128\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1864:\tlearn: 4367170.6245566\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1865:\tlearn: 4365184.2002693\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1866:\tlearn: 4364292.1239258\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1867:\tlearn: 4362317.4848862\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1868:\tlearn: 4361651.9138240\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1869:\tlearn: 4361174.1771455\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1870:\tlearn: 4360557.1479518\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1871:\tlearn: 4360203.7688627\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1872:\tlearn: 4359534.6533691\ttotal: 2m 51s\tremaining: 1m 41s\n",
      "1873:\tlearn: 4358925.3039416\ttotal: 2m 51s\tremaining: 1m 40s\n",
      "1874:\tlearn: 4357976.9003288\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "1875:\tlearn: 4357249.4035619\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "1876:\tlearn: 4352916.6913583\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "1877:\tlearn: 4352156.5385362\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "1878:\tlearn: 4348932.9649101\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "1879:\tlearn: 4348587.6449942\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "1880:\tlearn: 4347801.9044357\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "1881:\tlearn: 4346617.5168419\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "1882:\tlearn: 4345826.5965849\ttotal: 2m 52s\tremaining: 1m 40s\n",
      "1883:\tlearn: 4344739.1763163\ttotal: 2m 52s\tremaining: 1m 39s\n",
      "1884:\tlearn: 4343672.0060216\ttotal: 2m 52s\tremaining: 1m 39s\n",
      "1885:\tlearn: 4342872.5855581\ttotal: 2m 52s\tremaining: 1m 39s\n",
      "1886:\tlearn: 4342077.1341903\ttotal: 2m 52s\tremaining: 1m 39s\n",
      "1887:\tlearn: 4340473.8791369\ttotal: 2m 53s\tremaining: 1m 39s\n",
      "1888:\tlearn: 4338606.6702321\ttotal: 2m 53s\tremaining: 1m 39s\n",
      "1889:\tlearn: 4337655.0398346\ttotal: 2m 53s\tremaining: 1m 39s\n",
      "1890:\tlearn: 4336565.5650036\ttotal: 2m 53s\tremaining: 1m 39s\n",
      "1891:\tlearn: 4335650.9934244\ttotal: 2m 53s\tremaining: 1m 39s\n",
      "1892:\tlearn: 4334888.1940248\ttotal: 2m 53s\tremaining: 1m 39s\n",
      "1893:\tlearn: 4333509.0132004\ttotal: 2m 53s\tremaining: 1m 38s\n",
      "1894:\tlearn: 4333231.6752676\ttotal: 2m 53s\tremaining: 1m 38s\n",
      "1895:\tlearn: 4332212.0722032\ttotal: 2m 53s\tremaining: 1m 38s\n",
      "1896:\tlearn: 4331566.1892762\ttotal: 2m 53s\tremaining: 1m 38s\n",
      "1897:\tlearn: 4331102.8104307\ttotal: 2m 53s\tremaining: 1m 38s\n",
      "1898:\tlearn: 4330265.2800551\ttotal: 2m 53s\tremaining: 1m 38s\n",
      "1899:\tlearn: 4328347.1296141\ttotal: 2m 54s\tremaining: 1m 38s\n",
      "1900:\tlearn: 4327543.2251876\ttotal: 2m 54s\tremaining: 1m 38s\n",
      "1901:\tlearn: 4327008.6124654\ttotal: 2m 54s\tremaining: 1m 38s\n",
      "1902:\tlearn: 4326241.4966765\ttotal: 2m 54s\tremaining: 1m 38s\n",
      "1903:\tlearn: 4325040.2590035\ttotal: 2m 54s\tremaining: 1m 38s\n",
      "1904:\tlearn: 4323668.0047826\ttotal: 2m 54s\tremaining: 1m 37s\n",
      "1905:\tlearn: 4322806.3634119\ttotal: 2m 54s\tremaining: 1m 37s\n",
      "1906:\tlearn: 4322087.3675585\ttotal: 2m 54s\tremaining: 1m 37s\n",
      "1907:\tlearn: 4320799.3202476\ttotal: 2m 54s\tremaining: 1m 37s\n",
      "1908:\tlearn: 4320240.5681166\ttotal: 2m 54s\tremaining: 1m 37s\n",
      "1909:\tlearn: 4319606.3408888\ttotal: 2m 54s\tremaining: 1m 37s\n",
      "1910:\tlearn: 4318739.2265847\ttotal: 2m 55s\tremaining: 1m 37s\n",
      "1911:\tlearn: 4311675.5036150\ttotal: 2m 55s\tremaining: 1m 37s\n",
      "1912:\tlearn: 4307172.7203594\ttotal: 2m 55s\tremaining: 1m 37s\n",
      "1913:\tlearn: 4304253.3766145\ttotal: 2m 55s\tremaining: 1m 37s\n",
      "1914:\tlearn: 4303373.2456637\ttotal: 2m 55s\tremaining: 1m 37s\n",
      "1915:\tlearn: 4302772.2120219\ttotal: 2m 55s\tremaining: 1m 36s\n",
      "1916:\tlearn: 4301401.9466093\ttotal: 2m 55s\tremaining: 1m 36s\n",
      "1917:\tlearn: 4300701.6507773\ttotal: 2m 55s\tremaining: 1m 36s\n",
      "1918:\tlearn: 4296706.2809898\ttotal: 2m 55s\tremaining: 1m 36s\n",
      "1919:\tlearn: 4295873.7561937\ttotal: 2m 55s\tremaining: 1m 36s\n",
      "1920:\tlearn: 4295152.4996650\ttotal: 2m 55s\tremaining: 1m 36s\n",
      "1921:\tlearn: 4294108.7233059\ttotal: 2m 56s\tremaining: 1m 36s\n",
      "1922:\tlearn: 4293456.7346849\ttotal: 2m 56s\tremaining: 1m 36s\n",
      "1923:\tlearn: 4291490.8682728\ttotal: 2m 56s\tremaining: 1m 36s\n",
      "1924:\tlearn: 4290254.6052847\ttotal: 2m 56s\tremaining: 1m 36s\n",
      "1925:\tlearn: 4289204.4244732\ttotal: 2m 56s\tremaining: 1m 35s\n",
      "1926:\tlearn: 4287388.2942440\ttotal: 2m 56s\tremaining: 1m 35s\n",
      "1927:\tlearn: 4286756.9641482\ttotal: 2m 56s\tremaining: 1m 35s\n",
      "1928:\tlearn: 4283198.2866364\ttotal: 2m 56s\tremaining: 1m 35s\n",
      "1929:\tlearn: 4282139.9719970\ttotal: 2m 56s\tremaining: 1m 35s\n",
      "1930:\tlearn: 4281298.6021648\ttotal: 2m 56s\tremaining: 1m 35s\n",
      "1931:\tlearn: 4277854.5219495\ttotal: 2m 56s\tremaining: 1m 35s\n",
      "1932:\tlearn: 4276174.3618311\ttotal: 2m 56s\tremaining: 1m 35s\n",
      "1933:\tlearn: 4275832.6153587\ttotal: 2m 57s\tremaining: 1m 35s\n",
      "1934:\tlearn: 4274257.7032027\ttotal: 2m 57s\tremaining: 1m 35s\n",
      "1935:\tlearn: 4273495.2488255\ttotal: 2m 57s\tremaining: 1m 35s\n",
      "1936:\tlearn: 4271916.2872061\ttotal: 2m 57s\tremaining: 1m 34s\n",
      "1937:\tlearn: 4270199.5471174\ttotal: 2m 57s\tremaining: 1m 34s\n",
      "1938:\tlearn: 4269279.7200953\ttotal: 2m 57s\tremaining: 1m 34s\n",
      "1939:\tlearn: 4267864.2743123\ttotal: 2m 57s\tremaining: 1m 34s\n",
      "1940:\tlearn: 4266914.3403468\ttotal: 2m 57s\tremaining: 1m 34s\n",
      "1941:\tlearn: 4265308.5715421\ttotal: 2m 57s\tremaining: 1m 34s\n",
      "1942:\tlearn: 4264103.2368622\ttotal: 2m 57s\tremaining: 1m 34s\n",
      "1943:\tlearn: 4262358.8463940\ttotal: 2m 57s\tremaining: 1m 34s\n",
      "1944:\tlearn: 4261142.7696832\ttotal: 2m 58s\tremaining: 1m 34s\n",
      "1945:\tlearn: 4258491.9914098\ttotal: 2m 58s\tremaining: 1m 34s\n",
      "1946:\tlearn: 4255271.5141544\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1947:\tlearn: 4254529.7713599\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1948:\tlearn: 4253405.6138291\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1949:\tlearn: 4252807.4016767\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1950:\tlearn: 4251904.2021854\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1951:\tlearn: 4251137.4384684\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1952:\tlearn: 4250466.5492727\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1953:\tlearn: 4249328.7606964\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1954:\tlearn: 4248547.9993175\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1955:\tlearn: 4248058.2132297\ttotal: 2m 58s\tremaining: 1m 33s\n",
      "1956:\tlearn: 4247184.2834181\ttotal: 2m 59s\tremaining: 1m 33s\n",
      "1957:\tlearn: 4246415.8266871\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1958:\tlearn: 4239503.3358909\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1959:\tlearn: 4238777.9694413\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1960:\tlearn: 4237344.1406765\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1961:\tlearn: 4235407.4141272\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1962:\tlearn: 4235015.6976671\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1963:\tlearn: 4233343.5457559\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1964:\tlearn: 4232837.2357935\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1965:\tlearn: 4231749.5759040\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1966:\tlearn: 4231464.0284549\ttotal: 2m 59s\tremaining: 1m 32s\n",
      "1967:\tlearn: 4229892.0489917\ttotal: 3m\tremaining: 1m 32s\n",
      "1968:\tlearn: 4225999.0088089\ttotal: 3m\tremaining: 1m 31s\n",
      "1969:\tlearn: 4224110.3106798\ttotal: 3m\tremaining: 1m 31s\n",
      "1970:\tlearn: 4223632.6395385\ttotal: 3m\tremaining: 1m 31s\n",
      "1971:\tlearn: 4222183.1132514\ttotal: 3m\tremaining: 1m 31s\n",
      "1972:\tlearn: 4218825.9258708\ttotal: 3m\tremaining: 1m 31s\n",
      "1973:\tlearn: 4218105.3291124\ttotal: 3m\tremaining: 1m 31s\n",
      "1974:\tlearn: 4217333.4379045\ttotal: 3m\tremaining: 1m 31s\n",
      "1975:\tlearn: 4216866.1297006\ttotal: 3m\tremaining: 1m 31s\n",
      "1976:\tlearn: 4215096.5510959\ttotal: 3m\tremaining: 1m 31s\n",
      "1977:\tlearn: 4214354.8140231\ttotal: 3m\tremaining: 1m 31s\n",
      "1978:\tlearn: 4213750.5004564\ttotal: 3m 1s\tremaining: 1m 31s\n",
      "1979:\tlearn: 4212185.4008221\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1980:\tlearn: 4210741.2545875\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1981:\tlearn: 4210383.4754529\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1982:\tlearn: 4209717.3366164\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1983:\tlearn: 4207127.5710437\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1984:\tlearn: 4205236.3668512\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1985:\tlearn: 4204802.8221501\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1986:\tlearn: 4204438.2750773\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1987:\tlearn: 4203333.2692787\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1988:\tlearn: 4202522.8324711\ttotal: 3m 1s\tremaining: 1m 30s\n",
      "1989:\tlearn: 4199892.8589623\ttotal: 3m 2s\tremaining: 1m 30s\n",
      "1990:\tlearn: 4199100.6355335\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "1991:\tlearn: 4198051.4449200\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "1992:\tlearn: 4196315.6368262\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "1993:\tlearn: 4195369.4995485\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "1994:\tlearn: 4194629.1728634\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "1995:\tlearn: 4192955.9724515\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "1996:\tlearn: 4192236.2665846\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "1997:\tlearn: 4191671.4900289\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "1998:\tlearn: 4190772.7092340\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "1999:\tlearn: 4189973.7956156\ttotal: 3m 2s\tremaining: 1m 29s\n",
      "2000:\tlearn: 4188612.4144377\ttotal: 3m 2s\tremaining: 1m 28s\n",
      "2001:\tlearn: 4188009.0835886\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2002:\tlearn: 4181845.5063811\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2003:\tlearn: 4181279.4683308\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2004:\tlearn: 4180190.3296721\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2005:\tlearn: 4178472.0112349\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2006:\tlearn: 4177431.5933478\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2007:\tlearn: 4175996.3915640\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2008:\tlearn: 4169993.4738187\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2009:\tlearn: 4168600.5990284\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2010:\tlearn: 4167927.3358283\ttotal: 3m 3s\tremaining: 1m 28s\n",
      "2011:\tlearn: 4167195.9175326\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2012:\tlearn: 4165759.8447117\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2013:\tlearn: 4164953.9527013\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2014:\tlearn: 4163439.1281707\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2015:\tlearn: 4162577.3784654\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2016:\tlearn: 4161419.5711266\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2017:\tlearn: 4161006.8096477\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2018:\tlearn: 4160114.4984313\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2019:\tlearn: 4158691.1533985\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2020:\tlearn: 4155437.4165042\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2021:\tlearn: 4154873.7999391\ttotal: 3m 4s\tremaining: 1m 27s\n",
      "2022:\tlearn: 4154415.6951936\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2023:\tlearn: 4154022.6928895\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2024:\tlearn: 4153490.3565017\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2025:\tlearn: 4151945.9305158\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2026:\tlearn: 4151583.7717717\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2027:\tlearn: 4150363.9503164\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2028:\tlearn: 4149596.0302622\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2029:\tlearn: 4148259.6899913\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2030:\tlearn: 4148046.2630600\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2031:\tlearn: 4146846.9365928\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2032:\tlearn: 4146245.2531376\ttotal: 3m 5s\tremaining: 1m 26s\n",
      "2033:\tlearn: 4145211.3211871\ttotal: 3m 5s\tremaining: 1m 25s\n",
      "2034:\tlearn: 4143872.8025152\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2035:\tlearn: 4142588.5489172\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2036:\tlearn: 4140762.0705724\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2037:\tlearn: 4138980.2325556\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2038:\tlearn: 4136093.2800547\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2039:\tlearn: 4135153.1049108\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2040:\tlearn: 4134222.1482783\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2041:\tlearn: 4133602.2940802\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2042:\tlearn: 4132381.5904629\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2043:\tlearn: 4131265.0635743\ttotal: 3m 6s\tremaining: 1m 25s\n",
      "2044:\tlearn: 4130952.0667611\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2045:\tlearn: 4129312.9119676\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2046:\tlearn: 4128131.1446115\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2047:\tlearn: 4127576.0576123\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2048:\tlearn: 4126914.3205697\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2049:\tlearn: 4126309.6435613\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2050:\tlearn: 4125427.4973996\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2051:\tlearn: 4124166.5415271\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2052:\tlearn: 4123551.8996400\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2053:\tlearn: 4122614.1859687\ttotal: 3m 7s\tremaining: 1m 24s\n",
      "2054:\tlearn: 4122150.3777396\ttotal: 3m 8s\tremaining: 1m 24s\n",
      "2055:\tlearn: 4121455.6677520\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2056:\tlearn: 4120760.6750721\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2057:\tlearn: 4120073.9087831\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2058:\tlearn: 4118256.8089872\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2059:\tlearn: 4117577.7232409\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2060:\tlearn: 4116250.3179039\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2061:\tlearn: 4115113.8910032\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2062:\tlearn: 4114026.1951167\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2063:\tlearn: 4113525.6765147\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2064:\tlearn: 4113066.7561409\ttotal: 3m 8s\tremaining: 1m 23s\n",
      "2065:\tlearn: 4111667.8475786\ttotal: 3m 9s\tremaining: 1m 23s\n",
      "2066:\tlearn: 4110710.6042677\ttotal: 3m 9s\tremaining: 1m 22s\n",
      "2067:\tlearn: 4108316.9538341\ttotal: 3m 9s\tremaining: 1m 22s\n",
      "2068:\tlearn: 4107149.9621245\ttotal: 3m 9s\tremaining: 1m 22s\n",
      "2069:\tlearn: 4106913.3958952\ttotal: 3m 9s\tremaining: 1m 22s\n",
      "2070:\tlearn: 4105485.6758289\ttotal: 3m 9s\tremaining: 1m 22s\n",
      "2071:\tlearn: 4103807.6718108\ttotal: 3m 9s\tremaining: 1m 22s\n",
      "2072:\tlearn: 4102595.6601881\ttotal: 3m 9s\tremaining: 1m 22s\n",
      "2073:\tlearn: 4101985.2716186\ttotal: 3m 9s\tremaining: 1m 22s\n",
      "2074:\tlearn: 4099874.8116961\ttotal: 3m 9s\tremaining: 1m 22s\n",
      "2075:\tlearn: 4099158.1249463\ttotal: 3m 10s\tremaining: 1m 22s\n",
      "2076:\tlearn: 4098034.4237920\ttotal: 3m 10s\tremaining: 1m 22s\n",
      "2077:\tlearn: 4097358.8882769\ttotal: 3m 10s\tremaining: 1m 22s\n",
      "2078:\tlearn: 4096427.4846530\ttotal: 3m 10s\tremaining: 1m 21s\n",
      "2079:\tlearn: 4093997.0616586\ttotal: 3m 10s\tremaining: 1m 21s\n",
      "2080:\tlearn: 4092275.9007643\ttotal: 3m 10s\tremaining: 1m 21s\n",
      "2081:\tlearn: 4091711.2256076\ttotal: 3m 10s\tremaining: 1m 21s\n",
      "2082:\tlearn: 4090829.6691363\ttotal: 3m 10s\tremaining: 1m 21s\n",
      "2083:\tlearn: 4090024.9822927\ttotal: 3m 10s\tremaining: 1m 21s\n",
      "2084:\tlearn: 4089129.0155592\ttotal: 3m 10s\tremaining: 1m 21s\n",
      "2085:\tlearn: 4087376.7118042\ttotal: 3m 10s\tremaining: 1m 21s\n",
      "2086:\tlearn: 4086445.9193556\ttotal: 3m 11s\tremaining: 1m 21s\n",
      "2087:\tlearn: 4085204.2648515\ttotal: 3m 11s\tremaining: 1m 21s\n",
      "2088:\tlearn: 4084329.5320034\ttotal: 3m 11s\tremaining: 1m 21s\n",
      "2089:\tlearn: 4082997.9949580\ttotal: 3m 11s\tremaining: 1m 20s\n",
      "2090:\tlearn: 4082216.0728877\ttotal: 3m 11s\tremaining: 1m 20s\n",
      "2091:\tlearn: 4080957.0154485\ttotal: 3m 11s\tremaining: 1m 20s\n",
      "2092:\tlearn: 4080548.4093920\ttotal: 3m 11s\tremaining: 1m 20s\n",
      "2093:\tlearn: 4079318.9625894\ttotal: 3m 11s\tremaining: 1m 20s\n",
      "2094:\tlearn: 4077742.2254367\ttotal: 3m 11s\tremaining: 1m 20s\n",
      "2095:\tlearn: 4076126.9124005\ttotal: 3m 11s\tremaining: 1m 20s\n",
      "2096:\tlearn: 4073478.4469195\ttotal: 3m 12s\tremaining: 1m 20s\n",
      "2097:\tlearn: 4073044.9018881\ttotal: 3m 12s\tremaining: 1m 20s\n",
      "2098:\tlearn: 4072608.7159267\ttotal: 3m 12s\tremaining: 1m 20s\n",
      "2099:\tlearn: 4070795.6475500\ttotal: 3m 12s\tremaining: 1m 20s\n",
      "2100:\tlearn: 4070117.7902363\ttotal: 3m 12s\tremaining: 1m 19s\n",
      "2101:\tlearn: 4067946.6798500\ttotal: 3m 12s\tremaining: 1m 19s\n",
      "2102:\tlearn: 4067281.2945603\ttotal: 3m 12s\tremaining: 1m 19s\n",
      "2103:\tlearn: 4066457.3541952\ttotal: 3m 12s\tremaining: 1m 19s\n",
      "2104:\tlearn: 4064711.0267207\ttotal: 3m 12s\tremaining: 1m 19s\n",
      "2105:\tlearn: 4063528.1307689\ttotal: 3m 12s\tremaining: 1m 19s\n",
      "2106:\tlearn: 4062129.7186307\ttotal: 3m 12s\tremaining: 1m 19s\n",
      "2107:\tlearn: 4059913.2936703\ttotal: 3m 13s\tremaining: 1m 19s\n",
      "2108:\tlearn: 4059099.1865319\ttotal: 3m 13s\tremaining: 1m 19s\n",
      "2109:\tlearn: 4058159.2235515\ttotal: 3m 13s\tremaining: 1m 19s\n",
      "2110:\tlearn: 4056561.1106517\ttotal: 3m 13s\tremaining: 1m 19s\n",
      "2111:\tlearn: 4055664.6187261\ttotal: 3m 13s\tremaining: 1m 18s\n",
      "2112:\tlearn: 4055382.1231363\ttotal: 3m 13s\tremaining: 1m 18s\n",
      "2113:\tlearn: 4054166.5222674\ttotal: 3m 13s\tremaining: 1m 18s\n",
      "2114:\tlearn: 4053663.4697945\ttotal: 3m 13s\tremaining: 1m 18s\n",
      "2115:\tlearn: 4053294.1212771\ttotal: 3m 13s\tremaining: 1m 18s\n",
      "2116:\tlearn: 4052743.1873685\ttotal: 3m 13s\tremaining: 1m 18s\n",
      "2117:\tlearn: 4049732.0636454\ttotal: 3m 13s\tremaining: 1m 18s\n",
      "2118:\tlearn: 4048906.9176640\ttotal: 3m 13s\tremaining: 1m 18s\n",
      "2119:\tlearn: 4047449.6878539\ttotal: 3m 14s\tremaining: 1m 18s\n",
      "2120:\tlearn: 4047001.2674279\ttotal: 3m 14s\tremaining: 1m 18s\n",
      "2121:\tlearn: 4046323.0934792\ttotal: 3m 14s\tremaining: 1m 18s\n",
      "2122:\tlearn: 4045706.4460303\ttotal: 3m 14s\tremaining: 1m 17s\n",
      "2123:\tlearn: 4045102.4178444\ttotal: 3m 14s\tremaining: 1m 17s\n",
      "2124:\tlearn: 4043033.6492910\ttotal: 3m 14s\tremaining: 1m 17s\n",
      "2125:\tlearn: 4042606.8538448\ttotal: 3m 14s\tremaining: 1m 17s\n",
      "2126:\tlearn: 4041390.3484522\ttotal: 3m 14s\tremaining: 1m 17s\n",
      "2127:\tlearn: 4039969.5750749\ttotal: 3m 14s\tremaining: 1m 17s\n",
      "2128:\tlearn: 4038611.0224491\ttotal: 3m 14s\tremaining: 1m 17s\n",
      "2129:\tlearn: 4037943.6905381\ttotal: 3m 14s\tremaining: 1m 17s\n",
      "2130:\tlearn: 4037367.6153757\ttotal: 3m 15s\tremaining: 1m 17s\n",
      "2131:\tlearn: 4036582.3672431\ttotal: 3m 15s\tremaining: 1m 17s\n",
      "2132:\tlearn: 4035069.6230817\ttotal: 3m 15s\tremaining: 1m 16s\n",
      "2133:\tlearn: 4034115.7457014\ttotal: 3m 15s\tremaining: 1m 16s\n",
      "2134:\tlearn: 4033724.1993937\ttotal: 3m 15s\tremaining: 1m 16s\n",
      "2135:\tlearn: 4033142.1506604\ttotal: 3m 15s\tremaining: 1m 16s\n",
      "2136:\tlearn: 4031653.1216514\ttotal: 3m 15s\tremaining: 1m 16s\n",
      "2137:\tlearn: 4029580.3737364\ttotal: 3m 15s\tremaining: 1m 16s\n",
      "2138:\tlearn: 4029227.3200992\ttotal: 3m 15s\tremaining: 1m 16s\n",
      "2139:\tlearn: 4024921.6203066\ttotal: 3m 15s\tremaining: 1m 16s\n",
      "2140:\tlearn: 4023711.7509456\ttotal: 3m 15s\tremaining: 1m 16s\n",
      "2141:\tlearn: 4023481.5273467\ttotal: 3m 16s\tremaining: 1m 16s\n",
      "2142:\tlearn: 4021492.0958277\ttotal: 3m 16s\tremaining: 1m 16s\n",
      "2143:\tlearn: 4020709.8560849\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2144:\tlearn: 4020157.6451354\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2145:\tlearn: 4019286.6850544\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2146:\tlearn: 4018431.8432877\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2147:\tlearn: 4018059.8745823\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2148:\tlearn: 4016736.2345755\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2149:\tlearn: 4016278.4454767\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2150:\tlearn: 4014936.0849161\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2151:\tlearn: 4014558.8326156\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2152:\tlearn: 4014135.6516187\ttotal: 3m 16s\tremaining: 1m 15s\n",
      "2153:\tlearn: 4012999.7535197\ttotal: 3m 17s\tremaining: 1m 15s\n",
      "2154:\tlearn: 4011992.5704433\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2155:\tlearn: 4009900.8498873\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2156:\tlearn: 4009548.3911606\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2157:\tlearn: 4009181.2422378\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2158:\tlearn: 4008888.7412765\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2159:\tlearn: 4008042.9269274\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2160:\tlearn: 4007224.2064883\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2161:\tlearn: 4006152.8044060\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2162:\tlearn: 4001906.6879781\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2163:\tlearn: 4001188.3178414\ttotal: 3m 17s\tremaining: 1m 14s\n",
      "2164:\tlearn: 4000338.9006436\ttotal: 3m 18s\tremaining: 1m 14s\n",
      "2165:\tlearn: 3999991.1360486\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2166:\tlearn: 3999017.9617412\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2167:\tlearn: 3997555.9036266\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2168:\tlearn: 3996137.9753158\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2169:\tlearn: 3994415.9263619\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2170:\tlearn: 3992836.3779108\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2171:\tlearn: 3989657.0002863\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2172:\tlearn: 3989470.0616557\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2173:\tlearn: 3988349.1574230\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2174:\tlearn: 3987508.7399878\ttotal: 3m 18s\tremaining: 1m 13s\n",
      "2175:\tlearn: 3986237.9740918\ttotal: 3m 19s\tremaining: 1m 13s\n",
      "2176:\tlearn: 3986104.6448415\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2177:\tlearn: 3984916.8934753\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2178:\tlearn: 3984444.6550093\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2179:\tlearn: 3983943.6739780\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2180:\tlearn: 3982724.1850179\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2181:\tlearn: 3982333.4141652\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2182:\tlearn: 3977864.8323909\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2183:\tlearn: 3977269.9022327\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2184:\tlearn: 3969190.8703670\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2185:\tlearn: 3967998.1856257\ttotal: 3m 19s\tremaining: 1m 12s\n",
      "2186:\tlearn: 3964131.4605524\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2187:\tlearn: 3962992.8892693\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2188:\tlearn: 3962283.2874622\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2189:\tlearn: 3960894.6997608\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2190:\tlearn: 3958079.3689742\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2191:\tlearn: 3957503.4274598\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2192:\tlearn: 3955304.6341615\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2193:\tlearn: 3954906.9746887\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2194:\tlearn: 3953657.7234371\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2195:\tlearn: 3950751.8909381\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2196:\tlearn: 3949552.0279979\ttotal: 3m 20s\tremaining: 1m 11s\n",
      "2197:\tlearn: 3949280.0847460\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2198:\tlearn: 3948853.7167369\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2199:\tlearn: 3948201.5052837\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2200:\tlearn: 3946184.7102087\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2201:\tlearn: 3945649.8523235\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2202:\tlearn: 3944699.4424927\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2203:\tlearn: 3943717.3472779\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2204:\tlearn: 3942505.8923729\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2205:\tlearn: 3941702.7835514\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2206:\tlearn: 3939737.8900023\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2207:\tlearn: 3939075.9340128\ttotal: 3m 21s\tremaining: 1m 10s\n",
      "2208:\tlearn: 3937197.4616865\ttotal: 3m 21s\tremaining: 1m 9s\n",
      "2209:\tlearn: 3935545.1811592\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2210:\tlearn: 3931601.6749210\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2211:\tlearn: 3930361.0804075\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2212:\tlearn: 3930045.0230497\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2213:\tlearn: 3929600.6975075\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2214:\tlearn: 3928911.7398176\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2215:\tlearn: 3927164.7196378\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2216:\tlearn: 3926669.1388319\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2217:\tlearn: 3925987.6211269\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2218:\tlearn: 3925495.9028548\ttotal: 3m 22s\tremaining: 1m 9s\n",
      "2219:\tlearn: 3925023.4107088\ttotal: 3m 22s\tremaining: 1m 8s\n",
      "2220:\tlearn: 3924656.6455417\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2221:\tlearn: 3923407.2800925\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2222:\tlearn: 3922994.0500682\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2223:\tlearn: 3922764.0213728\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2224:\tlearn: 3922509.1913580\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2225:\tlearn: 3921728.5682533\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2226:\tlearn: 3921475.5001894\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2227:\tlearn: 3920872.3114207\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2228:\tlearn: 3920162.4804153\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2229:\tlearn: 3918965.8690795\ttotal: 3m 23s\tremaining: 1m 8s\n",
      "2230:\tlearn: 3918634.2289070\ttotal: 3m 23s\tremaining: 1m 7s\n",
      "2231:\tlearn: 3918142.7425442\ttotal: 3m 24s\tremaining: 1m 7s\n",
      "2232:\tlearn: 3917022.3186218\ttotal: 3m 24s\tremaining: 1m 7s\n",
      "2233:\tlearn: 3916200.6182636\ttotal: 3m 24s\tremaining: 1m 7s\n",
      "2234:\tlearn: 3915071.8172436\ttotal: 3m 24s\tremaining: 1m 7s\n",
      "2235:\tlearn: 3913812.8727901\ttotal: 3m 24s\tremaining: 1m 7s\n",
      "2236:\tlearn: 3913061.8727689\ttotal: 3m 24s\tremaining: 1m 7s\n",
      "2237:\tlearn: 3912496.3161124\ttotal: 3m 24s\tremaining: 1m 7s\n",
      "2238:\tlearn: 3911813.6760394\ttotal: 3m 24s\tremaining: 1m 7s\n",
      "2239:\tlearn: 3911580.2827961\ttotal: 3m 24s\tremaining: 1m 7s\n",
      "2240:\tlearn: 3910596.4172871\ttotal: 3m 25s\tremaining: 1m 7s\n",
      "2241:\tlearn: 3910148.3961521\ttotal: 3m 25s\tremaining: 1m 6s\n",
      "2242:\tlearn: 3909035.5909015\ttotal: 3m 25s\tremaining: 1m 6s\n",
      "2243:\tlearn: 3907860.3194339\ttotal: 3m 25s\tremaining: 1m 6s\n",
      "2244:\tlearn: 3907416.9035225\ttotal: 3m 25s\tremaining: 1m 6s\n",
      "2245:\tlearn: 3907073.7583337\ttotal: 3m 25s\tremaining: 1m 6s\n",
      "2246:\tlearn: 3906217.2691930\ttotal: 3m 25s\tremaining: 1m 6s\n",
      "2247:\tlearn: 3905909.9992441\ttotal: 3m 25s\tremaining: 1m 6s\n",
      "2248:\tlearn: 3904863.0311167\ttotal: 3m 25s\tremaining: 1m 6s\n",
      "2249:\tlearn: 3904225.1902529\ttotal: 3m 25s\tremaining: 1m 6s\n",
      "2250:\tlearn: 3903338.7944809\ttotal: 3m 26s\tremaining: 1m 6s\n",
      "2251:\tlearn: 3903048.0428593\ttotal: 3m 26s\tremaining: 1m 6s\n",
      "2252:\tlearn: 3901396.7996740\ttotal: 3m 26s\tremaining: 1m 5s\n",
      "2253:\tlearn: 3900720.5043004\ttotal: 3m 26s\tremaining: 1m 5s\n",
      "2254:\tlearn: 3900074.5650182\ttotal: 3m 26s\tremaining: 1m 5s\n",
      "2255:\tlearn: 3898808.6955223\ttotal: 3m 26s\tremaining: 1m 5s\n",
      "2256:\tlearn: 3897526.1452458\ttotal: 3m 26s\tremaining: 1m 5s\n",
      "2257:\tlearn: 3896959.6747283\ttotal: 3m 26s\tremaining: 1m 5s\n",
      "2258:\tlearn: 3896560.3263437\ttotal: 3m 26s\tremaining: 1m 5s\n",
      "2259:\tlearn: 3896002.2800463\ttotal: 3m 26s\tremaining: 1m 5s\n",
      "2260:\tlearn: 3895267.9733869\ttotal: 3m 26s\tremaining: 1m 5s\n",
      "2261:\tlearn: 3895042.0975669\ttotal: 3m 27s\tremaining: 1m 5s\n",
      "2262:\tlearn: 3894664.0644516\ttotal: 3m 27s\tremaining: 1m 5s\n",
      "2263:\tlearn: 3894121.9012513\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2264:\tlearn: 3893517.5976647\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2265:\tlearn: 3892050.9099855\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2266:\tlearn: 3891547.4150334\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2267:\tlearn: 3890561.0727744\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2268:\tlearn: 3887411.7060205\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2269:\tlearn: 3887068.0294040\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2270:\tlearn: 3885949.4322979\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2271:\tlearn: 3884900.4647437\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2272:\tlearn: 3883478.4007747\ttotal: 3m 27s\tremaining: 1m 4s\n",
      "2273:\tlearn: 3882780.9044173\ttotal: 3m 28s\tremaining: 1m 4s\n",
      "2274:\tlearn: 3882435.3851844\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2275:\tlearn: 3881931.2258107\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2276:\tlearn: 3880664.3484538\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2277:\tlearn: 3879654.5622041\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2278:\tlearn: 3878925.6583729\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2279:\tlearn: 3878527.6745641\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2280:\tlearn: 3877494.0592573\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2281:\tlearn: 3877304.7049498\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2282:\tlearn: 3872080.1526562\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2283:\tlearn: 3870530.6265061\ttotal: 3m 28s\tremaining: 1m 3s\n",
      "2284:\tlearn: 3869590.5943082\ttotal: 3m 29s\tremaining: 1m 3s\n",
      "2285:\tlearn: 3868595.4093333\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2286:\tlearn: 3868075.6881389\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2287:\tlearn: 3867630.2595131\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2288:\tlearn: 3866793.1363228\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2289:\tlearn: 3866287.6535060\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2290:\tlearn: 3865261.2127830\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2291:\tlearn: 3863778.4812348\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2292:\tlearn: 3862822.3884006\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2293:\tlearn: 3862117.6176870\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2294:\tlearn: 3861617.9203875\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2295:\tlearn: 3856788.3755916\ttotal: 3m 29s\tremaining: 1m 2s\n",
      "2296:\tlearn: 3856463.9562712\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2297:\tlearn: 3855836.2239610\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2298:\tlearn: 3855456.8842848\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2299:\tlearn: 3854880.7559014\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2300:\tlearn: 3853675.0586261\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2301:\tlearn: 3852817.2124354\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2302:\tlearn: 3851157.1503759\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2303:\tlearn: 3849776.8835010\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2304:\tlearn: 3849373.8145368\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2305:\tlearn: 3848386.6607912\ttotal: 3m 30s\tremaining: 1m 1s\n",
      "2306:\tlearn: 3847940.3126066\ttotal: 3m 30s\tremaining: 1m\n",
      "2307:\tlearn: 3847221.9620667\ttotal: 3m 31s\tremaining: 1m\n",
      "2308:\tlearn: 3846026.8853890\ttotal: 3m 31s\tremaining: 1m\n",
      "2309:\tlearn: 3845570.8210182\ttotal: 3m 31s\tremaining: 1m\n",
      "2310:\tlearn: 3844096.3668010\ttotal: 3m 31s\tremaining: 1m\n",
      "2311:\tlearn: 3842598.9701743\ttotal: 3m 31s\tremaining: 1m\n",
      "2312:\tlearn: 3842014.7614005\ttotal: 3m 31s\tremaining: 1m\n",
      "2313:\tlearn: 3841024.6717440\ttotal: 3m 31s\tremaining: 1m\n",
      "2314:\tlearn: 3840071.3106918\ttotal: 3m 31s\tremaining: 1m\n",
      "2315:\tlearn: 3839254.9611504\ttotal: 3m 31s\tremaining: 1m\n",
      "2316:\tlearn: 3838278.8166176\ttotal: 3m 31s\tremaining: 1m\n",
      "2317:\tlearn: 3837819.5374500\ttotal: 3m 31s\tremaining: 60s\n",
      "2318:\tlearn: 3837249.3409209\ttotal: 3m 31s\tremaining: 59.9s\n",
      "2319:\tlearn: 3833701.1435913\ttotal: 3m 32s\tremaining: 59.8s\n",
      "2320:\tlearn: 3832399.3361438\ttotal: 3m 32s\tremaining: 59.7s\n",
      "2321:\tlearn: 3829677.5190747\ttotal: 3m 32s\tremaining: 59.6s\n",
      "2322:\tlearn: 3828677.5723446\ttotal: 3m 32s\tremaining: 59.5s\n",
      "2323:\tlearn: 3827897.3576829\ttotal: 3m 32s\tremaining: 59.4s\n",
      "2324:\tlearn: 3826476.6330403\ttotal: 3m 32s\tremaining: 59.3s\n",
      "2325:\tlearn: 3825835.3355456\ttotal: 3m 32s\tremaining: 59.2s\n",
      "2326:\tlearn: 3825422.9001809\ttotal: 3m 32s\tremaining: 59.1s\n",
      "2327:\tlearn: 3824517.4334651\ttotal: 3m 32s\tremaining: 59s\n",
      "2328:\tlearn: 3824110.5422875\ttotal: 3m 32s\tremaining: 58.9s\n",
      "2329:\tlearn: 3823643.5272292\ttotal: 3m 32s\tremaining: 58.8s\n",
      "2330:\tlearn: 3823010.1910158\ttotal: 3m 32s\tremaining: 58.7s\n",
      "2331:\tlearn: 3822091.4628208\ttotal: 3m 33s\tremaining: 58.6s\n",
      "2332:\tlearn: 3821558.5549352\ttotal: 3m 33s\tremaining: 58.6s\n",
      "2333:\tlearn: 3820697.0501477\ttotal: 3m 33s\tremaining: 58.5s\n",
      "2334:\tlearn: 3819682.7068432\ttotal: 3m 33s\tremaining: 58.4s\n",
      "2335:\tlearn: 3818506.0332032\ttotal: 3m 33s\tremaining: 58.3s\n",
      "2336:\tlearn: 3813921.2856639\ttotal: 3m 33s\tremaining: 58.2s\n",
      "2337:\tlearn: 3813631.2990417\ttotal: 3m 33s\tremaining: 58.1s\n",
      "2338:\tlearn: 3810992.0422335\ttotal: 3m 33s\tremaining: 58s\n",
      "2339:\tlearn: 3810454.2532951\ttotal: 3m 33s\tremaining: 57.9s\n",
      "2340:\tlearn: 3809979.2819709\ttotal: 3m 33s\tremaining: 57.8s\n",
      "2341:\tlearn: 3807270.5739832\ttotal: 3m 33s\tremaining: 57.7s\n",
      "2342:\tlearn: 3806705.4253303\ttotal: 3m 33s\tremaining: 57.6s\n",
      "2343:\tlearn: 3806391.4384164\ttotal: 3m 34s\tremaining: 57.5s\n",
      "2344:\tlearn: 3804790.3579602\ttotal: 3m 34s\tremaining: 57.4s\n",
      "2345:\tlearn: 3804150.8483112\ttotal: 3m 34s\tremaining: 57.3s\n",
      "2346:\tlearn: 3800956.0964842\ttotal: 3m 34s\tremaining: 57.3s\n",
      "2347:\tlearn: 3799787.6553440\ttotal: 3m 34s\tremaining: 57.2s\n",
      "2348:\tlearn: 3799350.6010142\ttotal: 3m 34s\tremaining: 57.1s\n",
      "2349:\tlearn: 3798734.0512196\ttotal: 3m 34s\tremaining: 57s\n",
      "2350:\tlearn: 3797482.1975758\ttotal: 3m 34s\tremaining: 56.9s\n",
      "2351:\tlearn: 3796029.3751051\ttotal: 3m 34s\tremaining: 56.8s\n",
      "2352:\tlearn: 3795208.2250678\ttotal: 3m 34s\tremaining: 56.7s\n",
      "2353:\tlearn: 3794316.3479239\ttotal: 3m 34s\tremaining: 56.6s\n",
      "2354:\tlearn: 3793770.8164291\ttotal: 3m 34s\tremaining: 56.5s\n",
      "2355:\tlearn: 3792804.9923735\ttotal: 3m 35s\tremaining: 56.4s\n",
      "2356:\tlearn: 3792370.8266606\ttotal: 3m 35s\tremaining: 56.3s\n",
      "2357:\tlearn: 3791648.7068859\ttotal: 3m 35s\tremaining: 56.2s\n",
      "2358:\tlearn: 3790651.4837677\ttotal: 3m 35s\tremaining: 56.1s\n",
      "2359:\tlearn: 3789634.0017447\ttotal: 3m 35s\tremaining: 56s\n",
      "2360:\tlearn: 3789204.5965041\ttotal: 3m 35s\tremaining: 55.9s\n",
      "2361:\tlearn: 3788172.9581120\ttotal: 3m 35s\tremaining: 55.8s\n",
      "2362:\tlearn: 3785199.1862739\ttotal: 3m 35s\tremaining: 55.8s\n",
      "2363:\tlearn: 3784719.3848871\ttotal: 3m 35s\tremaining: 55.7s\n",
      "2364:\tlearn: 3783492.5939332\ttotal: 3m 35s\tremaining: 55.6s\n",
      "2365:\tlearn: 3782616.5298494\ttotal: 3m 35s\tremaining: 55.5s\n",
      "2366:\tlearn: 3782052.0516414\ttotal: 3m 35s\tremaining: 55.4s\n",
      "2367:\tlearn: 3781518.1868283\ttotal: 3m 36s\tremaining: 55.3s\n",
      "2368:\tlearn: 3780355.6979866\ttotal: 3m 36s\tremaining: 55.2s\n",
      "2369:\tlearn: 3779686.0979399\ttotal: 3m 36s\tremaining: 55.1s\n",
      "2370:\tlearn: 3779018.6365046\ttotal: 3m 36s\tremaining: 55s\n",
      "2371:\tlearn: 3778675.2284939\ttotal: 3m 36s\tremaining: 54.9s\n",
      "2372:\tlearn: 3777608.5936790\ttotal: 3m 36s\tremaining: 54.8s\n",
      "2373:\tlearn: 3773323.8643398\ttotal: 3m 36s\tremaining: 54.7s\n",
      "2374:\tlearn: 3771024.7332693\ttotal: 3m 36s\tremaining: 54.6s\n",
      "2375:\tlearn: 3769912.9204494\ttotal: 3m 36s\tremaining: 54.5s\n",
      "2376:\tlearn: 3769398.9896913\ttotal: 3m 36s\tremaining: 54.4s\n",
      "2377:\tlearn: 3768828.2690659\ttotal: 3m 36s\tremaining: 54.3s\n",
      "2378:\tlearn: 3764830.9143437\ttotal: 3m 36s\tremaining: 54.2s\n",
      "2379:\tlearn: 3763819.0029706\ttotal: 3m 36s\tremaining: 54.2s\n",
      "2380:\tlearn: 3762528.0224361\ttotal: 3m 37s\tremaining: 54.1s\n",
      "2381:\tlearn: 3761943.1836671\ttotal: 3m 37s\tremaining: 54s\n",
      "2382:\tlearn: 3761246.1173577\ttotal: 3m 37s\tremaining: 53.9s\n",
      "2383:\tlearn: 3760473.1137355\ttotal: 3m 37s\tremaining: 53.8s\n",
      "2384:\tlearn: 3759734.1841270\ttotal: 3m 37s\tremaining: 53.7s\n",
      "2385:\tlearn: 3758396.5548454\ttotal: 3m 37s\tremaining: 53.6s\n",
      "2386:\tlearn: 3757644.4037170\ttotal: 3m 37s\tremaining: 53.5s\n",
      "2387:\tlearn: 3756747.9522092\ttotal: 3m 37s\tremaining: 53.4s\n",
      "2388:\tlearn: 3756139.5715322\ttotal: 3m 37s\tremaining: 53.3s\n",
      "2389:\tlearn: 3755604.1115804\ttotal: 3m 37s\tremaining: 53.2s\n",
      "2390:\tlearn: 3754571.0329232\ttotal: 3m 37s\tremaining: 53.1s\n",
      "2391:\tlearn: 3754001.4336904\ttotal: 3m 37s\tremaining: 53s\n",
      "2392:\tlearn: 3753612.6283024\ttotal: 3m 37s\tremaining: 52.9s\n",
      "2393:\tlearn: 3753326.1673952\ttotal: 3m 38s\tremaining: 52.8s\n",
      "2394:\tlearn: 3751086.8204737\ttotal: 3m 38s\tremaining: 52.7s\n",
      "2395:\tlearn: 3750386.0437705\ttotal: 3m 38s\tremaining: 52.6s\n",
      "2396:\tlearn: 3749395.8035850\ttotal: 3m 38s\tremaining: 52.6s\n",
      "2397:\tlearn: 3748371.3660339\ttotal: 3m 38s\tremaining: 52.5s\n",
      "2398:\tlearn: 3746087.4370943\ttotal: 3m 38s\tremaining: 52.4s\n",
      "2399:\tlearn: 3745019.5309311\ttotal: 3m 38s\tremaining: 52.3s\n",
      "2400:\tlearn: 3744422.8302535\ttotal: 3m 38s\tremaining: 52.2s\n",
      "2401:\tlearn: 3744275.4021004\ttotal: 3m 38s\tremaining: 52.1s\n",
      "2402:\tlearn: 3743339.6689108\ttotal: 3m 38s\tremaining: 52s\n",
      "2403:\tlearn: 3742273.6361336\ttotal: 3m 38s\tremaining: 51.9s\n",
      "2404:\tlearn: 3741924.2890329\ttotal: 3m 38s\tremaining: 51.8s\n",
      "2405:\tlearn: 3740920.6503932\ttotal: 3m 39s\tremaining: 51.7s\n",
      "2406:\tlearn: 3740638.1376788\ttotal: 3m 39s\tremaining: 51.6s\n",
      "2407:\tlearn: 3739985.5106400\ttotal: 3m 39s\tremaining: 51.5s\n",
      "2408:\tlearn: 3739291.8740184\ttotal: 3m 39s\tremaining: 51.4s\n",
      "2409:\tlearn: 3738420.7894153\ttotal: 3m 39s\tremaining: 51.3s\n",
      "2410:\tlearn: 3737239.9596848\ttotal: 3m 39s\tremaining: 51.2s\n",
      "2411:\tlearn: 3736000.8581027\ttotal: 3m 39s\tremaining: 51.1s\n",
      "2412:\tlearn: 3734216.6073647\ttotal: 3m 39s\tremaining: 51.1s\n",
      "2413:\tlearn: 3733321.6684351\ttotal: 3m 39s\tremaining: 51s\n",
      "2414:\tlearn: 3731855.0325615\ttotal: 3m 39s\tremaining: 50.9s\n",
      "2415:\tlearn: 3731098.4005064\ttotal: 3m 39s\tremaining: 50.8s\n",
      "2416:\tlearn: 3730303.7395644\ttotal: 3m 39s\tremaining: 50.7s\n",
      "2417:\tlearn: 3729228.1389157\ttotal: 3m 40s\tremaining: 50.6s\n",
      "2418:\tlearn: 3729037.7342885\ttotal: 3m 40s\tremaining: 50.5s\n",
      "2419:\tlearn: 3728053.8758930\ttotal: 3m 40s\tremaining: 50.4s\n",
      "2420:\tlearn: 3727223.7531718\ttotal: 3m 40s\tremaining: 50.3s\n",
      "2421:\tlearn: 3725927.1083170\ttotal: 3m 40s\tremaining: 50.2s\n",
      "2422:\tlearn: 3724949.9047199\ttotal: 3m 40s\tremaining: 50.1s\n",
      "2423:\tlearn: 3723724.5668807\ttotal: 3m 40s\tremaining: 50s\n",
      "2424:\tlearn: 3723116.9535950\ttotal: 3m 40s\tremaining: 49.9s\n",
      "2425:\tlearn: 3720786.7685379\ttotal: 3m 40s\tremaining: 49.8s\n",
      "2426:\tlearn: 3720316.5938385\ttotal: 3m 40s\tremaining: 49.7s\n",
      "2427:\tlearn: 3719859.7524756\ttotal: 3m 40s\tremaining: 49.7s\n",
      "2428:\tlearn: 3719302.9003907\ttotal: 3m 40s\tremaining: 49.6s\n",
      "2429:\tlearn: 3718630.1990748\ttotal: 3m 40s\tremaining: 49.5s\n",
      "2430:\tlearn: 3717988.0337151\ttotal: 3m 41s\tremaining: 49.4s\n",
      "2431:\tlearn: 3717784.3409411\ttotal: 3m 41s\tremaining: 49.3s\n",
      "2432:\tlearn: 3717283.2737451\ttotal: 3m 41s\tremaining: 49.2s\n",
      "2433:\tlearn: 3716896.3683329\ttotal: 3m 41s\tremaining: 49.1s\n",
      "2434:\tlearn: 3716119.2113515\ttotal: 3m 41s\tremaining: 49s\n",
      "2435:\tlearn: 3714949.0933348\ttotal: 3m 41s\tremaining: 48.9s\n",
      "2436:\tlearn: 3712792.3621697\ttotal: 3m 41s\tremaining: 48.8s\n",
      "2437:\tlearn: 3711495.7694111\ttotal: 3m 41s\tremaining: 48.7s\n",
      "2438:\tlearn: 3710769.4044508\ttotal: 3m 41s\tremaining: 48.6s\n",
      "2439:\tlearn: 3710176.7711370\ttotal: 3m 41s\tremaining: 48.5s\n",
      "2440:\tlearn: 3709765.6676514\ttotal: 3m 41s\tremaining: 48.4s\n",
      "2441:\tlearn: 3708403.6963391\ttotal: 3m 41s\tremaining: 48.3s\n",
      "2442:\tlearn: 3707425.2186261\ttotal: 3m 42s\tremaining: 48.3s\n",
      "2443:\tlearn: 3705093.1827724\ttotal: 3m 42s\tremaining: 48.2s\n",
      "2444:\tlearn: 3704322.8052164\ttotal: 3m 42s\tremaining: 48.1s\n",
      "2445:\tlearn: 3702648.8215414\ttotal: 3m 42s\tremaining: 48s\n",
      "2446:\tlearn: 3701767.7035601\ttotal: 3m 42s\tremaining: 47.9s\n",
      "2447:\tlearn: 3700649.4976150\ttotal: 3m 42s\tremaining: 47.8s\n",
      "2448:\tlearn: 3700351.3335556\ttotal: 3m 42s\tremaining: 47.7s\n",
      "2449:\tlearn: 3699618.1473192\ttotal: 3m 42s\tremaining: 47.6s\n",
      "2450:\tlearn: 3698342.2650888\ttotal: 3m 42s\tremaining: 47.5s\n",
      "2451:\tlearn: 3697393.3247014\ttotal: 3m 42s\tremaining: 47.4s\n",
      "2452:\tlearn: 3697071.2107858\ttotal: 3m 42s\tremaining: 47.3s\n",
      "2453:\tlearn: 3694340.9155851\ttotal: 3m 42s\tremaining: 47.2s\n",
      "2454:\tlearn: 3692696.2568855\ttotal: 3m 42s\tremaining: 47.1s\n",
      "2455:\tlearn: 3691834.8737840\ttotal: 3m 43s\tremaining: 47s\n",
      "2456:\tlearn: 3691089.1940105\ttotal: 3m 43s\tremaining: 47s\n",
      "2457:\tlearn: 3690232.7856055\ttotal: 3m 43s\tremaining: 46.9s\n",
      "2458:\tlearn: 3689391.3877473\ttotal: 3m 43s\tremaining: 46.8s\n",
      "2459:\tlearn: 3689063.4701505\ttotal: 3m 43s\tremaining: 46.7s\n",
      "2460:\tlearn: 3687711.8917324\ttotal: 3m 43s\tremaining: 46.6s\n",
      "2461:\tlearn: 3687259.1533078\ttotal: 3m 43s\tremaining: 46.5s\n",
      "2462:\tlearn: 3685281.8166000\ttotal: 3m 43s\tremaining: 46.4s\n",
      "2463:\tlearn: 3684316.0411353\ttotal: 3m 43s\tremaining: 46.3s\n",
      "2464:\tlearn: 3683071.8770724\ttotal: 3m 43s\tremaining: 46.2s\n",
      "2465:\tlearn: 3682005.6553242\ttotal: 3m 43s\tremaining: 46.1s\n",
      "2466:\tlearn: 3681701.6112937\ttotal: 3m 43s\tremaining: 46s\n",
      "2467:\tlearn: 3680202.5579313\ttotal: 3m 44s\tremaining: 45.9s\n",
      "2468:\tlearn: 3680021.2984838\ttotal: 3m 44s\tremaining: 45.8s\n",
      "2469:\tlearn: 3678548.9590372\ttotal: 3m 44s\tremaining: 45.7s\n",
      "2470:\tlearn: 3677807.5294275\ttotal: 3m 44s\tremaining: 45.6s\n",
      "2471:\tlearn: 3677631.6968924\ttotal: 3m 44s\tremaining: 45.6s\n",
      "2472:\tlearn: 3676756.3495417\ttotal: 3m 44s\tremaining: 45.5s\n",
      "2473:\tlearn: 3675291.4822360\ttotal: 3m 44s\tremaining: 45.4s\n",
      "2474:\tlearn: 3673961.5313060\ttotal: 3m 44s\tremaining: 45.3s\n",
      "2475:\tlearn: 3672981.8412875\ttotal: 3m 44s\tremaining: 45.2s\n",
      "2476:\tlearn: 3672068.0184383\ttotal: 3m 44s\tremaining: 45.1s\n",
      "2477:\tlearn: 3670943.2665502\ttotal: 3m 44s\tremaining: 45s\n",
      "2478:\tlearn: 3670552.4543232\ttotal: 3m 44s\tremaining: 44.9s\n",
      "2479:\tlearn: 3669585.2722038\ttotal: 3m 44s\tremaining: 44.8s\n",
      "2480:\tlearn: 3669100.1160358\ttotal: 3m 45s\tremaining: 44.7s\n",
      "2481:\tlearn: 3667910.9667164\ttotal: 3m 45s\tremaining: 44.6s\n",
      "2482:\tlearn: 3665636.9244298\ttotal: 3m 45s\tremaining: 44.5s\n",
      "2483:\tlearn: 3664909.7749835\ttotal: 3m 45s\tremaining: 44.4s\n",
      "2484:\tlearn: 3660883.9353383\ttotal: 3m 45s\tremaining: 44.3s\n",
      "2485:\tlearn: 3659696.7950908\ttotal: 3m 45s\tremaining: 44.3s\n",
      "2486:\tlearn: 3658852.6053820\ttotal: 3m 45s\tremaining: 44.2s\n",
      "2487:\tlearn: 3657855.7127271\ttotal: 3m 45s\tremaining: 44.1s\n",
      "2488:\tlearn: 3657077.5095842\ttotal: 3m 45s\tremaining: 44s\n",
      "2489:\tlearn: 3656522.4071198\ttotal: 3m 45s\tremaining: 43.9s\n",
      "2490:\tlearn: 3656133.6489686\ttotal: 3m 45s\tremaining: 43.8s\n",
      "2491:\tlearn: 3655806.8926032\ttotal: 3m 45s\tremaining: 43.7s\n",
      "2492:\tlearn: 3655125.0554713\ttotal: 3m 45s\tremaining: 43.6s\n",
      "2493:\tlearn: 3653134.0029767\ttotal: 3m 46s\tremaining: 43.5s\n",
      "2494:\tlearn: 3652651.0174176\ttotal: 3m 46s\tremaining: 43.4s\n",
      "2495:\tlearn: 3652211.2095123\ttotal: 3m 46s\tremaining: 43.3s\n",
      "2496:\tlearn: 3651791.4615953\ttotal: 3m 46s\tremaining: 43.2s\n",
      "2497:\tlearn: 3650795.1212678\ttotal: 3m 46s\tremaining: 43.1s\n",
      "2498:\tlearn: 3649917.9173207\ttotal: 3m 46s\tremaining: 43s\n",
      "2499:\tlearn: 3648849.7168475\ttotal: 3m 46s\tremaining: 43s\n",
      "2500:\tlearn: 3647846.6573274\ttotal: 3m 46s\tremaining: 42.9s\n",
      "2501:\tlearn: 3645789.5933743\ttotal: 3m 46s\tremaining: 42.8s\n",
      "2502:\tlearn: 3645042.6965019\ttotal: 3m 46s\tremaining: 42.7s\n",
      "2503:\tlearn: 3644719.3295753\ttotal: 3m 46s\tremaining: 42.6s\n",
      "2504:\tlearn: 3644539.2750934\ttotal: 3m 46s\tremaining: 42.5s\n",
      "2505:\tlearn: 3643692.3335207\ttotal: 3m 47s\tremaining: 42.4s\n",
      "2506:\tlearn: 3643184.4461626\ttotal: 3m 47s\tremaining: 42.3s\n",
      "2507:\tlearn: 3642428.7845820\ttotal: 3m 47s\tremaining: 42.2s\n",
      "2508:\tlearn: 3641596.3393514\ttotal: 3m 47s\tremaining: 42.1s\n",
      "2509:\tlearn: 3640756.7165684\ttotal: 3m 47s\tremaining: 42s\n",
      "2510:\tlearn: 3639928.7137652\ttotal: 3m 47s\tremaining: 41.9s\n",
      "2511:\tlearn: 3639387.9019496\ttotal: 3m 47s\tremaining: 41.8s\n",
      "2512:\tlearn: 3638792.8380627\ttotal: 3m 47s\tremaining: 41.8s\n",
      "2513:\tlearn: 3638400.6451960\ttotal: 3m 47s\tremaining: 41.7s\n",
      "2514:\tlearn: 3637514.5248298\ttotal: 3m 47s\tremaining: 41.6s\n",
      "2515:\tlearn: 3636994.6854569\ttotal: 3m 47s\tremaining: 41.5s\n",
      "2516:\tlearn: 3636216.5791258\ttotal: 3m 47s\tremaining: 41.4s\n",
      "2517:\tlearn: 3634640.6347107\ttotal: 3m 48s\tremaining: 41.3s\n",
      "2518:\tlearn: 3634265.8535944\ttotal: 3m 48s\tremaining: 41.2s\n",
      "2519:\tlearn: 3633098.7915271\ttotal: 3m 48s\tremaining: 41.1s\n",
      "2520:\tlearn: 3632309.2858627\ttotal: 3m 48s\tremaining: 41s\n",
      "2521:\tlearn: 3631775.0260624\ttotal: 3m 48s\tremaining: 40.9s\n",
      "2522:\tlearn: 3631106.8839163\ttotal: 3m 48s\tremaining: 40.8s\n",
      "2523:\tlearn: 3630591.8635609\ttotal: 3m 48s\tremaining: 40.7s\n",
      "2524:\tlearn: 3629978.4821130\ttotal: 3m 48s\tremaining: 40.6s\n",
      "2525:\tlearn: 3629523.1470391\ttotal: 3m 48s\tremaining: 40.6s\n",
      "2526:\tlearn: 3628133.8786724\ttotal: 3m 48s\tremaining: 40.5s\n",
      "2527:\tlearn: 3627956.2340395\ttotal: 3m 48s\tremaining: 40.4s\n",
      "2528:\tlearn: 3627432.6566425\ttotal: 3m 48s\tremaining: 40.3s\n",
      "2529:\tlearn: 3626832.9639072\ttotal: 3m 48s\tremaining: 40.2s\n",
      "2530:\tlearn: 3625581.9652210\ttotal: 3m 49s\tremaining: 40.1s\n",
      "2531:\tlearn: 3625194.5096410\ttotal: 3m 49s\tremaining: 40s\n",
      "2532:\tlearn: 3624199.6098234\ttotal: 3m 49s\tremaining: 39.9s\n",
      "2533:\tlearn: 3623220.7902374\ttotal: 3m 49s\tremaining: 39.8s\n",
      "2534:\tlearn: 3622805.3003622\ttotal: 3m 49s\tremaining: 39.7s\n",
      "2535:\tlearn: 3622096.4128541\ttotal: 3m 49s\tremaining: 39.6s\n",
      "2536:\tlearn: 3621120.7088922\ttotal: 3m 49s\tremaining: 39.5s\n",
      "2537:\tlearn: 3620832.0421035\ttotal: 3m 49s\tremaining: 39.5s\n",
      "2538:\tlearn: 3620059.2947608\ttotal: 3m 49s\tremaining: 39.4s\n",
      "2539:\tlearn: 3617659.2834113\ttotal: 3m 49s\tremaining: 39.3s\n",
      "2540:\tlearn: 3617270.7907320\ttotal: 3m 49s\tremaining: 39.2s\n",
      "2541:\tlearn: 3616811.7143268\ttotal: 3m 49s\tremaining: 39.1s\n",
      "2542:\tlearn: 3614490.4400266\ttotal: 3m 50s\tremaining: 39s\n",
      "2543:\tlearn: 3612397.7251995\ttotal: 3m 50s\tremaining: 38.9s\n",
      "2544:\tlearn: 3609813.7943230\ttotal: 3m 50s\tremaining: 38.8s\n",
      "2545:\tlearn: 3609315.4127293\ttotal: 3m 50s\tremaining: 38.7s\n",
      "2546:\tlearn: 3608841.3770751\ttotal: 3m 50s\tremaining: 38.6s\n",
      "2547:\tlearn: 3608607.1443166\ttotal: 3m 50s\tremaining: 38.5s\n",
      "2548:\tlearn: 3606006.0406079\ttotal: 3m 50s\tremaining: 38.4s\n",
      "2549:\tlearn: 3604150.0300062\ttotal: 3m 50s\tremaining: 38.3s\n",
      "2550:\tlearn: 3603563.2837677\ttotal: 3m 50s\tremaining: 38.3s\n",
      "2551:\tlearn: 3602939.9500084\ttotal: 3m 50s\tremaining: 38.2s\n",
      "2552:\tlearn: 3602516.4242680\ttotal: 3m 50s\tremaining: 38.1s\n",
      "2553:\tlearn: 3601919.6298267\ttotal: 3m 50s\tremaining: 38s\n",
      "2554:\tlearn: 3601201.2581214\ttotal: 3m 51s\tremaining: 37.9s\n",
      "2555:\tlearn: 3600226.5567468\ttotal: 3m 51s\tremaining: 37.8s\n",
      "2556:\tlearn: 3598552.5598018\ttotal: 3m 51s\tremaining: 37.7s\n",
      "2557:\tlearn: 3596826.8831505\ttotal: 3m 51s\tremaining: 37.6s\n",
      "2558:\tlearn: 3595926.4242670\ttotal: 3m 51s\tremaining: 37.5s\n",
      "2559:\tlearn: 3595444.4673965\ttotal: 3m 51s\tremaining: 37.4s\n",
      "2560:\tlearn: 3594923.4451467\ttotal: 3m 51s\tremaining: 37.3s\n",
      "2561:\tlearn: 3593964.0864806\ttotal: 3m 51s\tremaining: 37.2s\n",
      "2562:\tlearn: 3593762.7023517\ttotal: 3m 51s\tremaining: 37.2s\n",
      "2563:\tlearn: 3589730.1852557\ttotal: 3m 51s\tremaining: 37.1s\n",
      "2564:\tlearn: 3588831.8804610\ttotal: 3m 51s\tremaining: 37s\n",
      "2565:\tlearn: 3588216.9813870\ttotal: 3m 51s\tremaining: 36.9s\n",
      "2566:\tlearn: 3587721.5554811\ttotal: 3m 52s\tremaining: 36.8s\n",
      "2567:\tlearn: 3586986.2851290\ttotal: 3m 52s\tremaining: 36.7s\n",
      "2568:\tlearn: 3585098.9628222\ttotal: 3m 52s\tremaining: 36.6s\n",
      "2569:\tlearn: 3584060.5120822\ttotal: 3m 52s\tremaining: 36.5s\n",
      "2570:\tlearn: 3583034.7337330\ttotal: 3m 52s\tremaining: 36.4s\n",
      "2571:\tlearn: 3582504.5990822\ttotal: 3m 52s\tremaining: 36.3s\n",
      "2572:\tlearn: 3582172.3805148\ttotal: 3m 52s\tremaining: 36.2s\n",
      "2573:\tlearn: 3577983.7985733\ttotal: 3m 52s\tremaining: 36.2s\n",
      "2574:\tlearn: 3576610.2547927\ttotal: 3m 52s\tremaining: 36.1s\n",
      "2575:\tlearn: 3574746.1748728\ttotal: 3m 52s\tremaining: 36s\n",
      "2576:\tlearn: 3574296.1683337\ttotal: 3m 52s\tremaining: 35.9s\n",
      "2577:\tlearn: 3573632.6670075\ttotal: 3m 53s\tremaining: 35.8s\n",
      "2578:\tlearn: 3572730.7449936\ttotal: 3m 53s\tremaining: 35.7s\n",
      "2579:\tlearn: 3571944.0682559\ttotal: 3m 53s\tremaining: 35.6s\n",
      "2580:\tlearn: 3570987.1513301\ttotal: 3m 53s\tremaining: 35.5s\n",
      "2581:\tlearn: 3570797.3690952\ttotal: 3m 53s\tremaining: 35.4s\n",
      "2582:\tlearn: 3570378.8675386\ttotal: 3m 53s\tremaining: 35.3s\n",
      "2583:\tlearn: 3569462.0249276\ttotal: 3m 53s\tremaining: 35.3s\n",
      "2584:\tlearn: 3568580.2348959\ttotal: 3m 53s\tremaining: 35.2s\n",
      "2585:\tlearn: 3567580.3997189\ttotal: 3m 53s\tremaining: 35.1s\n",
      "2586:\tlearn: 3566971.1738796\ttotal: 3m 53s\tremaining: 35s\n",
      "2587:\tlearn: 3566055.1109755\ttotal: 3m 53s\tremaining: 34.9s\n",
      "2588:\tlearn: 3565108.2628050\ttotal: 3m 54s\tremaining: 34.8s\n",
      "2589:\tlearn: 3564265.9466268\ttotal: 3m 54s\tremaining: 34.7s\n",
      "2590:\tlearn: 3563054.5747492\ttotal: 3m 54s\tremaining: 34.6s\n",
      "2591:\tlearn: 3562222.0162647\ttotal: 3m 54s\tremaining: 34.5s\n",
      "2592:\tlearn: 3561606.3846020\ttotal: 3m 54s\tremaining: 34.4s\n",
      "2593:\tlearn: 3561151.7035485\ttotal: 3m 54s\tremaining: 34.4s\n",
      "2594:\tlearn: 3560631.7542369\ttotal: 3m 54s\tremaining: 34.3s\n",
      "2595:\tlearn: 3559927.3403085\ttotal: 3m 54s\tremaining: 34.2s\n",
      "2596:\tlearn: 3559113.7242506\ttotal: 3m 54s\tremaining: 34.1s\n",
      "2597:\tlearn: 3558525.4946313\ttotal: 3m 54s\tremaining: 34s\n",
      "2598:\tlearn: 3557757.5402427\ttotal: 3m 54s\tremaining: 33.9s\n",
      "2599:\tlearn: 3557247.7316318\ttotal: 3m 55s\tremaining: 33.8s\n",
      "2600:\tlearn: 3556770.3738200\ttotal: 3m 55s\tremaining: 33.7s\n",
      "2601:\tlearn: 3556227.6286299\ttotal: 3m 55s\tremaining: 33.6s\n",
      "2602:\tlearn: 3555866.8302920\ttotal: 3m 55s\tremaining: 33.5s\n",
      "2603:\tlearn: 3555069.5743399\ttotal: 3m 55s\tremaining: 33.4s\n",
      "2604:\tlearn: 3554651.5627794\ttotal: 3m 55s\tremaining: 33.4s\n",
      "2605:\tlearn: 3554196.8419542\ttotal: 3m 55s\tremaining: 33.3s\n",
      "2606:\tlearn: 3553639.8141032\ttotal: 3m 55s\tremaining: 33.2s\n",
      "2607:\tlearn: 3553115.9571415\ttotal: 3m 55s\tremaining: 33.1s\n",
      "2608:\tlearn: 3552788.0285240\ttotal: 3m 55s\tremaining: 33s\n",
      "2609:\tlearn: 3552342.7025673\ttotal: 3m 55s\tremaining: 32.9s\n",
      "2610:\tlearn: 3551519.0320652\ttotal: 3m 55s\tremaining: 32.8s\n",
      "2611:\tlearn: 3550961.6462681\ttotal: 3m 56s\tremaining: 32.7s\n",
      "2612:\tlearn: 3550341.6924722\ttotal: 3m 56s\tremaining: 32.6s\n",
      "2613:\tlearn: 3549597.2586718\ttotal: 3m 56s\tremaining: 32.5s\n",
      "2614:\tlearn: 3548641.0038468\ttotal: 3m 56s\tremaining: 32.4s\n",
      "2615:\tlearn: 3548222.6520378\ttotal: 3m 56s\tremaining: 32.4s\n",
      "2616:\tlearn: 3547307.0068576\ttotal: 3m 56s\tremaining: 32.3s\n",
      "2617:\tlearn: 3546814.4113199\ttotal: 3m 56s\tremaining: 32.2s\n",
      "2618:\tlearn: 3546590.5453175\ttotal: 3m 56s\tremaining: 32.1s\n",
      "2619:\tlearn: 3545529.7940252\ttotal: 3m 56s\tremaining: 32s\n",
      "2620:\tlearn: 3544472.5265238\ttotal: 3m 56s\tremaining: 31.9s\n",
      "2621:\tlearn: 3543059.0060875\ttotal: 3m 56s\tremaining: 31.8s\n",
      "2622:\tlearn: 3542625.5482724\ttotal: 3m 57s\tremaining: 31.7s\n",
      "2623:\tlearn: 3541826.2958478\ttotal: 3m 57s\tremaining: 31.6s\n",
      "2624:\tlearn: 3539983.8709530\ttotal: 3m 57s\tremaining: 31.5s\n",
      "2625:\tlearn: 3539416.4899559\ttotal: 3m 57s\tremaining: 31.5s\n",
      "2626:\tlearn: 3538472.0300849\ttotal: 3m 57s\tremaining: 31.4s\n",
      "2627:\tlearn: 3538086.4160717\ttotal: 3m 57s\tremaining: 31.3s\n",
      "2628:\tlearn: 3537133.7619856\ttotal: 3m 57s\tremaining: 31.2s\n",
      "2629:\tlearn: 3536486.7517904\ttotal: 3m 57s\tremaining: 31.1s\n",
      "2630:\tlearn: 3535980.2532792\ttotal: 3m 57s\tremaining: 31s\n",
      "2631:\tlearn: 3535197.3384122\ttotal: 3m 57s\tremaining: 30.9s\n",
      "2632:\tlearn: 3534237.8081030\ttotal: 3m 57s\tremaining: 30.8s\n",
      "2633:\tlearn: 3532591.6569772\ttotal: 3m 58s\tremaining: 30.7s\n",
      "2634:\tlearn: 3532432.6864446\ttotal: 3m 58s\tremaining: 30.6s\n",
      "2635:\tlearn: 3530704.9573064\ttotal: 3m 58s\tremaining: 30.6s\n",
      "2636:\tlearn: 3530417.5899636\ttotal: 3m 58s\tremaining: 30.5s\n",
      "2637:\tlearn: 3529967.6665650\ttotal: 3m 58s\tremaining: 30.4s\n",
      "2638:\tlearn: 3529159.4009294\ttotal: 3m 58s\tremaining: 30.3s\n",
      "2639:\tlearn: 3528412.1629204\ttotal: 3m 58s\tremaining: 30.2s\n",
      "2640:\tlearn: 3527511.3955293\ttotal: 3m 58s\tremaining: 30.1s\n",
      "2641:\tlearn: 3526412.2238959\ttotal: 3m 58s\tremaining: 30s\n",
      "2642:\tlearn: 3526144.4298261\ttotal: 3m 58s\tremaining: 29.9s\n",
      "2643:\tlearn: 3525457.9966362\ttotal: 3m 59s\tremaining: 29.8s\n",
      "2644:\tlearn: 3524762.4251970\ttotal: 3m 59s\tremaining: 29.7s\n",
      "2645:\tlearn: 3524487.8771169\ttotal: 3m 59s\tremaining: 29.7s\n",
      "2646:\tlearn: 3523808.2157771\ttotal: 3m 59s\tremaining: 29.6s\n",
      "2647:\tlearn: 3522953.8854581\ttotal: 3m 59s\tremaining: 29.5s\n",
      "2648:\tlearn: 3522121.7651752\ttotal: 3m 59s\tremaining: 29.4s\n",
      "2649:\tlearn: 3521467.6069423\ttotal: 3m 59s\tremaining: 29.3s\n",
      "2650:\tlearn: 3521291.6903927\ttotal: 3m 59s\tremaining: 29.2s\n",
      "2651:\tlearn: 3520851.0037994\ttotal: 3m 59s\tremaining: 29.1s\n",
      "2652:\tlearn: 3520652.7862677\ttotal: 3m 59s\tremaining: 29s\n",
      "2653:\tlearn: 3519751.9717093\ttotal: 3m 59s\tremaining: 28.9s\n",
      "2654:\tlearn: 3519294.8828389\ttotal: 4m\tremaining: 28.8s\n",
      "2655:\tlearn: 3517623.6122376\ttotal: 4m\tremaining: 28.8s\n",
      "2656:\tlearn: 3516996.4888402\ttotal: 4m\tremaining: 28.7s\n",
      "2657:\tlearn: 3515948.6522382\ttotal: 4m\tremaining: 28.6s\n",
      "2658:\tlearn: 3514881.6808851\ttotal: 4m\tremaining: 28.5s\n",
      "2659:\tlearn: 3514074.6514018\ttotal: 4m\tremaining: 28.4s\n",
      "2660:\tlearn: 3513218.2253163\ttotal: 4m\tremaining: 28.3s\n",
      "2661:\tlearn: 3512886.4868452\ttotal: 4m\tremaining: 28.2s\n",
      "2662:\tlearn: 3512395.9017633\ttotal: 4m\tremaining: 28.1s\n",
      "2663:\tlearn: 3511641.0540656\ttotal: 4m\tremaining: 28s\n",
      "2664:\tlearn: 3511141.9630728\ttotal: 4m 1s\tremaining: 27.9s\n",
      "2665:\tlearn: 3510438.9445772\ttotal: 4m 1s\tremaining: 27.9s\n",
      "2666:\tlearn: 3508054.4013902\ttotal: 4m 1s\tremaining: 27.8s\n",
      "2667:\tlearn: 3507618.1924335\ttotal: 4m 1s\tremaining: 27.7s\n",
      "2668:\tlearn: 3506972.0275858\ttotal: 4m 1s\tremaining: 27.6s\n",
      "2669:\tlearn: 3505619.9484851\ttotal: 4m 1s\tremaining: 27.5s\n",
      "2670:\tlearn: 3504276.9507487\ttotal: 4m 1s\tremaining: 27.4s\n",
      "2671:\tlearn: 3503039.6172311\ttotal: 4m 1s\tremaining: 27.3s\n",
      "2672:\tlearn: 3502064.2111366\ttotal: 4m 1s\tremaining: 27.2s\n",
      "2673:\tlearn: 3501270.8803930\ttotal: 4m 1s\tremaining: 27.1s\n",
      "2674:\tlearn: 3500479.1034118\ttotal: 4m 1s\tremaining: 27s\n",
      "2675:\tlearn: 3499503.4242610\ttotal: 4m 2s\tremaining: 27s\n",
      "2676:\tlearn: 3499185.9306074\ttotal: 4m 2s\tremaining: 26.9s\n",
      "2677:\tlearn: 3498561.9060393\ttotal: 4m 2s\tremaining: 26.8s\n",
      "2678:\tlearn: 3498192.2127718\ttotal: 4m 2s\tremaining: 26.7s\n",
      "2679:\tlearn: 3497727.6486732\ttotal: 4m 2s\tremaining: 26.6s\n",
      "2680:\tlearn: 3497239.1330319\ttotal: 4m 2s\tremaining: 26.5s\n",
      "2681:\tlearn: 3496535.6608872\ttotal: 4m 2s\tremaining: 26.4s\n",
      "2682:\tlearn: 3495484.1614656\ttotal: 4m 2s\tremaining: 26.3s\n",
      "2683:\tlearn: 3494826.6371641\ttotal: 4m 2s\tremaining: 26.2s\n",
      "2684:\tlearn: 3494045.5191737\ttotal: 4m 2s\tremaining: 26.1s\n",
      "2685:\tlearn: 3493536.5520352\ttotal: 4m 3s\tremaining: 26.1s\n",
      "2686:\tlearn: 3492489.7886976\ttotal: 4m 3s\tremaining: 26s\n",
      "2687:\tlearn: 3492036.0003554\ttotal: 4m 3s\tremaining: 25.9s\n",
      "2688:\tlearn: 3491715.6779347\ttotal: 4m 3s\tremaining: 25.8s\n",
      "2689:\tlearn: 3491238.7456374\ttotal: 4m 3s\tremaining: 25.7s\n",
      "2690:\tlearn: 3490221.7978377\ttotal: 4m 3s\tremaining: 25.6s\n",
      "2691:\tlearn: 3489350.3067263\ttotal: 4m 3s\tremaining: 25.5s\n",
      "2692:\tlearn: 3488851.8380079\ttotal: 4m 3s\tremaining: 25.4s\n",
      "2693:\tlearn: 3488562.6318855\ttotal: 4m 3s\tremaining: 25.3s\n",
      "2694:\tlearn: 3488142.9810684\ttotal: 4m 3s\tremaining: 25.2s\n",
      "2695:\tlearn: 3486417.9353065\ttotal: 4m 3s\tremaining: 25.2s\n",
      "2696:\tlearn: 3485356.1430495\ttotal: 4m 4s\tremaining: 25.1s\n",
      "2697:\tlearn: 3484698.4178545\ttotal: 4m 4s\tremaining: 25s\n",
      "2698:\tlearn: 3484345.0168928\ttotal: 4m 4s\tremaining: 24.9s\n",
      "2699:\tlearn: 3483967.8373151\ttotal: 4m 4s\tremaining: 24.8s\n",
      "2700:\tlearn: 3483489.8354444\ttotal: 4m 4s\tremaining: 24.7s\n",
      "2701:\tlearn: 3483293.6292176\ttotal: 4m 4s\tremaining: 24.6s\n",
      "2702:\tlearn: 3482712.8446738\ttotal: 4m 4s\tremaining: 24.5s\n",
      "2703:\tlearn: 3482343.9316346\ttotal: 4m 4s\tremaining: 24.4s\n",
      "2704:\tlearn: 3481667.4691274\ttotal: 4m 4s\tremaining: 24.3s\n",
      "2705:\tlearn: 3481409.5502893\ttotal: 4m 4s\tremaining: 24.2s\n",
      "2706:\tlearn: 3480982.3889882\ttotal: 4m 4s\tremaining: 24.2s\n",
      "2707:\tlearn: 3480498.7198620\ttotal: 4m 4s\tremaining: 24.1s\n",
      "2708:\tlearn: 3479899.8090500\ttotal: 4m 5s\tremaining: 24s\n",
      "2709:\tlearn: 3478882.6951539\ttotal: 4m 5s\tremaining: 23.9s\n",
      "2710:\tlearn: 3478510.7092513\ttotal: 4m 5s\tremaining: 23.8s\n",
      "2711:\tlearn: 3477241.6698603\ttotal: 4m 5s\tremaining: 23.7s\n",
      "2712:\tlearn: 3476382.0619803\ttotal: 4m 5s\tremaining: 23.6s\n",
      "2713:\tlearn: 3475308.0981855\ttotal: 4m 5s\tremaining: 23.5s\n",
      "2714:\tlearn: 3474950.6481210\ttotal: 4m 5s\tremaining: 23.4s\n",
      "2715:\tlearn: 3473397.4878421\ttotal: 4m 5s\tremaining: 23.3s\n",
      "2716:\tlearn: 3472904.1096835\ttotal: 4m 5s\tremaining: 23.2s\n",
      "2717:\tlearn: 3472174.8387465\ttotal: 4m 5s\tremaining: 23.2s\n",
      "2718:\tlearn: 3471567.8071702\ttotal: 4m 5s\tremaining: 23.1s\n",
      "2719:\tlearn: 3471042.6305820\ttotal: 4m 6s\tremaining: 23s\n",
      "2720:\tlearn: 3470555.7272923\ttotal: 4m 6s\tremaining: 22.9s\n",
      "2721:\tlearn: 3470245.8989797\ttotal: 4m 6s\tremaining: 22.8s\n",
      "2722:\tlearn: 3469627.9587796\ttotal: 4m 6s\tremaining: 22.7s\n",
      "2723:\tlearn: 3469176.9739587\ttotal: 4m 6s\tremaining: 22.6s\n",
      "2724:\tlearn: 3468829.1079669\ttotal: 4m 6s\tremaining: 22.5s\n",
      "2725:\tlearn: 3468055.5511648\ttotal: 4m 6s\tremaining: 22.4s\n",
      "2726:\tlearn: 3466910.0842288\ttotal: 4m 6s\tremaining: 22.4s\n",
      "2727:\tlearn: 3466201.7934575\ttotal: 4m 6s\tremaining: 22.3s\n",
      "2728:\tlearn: 3465590.8929153\ttotal: 4m 6s\tremaining: 22.2s\n",
      "2729:\tlearn: 3465211.7242488\ttotal: 4m 7s\tremaining: 22.1s\n",
      "2730:\tlearn: 3464606.1893256\ttotal: 4m 7s\tremaining: 22s\n",
      "2731:\tlearn: 3463759.9984122\ttotal: 4m 7s\tremaining: 21.9s\n",
      "2732:\tlearn: 3462764.9237063\ttotal: 4m 7s\tremaining: 21.8s\n",
      "2733:\tlearn: 3461921.5926010\ttotal: 4m 7s\tremaining: 21.7s\n",
      "2734:\tlearn: 3460950.9164265\ttotal: 4m 7s\tremaining: 21.6s\n",
      "2735:\tlearn: 3460191.7633272\ttotal: 4m 7s\tremaining: 21.5s\n",
      "2736:\tlearn: 3459807.0043775\ttotal: 4m 7s\tremaining: 21.4s\n",
      "2737:\tlearn: 3459029.9484187\ttotal: 4m 7s\tremaining: 21.4s\n",
      "2738:\tlearn: 3458100.2541545\ttotal: 4m 7s\tremaining: 21.3s\n",
      "2739:\tlearn: 3457655.2500817\ttotal: 4m 7s\tremaining: 21.2s\n",
      "2740:\tlearn: 3457013.2215148\ttotal: 4m 8s\tremaining: 21.1s\n",
      "2741:\tlearn: 3456724.2082121\ttotal: 4m 8s\tremaining: 21s\n",
      "2742:\tlearn: 3456166.8176325\ttotal: 4m 8s\tremaining: 20.9s\n",
      "2743:\tlearn: 3455825.8462888\ttotal: 4m 8s\tremaining: 20.8s\n",
      "2744:\tlearn: 3455432.1398601\ttotal: 4m 8s\tremaining: 20.7s\n",
      "2745:\tlearn: 3454700.2178914\ttotal: 4m 8s\tremaining: 20.6s\n",
      "2746:\tlearn: 3454044.8743468\ttotal: 4m 8s\tremaining: 20.6s\n",
      "2747:\tlearn: 3453819.0326803\ttotal: 4m 8s\tremaining: 20.5s\n",
      "2748:\tlearn: 3453265.8686065\ttotal: 4m 8s\tremaining: 20.4s\n",
      "2749:\tlearn: 3451116.4226647\ttotal: 4m 8s\tremaining: 20.3s\n",
      "2750:\tlearn: 3450465.0430797\ttotal: 4m 9s\tremaining: 20.2s\n",
      "2751:\tlearn: 3449562.8595242\ttotal: 4m 9s\tremaining: 20.1s\n",
      "2752:\tlearn: 3448752.1012762\ttotal: 4m 9s\tremaining: 20s\n",
      "2753:\tlearn: 3448178.3598828\ttotal: 4m 9s\tremaining: 19.9s\n",
      "2754:\tlearn: 3447865.5793950\ttotal: 4m 9s\tremaining: 19.8s\n",
      "2755:\tlearn: 3447601.5050361\ttotal: 4m 9s\tremaining: 19.7s\n",
      "2756:\tlearn: 3447071.4570373\ttotal: 4m 9s\tremaining: 19.6s\n",
      "2757:\tlearn: 3446323.2187361\ttotal: 4m 9s\tremaining: 19.6s\n",
      "2758:\tlearn: 3445162.2126852\ttotal: 4m 9s\tremaining: 19.5s\n",
      "2759:\tlearn: 3444817.5327071\ttotal: 4m 9s\tremaining: 19.4s\n",
      "2760:\tlearn: 3443073.5267524\ttotal: 4m 10s\tremaining: 19.3s\n",
      "2761:\tlearn: 3442426.4666200\ttotal: 4m 10s\tremaining: 19.2s\n",
      "2762:\tlearn: 3441687.8910768\ttotal: 4m 10s\tremaining: 19.1s\n",
      "2763:\tlearn: 3441350.8185931\ttotal: 4m 10s\tremaining: 19s\n",
      "2764:\tlearn: 3440652.7839503\ttotal: 4m 10s\tremaining: 18.9s\n",
      "2765:\tlearn: 3439626.9677041\ttotal: 4m 10s\tremaining: 18.8s\n",
      "2766:\tlearn: 3438447.7742459\ttotal: 4m 10s\tremaining: 18.7s\n",
      "2767:\tlearn: 3437987.5134820\ttotal: 4m 10s\tremaining: 18.7s\n",
      "2768:\tlearn: 3437611.6410547\ttotal: 4m 10s\tremaining: 18.6s\n",
      "2769:\tlearn: 3436654.0087100\ttotal: 4m 10s\tremaining: 18.5s\n",
      "2770:\tlearn: 3435815.7816886\ttotal: 4m 10s\tremaining: 18.4s\n",
      "2771:\tlearn: 3435414.9839155\ttotal: 4m 11s\tremaining: 18.3s\n",
      "2772:\tlearn: 3434635.8854863\ttotal: 4m 11s\tremaining: 18.2s\n",
      "2773:\tlearn: 3434222.3931353\ttotal: 4m 11s\tremaining: 18.1s\n",
      "2774:\tlearn: 3433603.4291432\ttotal: 4m 11s\tremaining: 18s\n",
      "2775:\tlearn: 3433161.6818918\ttotal: 4m 11s\tremaining: 17.9s\n",
      "2776:\tlearn: 3432868.7958936\ttotal: 4m 11s\tremaining: 17.8s\n",
      "2777:\tlearn: 3432068.9209397\ttotal: 4m 11s\tremaining: 17.8s\n",
      "2778:\tlearn: 3431751.0609799\ttotal: 4m 11s\tremaining: 17.7s\n",
      "2779:\tlearn: 3431349.9058375\ttotal: 4m 11s\tremaining: 17.6s\n",
      "2780:\tlearn: 3430612.4219453\ttotal: 4m 11s\tremaining: 17.5s\n",
      "2781:\tlearn: 3430261.5821447\ttotal: 4m 12s\tremaining: 17.4s\n",
      "2782:\tlearn: 3429912.3566610\ttotal: 4m 12s\tremaining: 17.3s\n",
      "2783:\tlearn: 3429576.3015497\ttotal: 4m 12s\tremaining: 17.2s\n",
      "2784:\tlearn: 3428931.5535798\ttotal: 4m 12s\tremaining: 17.1s\n",
      "2785:\tlearn: 3428299.5548831\ttotal: 4m 12s\tremaining: 17s\n",
      "2786:\tlearn: 3427616.3772744\ttotal: 4m 12s\tremaining: 16.9s\n",
      "2787:\tlearn: 3426997.8505446\ttotal: 4m 12s\tremaining: 16.9s\n",
      "2788:\tlearn: 3426610.4526624\ttotal: 4m 12s\tremaining: 16.8s\n",
      "2789:\tlearn: 3426080.1302161\ttotal: 4m 12s\tremaining: 16.7s\n",
      "2790:\tlearn: 3425578.2580287\ttotal: 4m 12s\tremaining: 16.6s\n",
      "2791:\tlearn: 3425074.1548837\ttotal: 4m 12s\tremaining: 16.5s\n",
      "2792:\tlearn: 3424572.4223283\ttotal: 4m 13s\tremaining: 16.4s\n",
      "2793:\tlearn: 3423711.8819417\ttotal: 4m 13s\tremaining: 16.3s\n",
      "2794:\tlearn: 3423365.9435565\ttotal: 4m 13s\tremaining: 16.2s\n",
      "2795:\tlearn: 3422855.7446580\ttotal: 4m 13s\tremaining: 16.1s\n",
      "2796:\tlearn: 3422342.7205987\ttotal: 4m 13s\tremaining: 16s\n",
      "2797:\tlearn: 3421511.5399171\ttotal: 4m 13s\tremaining: 15.9s\n",
      "2798:\tlearn: 3421252.2962182\ttotal: 4m 13s\tremaining: 15.9s\n",
      "2799:\tlearn: 3419618.1774445\ttotal: 4m 13s\tremaining: 15.8s\n",
      "2800:\tlearn: 3418957.1037729\ttotal: 4m 13s\tremaining: 15.7s\n",
      "2801:\tlearn: 3418469.6434671\ttotal: 4m 13s\tremaining: 15.6s\n",
      "2802:\tlearn: 3417952.8753129\ttotal: 4m 14s\tremaining: 15.5s\n",
      "2803:\tlearn: 3417412.6415049\ttotal: 4m 14s\tremaining: 15.4s\n",
      "2804:\tlearn: 3416857.8697485\ttotal: 4m 14s\tremaining: 15.3s\n",
      "2805:\tlearn: 3416188.8378144\ttotal: 4m 14s\tremaining: 15.2s\n",
      "2806:\tlearn: 3415806.0512152\ttotal: 4m 14s\tremaining: 15.1s\n",
      "2807:\tlearn: 3415222.5725317\ttotal: 4m 14s\tremaining: 15s\n",
      "2808:\tlearn: 3414326.1848371\ttotal: 4m 14s\tremaining: 15s\n",
      "2809:\tlearn: 3413978.9098418\ttotal: 4m 14s\tremaining: 14.9s\n",
      "2810:\tlearn: 3413039.3461870\ttotal: 4m 14s\tremaining: 14.8s\n",
      "2811:\tlearn: 3412310.5495143\ttotal: 4m 14s\tremaining: 14.7s\n",
      "2812:\tlearn: 3411634.2868120\ttotal: 4m 15s\tremaining: 14.6s\n",
      "2813:\tlearn: 3411205.7165632\ttotal: 4m 15s\tremaining: 14.5s\n",
      "2814:\tlearn: 3410436.8026137\ttotal: 4m 15s\tremaining: 14.4s\n",
      "2815:\tlearn: 3409824.7414037\ttotal: 4m 15s\tremaining: 14.3s\n",
      "2816:\tlearn: 3408905.8283751\ttotal: 4m 15s\tremaining: 14.2s\n",
      "2817:\tlearn: 3408351.4218415\ttotal: 4m 15s\tremaining: 14.1s\n",
      "2818:\tlearn: 3408001.8818450\ttotal: 4m 15s\tremaining: 14.1s\n",
      "2819:\tlearn: 3407409.7356143\ttotal: 4m 15s\tremaining: 14s\n",
      "2820:\tlearn: 3405618.1933963\ttotal: 4m 15s\tremaining: 13.9s\n",
      "2821:\tlearn: 3404918.0364001\ttotal: 4m 15s\tremaining: 13.8s\n",
      "2822:\tlearn: 3404402.9008152\ttotal: 4m 16s\tremaining: 13.7s\n",
      "2823:\tlearn: 3402975.7732684\ttotal: 4m 16s\tremaining: 13.6s\n",
      "2824:\tlearn: 3402447.3920333\ttotal: 4m 16s\tremaining: 13.5s\n",
      "2825:\tlearn: 3401969.6816307\ttotal: 4m 16s\tremaining: 13.4s\n",
      "2826:\tlearn: 3401264.9286027\ttotal: 4m 16s\tremaining: 13.3s\n",
      "2827:\tlearn: 3400678.6582144\ttotal: 4m 16s\tremaining: 13.2s\n",
      "2828:\tlearn: 3399861.2627921\ttotal: 4m 16s\tremaining: 13.2s\n",
      "2829:\tlearn: 3399372.6479652\ttotal: 4m 16s\tremaining: 13.1s\n",
      "2830:\tlearn: 3398952.2326740\ttotal: 4m 16s\tremaining: 13s\n",
      "2831:\tlearn: 3398514.6894630\ttotal: 4m 16s\tremaining: 12.9s\n",
      "2832:\tlearn: 3397961.8895424\ttotal: 4m 17s\tremaining: 12.8s\n",
      "2833:\tlearn: 3397686.6190860\ttotal: 4m 17s\tremaining: 12.7s\n",
      "2834:\tlearn: 3397160.0538826\ttotal: 4m 17s\tremaining: 12.6s\n",
      "2835:\tlearn: 3396537.5477590\ttotal: 4m 17s\tremaining: 12.5s\n",
      "2836:\tlearn: 3395830.8652479\ttotal: 4m 17s\tremaining: 12.4s\n",
      "2837:\tlearn: 3395263.1627580\ttotal: 4m 17s\tremaining: 12.3s\n",
      "2838:\tlearn: 3394729.6325800\ttotal: 4m 17s\tremaining: 12.3s\n",
      "2839:\tlearn: 3394019.0455836\ttotal: 4m 17s\tremaining: 12.2s\n",
      "2840:\tlearn: 3393219.0709480\ttotal: 4m 17s\tremaining: 12.1s\n",
      "2841:\tlearn: 3392734.9924151\ttotal: 4m 17s\tremaining: 12s\n",
      "2842:\tlearn: 3392373.6418509\ttotal: 4m 18s\tremaining: 11.9s\n",
      "2843:\tlearn: 3391843.2077708\ttotal: 4m 18s\tremaining: 11.8s\n",
      "2844:\tlearn: 3391213.7434930\ttotal: 4m 18s\tremaining: 11.7s\n",
      "2845:\tlearn: 3390784.9306333\ttotal: 4m 18s\tremaining: 11.6s\n",
      "2846:\tlearn: 3390247.8648447\ttotal: 4m 18s\tremaining: 11.5s\n",
      "2847:\tlearn: 3389725.3283383\ttotal: 4m 18s\tremaining: 11.4s\n",
      "2848:\tlearn: 3388813.0508188\ttotal: 4m 18s\tremaining: 11.3s\n",
      "2849:\tlearn: 3388260.7851395\ttotal: 4m 18s\tremaining: 11.3s\n",
      "2850:\tlearn: 3387390.2238201\ttotal: 4m 18s\tremaining: 11.2s\n",
      "2851:\tlearn: 3386908.3889358\ttotal: 4m 18s\tremaining: 11.1s\n",
      "2852:\tlearn: 3386039.5318449\ttotal: 4m 19s\tremaining: 11s\n",
      "2853:\tlearn: 3385832.6331041\ttotal: 4m 19s\tremaining: 10.9s\n",
      "2854:\tlearn: 3385497.6079243\ttotal: 4m 19s\tremaining: 10.8s\n",
      "2855:\tlearn: 3384851.0253666\ttotal: 4m 19s\tremaining: 10.7s\n",
      "2856:\tlearn: 3382772.5555615\ttotal: 4m 19s\tremaining: 10.6s\n",
      "2857:\tlearn: 3382337.2931614\ttotal: 4m 19s\tremaining: 10.5s\n",
      "2858:\tlearn: 3381613.0134619\ttotal: 4m 19s\tremaining: 10.4s\n",
      "2859:\tlearn: 3381286.9547634\ttotal: 4m 19s\tremaining: 10.4s\n",
      "2860:\tlearn: 3377141.0738378\ttotal: 4m 19s\tremaining: 10.3s\n",
      "2861:\tlearn: 3376825.0733652\ttotal: 4m 19s\tremaining: 10.2s\n",
      "2862:\tlearn: 3376589.9354774\ttotal: 4m 20s\tremaining: 10.1s\n",
      "2863:\tlearn: 3375976.8467458\ttotal: 4m 20s\tremaining: 9.99s\n",
      "2864:\tlearn: 3375542.5483888\ttotal: 4m 20s\tremaining: 9.9s\n",
      "2865:\tlearn: 3375007.0629056\ttotal: 4m 20s\tremaining: 9.81s\n",
      "2866:\tlearn: 3374831.2858503\ttotal: 4m 20s\tremaining: 9.72s\n",
      "2867:\tlearn: 3374639.4520872\ttotal: 4m 20s\tremaining: 9.63s\n",
      "2868:\tlearn: 3372808.2013163\ttotal: 4m 20s\tremaining: 9.54s\n",
      "2869:\tlearn: 3371919.7077818\ttotal: 4m 20s\tremaining: 9.44s\n",
      "2870:\tlearn: 3371395.5823833\ttotal: 4m 20s\tremaining: 9.35s\n",
      "2871:\tlearn: 3370425.4954728\ttotal: 4m 20s\tremaining: 9.26s\n",
      "2872:\tlearn: 3369269.2108243\ttotal: 4m 20s\tremaining: 9.17s\n",
      "2873:\tlearn: 3367753.3187388\ttotal: 4m 20s\tremaining: 9.08s\n",
      "2874:\tlearn: 3366943.0934593\ttotal: 4m 21s\tremaining: 8.99s\n",
      "2875:\tlearn: 3366374.5048812\ttotal: 4m 21s\tremaining: 8.9s\n",
      "2876:\tlearn: 3365729.5373837\ttotal: 4m 21s\tremaining: 8.81s\n",
      "2877:\tlearn: 3364207.8541604\ttotal: 4m 21s\tremaining: 8.72s\n",
      "2878:\tlearn: 3360214.5869787\ttotal: 4m 21s\tremaining: 8.63s\n",
      "2879:\tlearn: 3359682.2984022\ttotal: 4m 21s\tremaining: 8.54s\n",
      "2880:\tlearn: 3359044.5967923\ttotal: 4m 21s\tremaining: 8.45s\n",
      "2881:\tlearn: 3358193.6302792\ttotal: 4m 21s\tremaining: 8.35s\n",
      "2882:\tlearn: 3357652.0306961\ttotal: 4m 21s\tremaining: 8.26s\n",
      "2883:\tlearn: 3357014.4698498\ttotal: 4m 21s\tremaining: 8.17s\n",
      "2884:\tlearn: 3356492.2763100\ttotal: 4m 21s\tremaining: 8.08s\n",
      "2885:\tlearn: 3354611.1849617\ttotal: 4m 22s\tremaining: 7.99s\n",
      "2886:\tlearn: 3354326.1775004\ttotal: 4m 22s\tremaining: 7.9s\n",
      "2887:\tlearn: 3353456.3551325\ttotal: 4m 22s\tremaining: 7.81s\n",
      "2888:\tlearn: 3352986.8723037\ttotal: 4m 22s\tremaining: 7.72s\n",
      "2889:\tlearn: 3352671.6741607\ttotal: 4m 22s\tremaining: 7.63s\n",
      "2890:\tlearn: 3348988.4357548\ttotal: 4m 22s\tremaining: 7.54s\n",
      "2891:\tlearn: 3347451.2385259\ttotal: 4m 22s\tremaining: 7.45s\n",
      "2892:\tlearn: 3347112.5201094\ttotal: 4m 22s\tremaining: 7.36s\n",
      "2893:\tlearn: 3346862.9904106\ttotal: 4m 22s\tremaining: 7.26s\n",
      "2894:\tlearn: 3345840.6878263\ttotal: 4m 22s\tremaining: 7.17s\n",
      "2895:\tlearn: 3345393.9907683\ttotal: 4m 22s\tremaining: 7.08s\n",
      "2896:\tlearn: 3344836.3411266\ttotal: 4m 23s\tremaining: 6.99s\n",
      "2897:\tlearn: 3344520.6536056\ttotal: 4m 23s\tremaining: 6.9s\n",
      "2898:\tlearn: 3344029.1325392\ttotal: 4m 23s\tremaining: 6.81s\n",
      "2899:\tlearn: 3343688.4062949\ttotal: 4m 23s\tremaining: 6.72s\n",
      "2900:\tlearn: 3343174.0347872\ttotal: 4m 23s\tremaining: 6.63s\n",
      "2901:\tlearn: 3341800.9782515\ttotal: 4m 23s\tremaining: 6.54s\n",
      "2902:\tlearn: 3341002.0565924\ttotal: 4m 23s\tremaining: 6.45s\n",
      "2903:\tlearn: 3340437.5784087\ttotal: 4m 23s\tremaining: 6.36s\n",
      "2904:\tlearn: 3339725.9888898\ttotal: 4m 23s\tremaining: 6.26s\n",
      "2905:\tlearn: 3339437.1343601\ttotal: 4m 23s\tremaining: 6.17s\n",
      "2906:\tlearn: 3338379.1036384\ttotal: 4m 23s\tremaining: 6.08s\n",
      "2907:\tlearn: 3337903.0254627\ttotal: 4m 24s\tremaining: 5.99s\n",
      "2908:\tlearn: 3337133.5643906\ttotal: 4m 24s\tremaining: 5.9s\n",
      "2909:\tlearn: 3336636.1381316\ttotal: 4m 24s\tremaining: 5.81s\n",
      "2910:\tlearn: 3335894.1911146\ttotal: 4m 24s\tremaining: 5.72s\n",
      "2911:\tlearn: 3335264.9786176\ttotal: 4m 24s\tremaining: 5.63s\n",
      "2912:\tlearn: 3334517.9128303\ttotal: 4m 24s\tremaining: 5.54s\n",
      "2913:\tlearn: 3333918.2459780\ttotal: 4m 24s\tremaining: 5.45s\n",
      "2914:\tlearn: 3332791.2523309\ttotal: 4m 24s\tremaining: 5.36s\n",
      "2915:\tlearn: 3332300.5980787\ttotal: 4m 24s\tremaining: 5.27s\n",
      "2916:\tlearn: 3331509.8018947\ttotal: 4m 24s\tremaining: 5.17s\n",
      "2917:\tlearn: 3331209.5878935\ttotal: 4m 24s\tremaining: 5.08s\n",
      "2918:\tlearn: 3330371.7044928\ttotal: 4m 25s\tremaining: 4.99s\n",
      "2919:\tlearn: 3330132.5520637\ttotal: 4m 25s\tremaining: 4.9s\n",
      "2920:\tlearn: 3329363.2725144\ttotal: 4m 25s\tremaining: 4.81s\n",
      "2921:\tlearn: 3328482.5528458\ttotal: 4m 25s\tremaining: 4.72s\n",
      "2922:\tlearn: 3327764.2090678\ttotal: 4m 25s\tremaining: 4.63s\n",
      "2923:\tlearn: 3326597.4780309\ttotal: 4m 25s\tremaining: 4.54s\n",
      "2924:\tlearn: 3326168.8232876\ttotal: 4m 25s\tremaining: 4.45s\n",
      "2925:\tlearn: 3325487.4915390\ttotal: 4m 25s\tremaining: 4.36s\n",
      "2926:\tlearn: 3324513.9682391\ttotal: 4m 25s\tremaining: 4.27s\n",
      "2927:\tlearn: 3324048.9556066\ttotal: 4m 25s\tremaining: 4.17s\n",
      "2928:\tlearn: 3323038.0521675\ttotal: 4m 25s\tremaining: 4.08s\n",
      "2929:\tlearn: 3322862.7865673\ttotal: 4m 25s\tremaining: 3.99s\n",
      "2930:\tlearn: 3322144.8531772\ttotal: 4m 26s\tremaining: 3.9s\n",
      "2931:\tlearn: 3321693.8847475\ttotal: 4m 26s\tremaining: 3.81s\n",
      "2932:\tlearn: 3321364.2205519\ttotal: 4m 26s\tremaining: 3.72s\n",
      "2933:\tlearn: 3320395.3127325\ttotal: 4m 26s\tremaining: 3.63s\n",
      "2934:\tlearn: 3319963.4948797\ttotal: 4m 26s\tremaining: 3.54s\n",
      "2935:\tlearn: 3319445.3473686\ttotal: 4m 26s\tremaining: 3.45s\n",
      "2936:\tlearn: 3318469.0640489\ttotal: 4m 26s\tremaining: 3.36s\n",
      "2937:\tlearn: 3318004.7993321\ttotal: 4m 26s\tremaining: 3.27s\n",
      "2938:\tlearn: 3317707.9314916\ttotal: 4m 26s\tremaining: 3.17s\n",
      "2939:\tlearn: 3317163.0855843\ttotal: 4m 26s\tremaining: 3.08s\n",
      "2940:\tlearn: 3316394.9350361\ttotal: 4m 26s\tremaining: 2.99s\n",
      "2941:\tlearn: 3315999.4180085\ttotal: 4m 26s\tremaining: 2.9s\n",
      "2942:\tlearn: 3315580.1931779\ttotal: 4m 27s\tremaining: 2.81s\n",
      "2943:\tlearn: 3314816.6686047\ttotal: 4m 27s\tremaining: 2.72s\n",
      "2944:\tlearn: 3314307.6802335\ttotal: 4m 27s\tremaining: 2.63s\n",
      "2945:\tlearn: 3312901.8399666\ttotal: 4m 27s\tremaining: 2.54s\n",
      "2946:\tlearn: 3312458.7736265\ttotal: 4m 27s\tremaining: 2.45s\n",
      "2947:\tlearn: 3312027.2276432\ttotal: 4m 27s\tremaining: 2.36s\n",
      "2948:\tlearn: 3311510.7125210\ttotal: 4m 27s\tremaining: 2.27s\n",
      "2949:\tlearn: 3311180.6534126\ttotal: 4m 27s\tremaining: 2.18s\n",
      "2950:\tlearn: 3310978.1409608\ttotal: 4m 27s\tremaining: 2.09s\n",
      "2951:\tlearn: 3310523.9054117\ttotal: 4m 27s\tremaining: 2s\n",
      "2952:\tlearn: 3309692.3041613\ttotal: 4m 27s\tremaining: 1.9s\n",
      "2953:\tlearn: 3309234.5224934\ttotal: 4m 27s\tremaining: 1.81s\n",
      "2954:\tlearn: 3307890.8342518\ttotal: 4m 28s\tremaining: 1.72s\n",
      "2955:\tlearn: 3307432.5034333\ttotal: 4m 28s\tremaining: 1.63s\n",
      "2956:\tlearn: 3307034.4580728\ttotal: 4m 28s\tremaining: 1.54s\n",
      "2957:\tlearn: 3306397.3010430\ttotal: 4m 28s\tremaining: 1.45s\n",
      "2958:\tlearn: 3305873.7157728\ttotal: 4m 28s\tremaining: 1.36s\n",
      "2959:\tlearn: 3305658.4715521\ttotal: 4m 28s\tremaining: 1.27s\n",
      "2960:\tlearn: 3305320.4722498\ttotal: 4m 28s\tremaining: 1.18s\n",
      "2961:\tlearn: 3304947.1452135\ttotal: 4m 28s\tremaining: 1.09s\n",
      "2962:\tlearn: 3304200.9094587\ttotal: 4m 28s\tremaining: 997ms\n",
      "2963:\tlearn: 3303426.4799543\ttotal: 4m 28s\tremaining: 907ms\n",
      "2964:\tlearn: 3302972.1270841\ttotal: 4m 28s\tremaining: 816ms\n",
      "2965:\tlearn: 3302365.3779188\ttotal: 4m 28s\tremaining: 725ms\n",
      "2966:\tlearn: 3301325.0763900\ttotal: 4m 28s\tremaining: 635ms\n",
      "2967:\tlearn: 3300872.4655792\ttotal: 4m 29s\tremaining: 544ms\n",
      "2968:\tlearn: 3298541.1936568\ttotal: 4m 29s\tremaining: 453ms\n",
      "2969:\tlearn: 3298229.5845423\ttotal: 4m 29s\tremaining: 363ms\n",
      "2970:\tlearn: 3297957.0527396\ttotal: 4m 29s\tremaining: 272ms\n",
      "2971:\tlearn: 3297435.3572216\ttotal: 4m 29s\tremaining: 181ms\n",
      "2972:\tlearn: 3297082.7167289\ttotal: 4m 29s\tremaining: 90.6ms\n",
      "2973:\tlearn: 3295506.2495999\ttotal: 4m 29s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "modellgbm = LGBMRegressor(**lgbm_param).fit(X_train, y_train)\n",
    "modelxg = XGBRegressor(**xgb_param).fit(X_train, y_train)\n",
    "modelcb = CatBoostRegressor(**cb_param).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3182706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: depth\n",
      "[LightGBM] [Warning] feature_fraction is set=0.775150906035067, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.775150906035067\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1873614189651116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1873614189651116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.30002810690969617, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.30002810690969617\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9126199831365078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9126199831365078\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10426068848332776"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error (y, (modellgbm.predict(X_cb)+modelxg.predict(X_cb)+modelcb.predict(X_cb))/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5530117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(modellgbm, open('modellgbm.pkl', 'wb'))\n",
    "pickle.dump(modelxg, open('modelxg.pkl', 'wb'))\n",
    "pickle.dump(modelcb, open('modelcb.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05aa8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(encoder, open('encoder_cb.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b89f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelxg.save_model('modelxg.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
